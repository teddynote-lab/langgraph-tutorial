{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph MCP (Model Context Protocol) íŠœí† ë¦¬ì–¼\n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” LangGraphì™€ MCP(Model Context Protocol)ë¥¼ í†µí•©í•˜ì—¬ ê°•ë ¥í•œ AI ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- MCPì˜ ê°œë…ê³¼ ì•„í‚¤í…ì²˜ ì´í•´\n",
    "- MultiServerMCPClientë¥¼ ì‚¬ìš©í•œ ë‹¤ì¤‘ ì„œë²„ ê´€ë¦¬\n",
    "- React Agent ë° ToolNodeì™€ MCP í†µí•©\n",
    "- ì‹¤ì „ ì˜ˆì œë¥¼ í†µí•œ ë³µì¡í•œ ì—ì´ì „íŠ¸ êµ¬ì¶•\n",
    "\n",
    "## ëª©ì°¨\n",
    "1. **MCP ê°œìš” ë° ì„¤ì¹˜**\n",
    "2. **ê¸°ë³¸ MCP ì„œë²„ ìƒì„±**\n",
    "3. **MultiServerMCPClient ì„¤ì •**\n",
    "4. **React Agentì™€ MCP í†µí•©**\n",
    "5. **ToolNodeì™€ MCP í†µí•©**\n",
    "6. **ë‹¤ì¤‘ MCP ì„œë²„ ê´€ë¦¬**\n",
    "7. **ì‹¤ì „ ì˜ˆì œ - ë³µì¡í•œ ì—ì´ì „íŠ¸ êµ¬ì¶•**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MCP ê°œìš” ë° ì„¤ì¹˜\n",
    "\n",
    "### MCP(Model Context Protocol)ë€?\n",
    "\n",
    "MCPëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì–¸ì–´ ëª¨ë¸ì— ë„êµ¬ì™€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì œê³µí•˜ëŠ” ë°©ë²•ì„ í‘œì¤€í™”í•œ ì˜¤í”ˆ í”„ë¡œí† ì½œì…ë‹ˆë‹¤.\n",
    "\n",
    "#### ì£¼ìš” íŠ¹ì§•:\n",
    "- ğŸ”§ **í‘œì¤€í™”ëœ ë„êµ¬ ì¸í„°í˜ì´ìŠ¤**: ì¼ê´€ëœ ë°©ì‹ìœ¼ë¡œ ë„êµ¬ ì •ì˜ ë° ì‚¬ìš©\n",
    "- ğŸŒ **ë‹¤ì–‘í•œ ì „ì†¡ ë©”ì»¤ë‹ˆì¦˜**: stdio, HTTP, WebSocket ë“± ì§€ì›\n",
    "- ğŸ”„ **ë™ì  ë„êµ¬ ê²€ìƒ‰**: ëŸ°íƒ€ì„ì— ë„êµ¬ ìë™ ê²€ìƒ‰ ë° ë¡œë“œ\n",
    "- ğŸ—ï¸ **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜**: ì—¬ëŸ¬ ì„œë²„ë¥¼ ë™ì‹œì— ì—°ê²° ê°€ëŠ¥\n",
    "\n",
    "### ì„¤ì¹˜\n",
    "\n",
    "MCPë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import nest_asyncio\n",
    "from typing import Annotated, List, Dict, Any\n",
    "from dataclasses import dataclass\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain & LangGraph\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# MCP\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: ê¸°ë³¸ MCP ì„œë²„ ìƒì„±\n",
    "\n",
    "MCP ì„œë²„ëŠ” ë„êµ¬ë¥¼ ì œê³µí•˜ëŠ” ë…ë¦½ì ì¸ í”„ë¡œì„¸ìŠ¤ì…ë‹ˆë‹¤. FastMCPë¥¼ ì‚¬ìš©í•˜ì—¬ ê°„ë‹¨í•œ ì„œë²„ë¥¼ ë§Œë“¤ì–´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ì˜ˆì œ: ìˆ˜í•™ ì—°ì‚° MCP ì„œë²„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… math_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# math_server.py íŒŒì¼ ìƒì„±\n",
    "math_server_code = '''\n",
    "#!/usr/bin/env python\n",
    "\"\"\"Simple math operations MCP server.\"\"\"\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from typing import Annotated\n",
    "\n",
    "# MCP ì„œë²„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±\n",
    "mcp = FastMCP(\"Math Operations\")\n",
    "\n",
    "@mcp.tool()\n",
    "def add(\n",
    "    a: Annotated[float, \"First number\"],\n",
    "    b: Annotated[float, \"Second number\"]\n",
    ") -> float:\n",
    "    \"\"\"Add two numbers together.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@mcp.tool()\n",
    "def multiply(\n",
    "    a: Annotated[float, \"First number\"],\n",
    "    b: Annotated[float, \"Second number\"]\n",
    ") -> float:\n",
    "    \"\"\"Multiply two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@mcp.tool()\n",
    "def divide(\n",
    "    a: Annotated[float, \"Numerator\"],\n",
    "    b: Annotated[float, \"Denominator\"]\n",
    ") -> float:\n",
    "    \"\"\"Divide two numbers.\"\"\"\n",
    "    if b == 0:\n",
    "        raise ValueError(\"Cannot divide by zero\")\n",
    "    return a / b\n",
    "\n",
    "@mcp.tool()\n",
    "def power(\n",
    "    base: Annotated[float, \"Base number\"],\n",
    "    exponent: Annotated[float, \"Exponent\"]\n",
    ") -> float:\n",
    "    \"\"\"Calculate base raised to the power of exponent.\"\"\"\n",
    "    return base ** exponent\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # stdio ì „ì†¡ ë°©ì‹ìœ¼ë¡œ ì„œë²„ ì‹¤í–‰\n",
    "    mcp.run(transport=\"stdio\")\n",
    "'''\n",
    "\n",
    "# íŒŒì¼ ì €ì¥\n",
    "with open(\"math_server.py\", \"w\") as f:\n",
    "    f.write(math_server_code)\n",
    "\n",
    "print(\"âœ… math_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… weather_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ë‚ ì”¨ ì •ë³´ ì„œë²„ ìƒì„±\n",
    "weather_server_code = '''\n",
    "#!/usr/bin/env python\n",
    "\"\"\"Weather information MCP server.\"\"\"\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from typing import Annotated\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "mcp = FastMCP(\"Weather Service\")\n",
    "\n",
    "@mcp.tool()\n",
    "def get_weather(\n",
    "    city: Annotated[str, \"City name\"]\n",
    ") -> dict:\n",
    "    \"\"\"Get current weather for a city.\"\"\"\n",
    "    # ì‹¤ì œë¡œëŠ” API í˜¸ì¶œì„ í•˜ê² ì§€ë§Œ, ì—¬ê¸°ì„œëŠ” ëª¨ì˜ ë°ì´í„° ë°˜í™˜\n",
    "    weather_conditions = [\"Sunny\", \"Cloudy\", \"Rainy\", \"Snowy\", \"Windy\"]\n",
    "    \n",
    "    return {\n",
    "        \"city\": city,\n",
    "        \"temperature\": random.randint(-10, 35),\n",
    "        \"condition\": random.choice(weather_conditions),\n",
    "        \"humidity\": random.randint(30, 90),\n",
    "        \"wind_speed\": random.randint(0, 30),\n",
    "        \"timestamp\": datetime.now().isoformat()\n",
    "    }\n",
    "\n",
    "@mcp.tool()\n",
    "def get_forecast(\n",
    "    city: Annotated[str, \"City name\"],\n",
    "    days: Annotated[int, \"Number of days (1-7)\"] = 3\n",
    ") -> list:\n",
    "    \"\"\"Get weather forecast for a city.\"\"\"\n",
    "    if days < 1 or days > 7:\n",
    "        raise ValueError(\"Days must be between 1 and 7\")\n",
    "    \n",
    "    forecast = []\n",
    "    for i in range(days):\n",
    "        forecast.append({\n",
    "            \"day\": i + 1,\n",
    "            \"high\": random.randint(10, 35),\n",
    "            \"low\": random.randint(-5, 20),\n",
    "            \"condition\": random.choice([\"Sunny\", \"Cloudy\", \"Rainy\"])\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        \"city\": city,\n",
    "        \"forecast\": forecast\n",
    "    }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "'''\n",
    "\n",
    "with open(\"weather_server.py\", \"w\") as f:\n",
    "    f.write(weather_server_code)\n",
    "\n",
    "print(\"âœ… weather_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: MultiServerMCPClient ì„¤ì •\n",
    "\n",
    "MultiServerMCPClientë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ ë™ì‹œì— ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ê¸°ë³¸ ì„¤ì • íŒ¨í„´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 6 ê°œì˜ ë„êµ¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤:\n",
      "  - add: Add two numbers together.\n",
      "  - multiply: Multiply two numbers.\n",
      "  - divide: Divide two numbers.\n",
      "  - power: Calculate base raised to the power of exponent.\n",
      "  - get_weather: Get current weather for a city.\n",
      "  - get_forecast: Get weather forecast for a city.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<langchain_mcp_adapters.client.MultiServerMCPClient at 0x1589991f0>,\n",
       " [StructuredTool(name='add', description='Add two numbers together.', args_schema={'properties': {'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15aed3560>),\n",
       "  StructuredTool(name='multiply', description='Multiply two numbers.', args_schema={'properties': {'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}, 'required': ['a', 'b'], 'title': 'multiplyArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15f9f5800>),\n",
       "  StructuredTool(name='divide', description='Divide two numbers.', args_schema={'properties': {'a': {'title': 'A', 'type': 'number'}, 'b': {'title': 'B', 'type': 'number'}}, 'required': ['a', 'b'], 'title': 'divideArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15f9f45e0>),\n",
       "  StructuredTool(name='power', description='Calculate base raised to the power of exponent.', args_schema={'properties': {'base': {'title': 'Base', 'type': 'number'}, 'exponent': {'title': 'Exponent', 'type': 'number'}}, 'required': ['base', 'exponent'], 'title': 'powerArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15f9f6020>),\n",
       "  StructuredTool(name='get_weather', description='Get current weather for a city.', args_schema={'properties': {'city': {'title': 'City', 'type': 'string'}}, 'required': ['city'], 'title': 'get_weatherArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15aed3b00>),\n",
       "  StructuredTool(name='get_forecast', description='Get weather forecast for a city.', args_schema={'properties': {'city': {'title': 'City', 'type': 'string'}, 'days': {'default': 3, 'title': 'Days', 'type': 'integer'}}, 'required': ['city'], 'title': 'get_forecastArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x15aed27a0>)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MultiServerMCPClient ì„¤ì • ì˜ˆì œ\n",
    "async def setup_mcp_client():\n",
    "    \"\"\"MCP í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•˜ê³  ë„êµ¬ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    # ì„œë²„ êµ¬ì„± ì •ì˜\n",
    "    server_configs = {\n",
    "        \"math\": {\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"math_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "            \"env\": {},  # í™˜ê²½ ë³€ìˆ˜ (í•„ìš”ì‹œ)\n",
    "        },\n",
    "        \"weather\": {\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"weather_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "    client = MultiServerMCPClient(server_configs)\n",
    "\n",
    "    # ë„êµ¬ ê°€ì ¸ì˜¤ê¸°\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    print(f\"âœ… {len(tools)} ê°œì˜ ë„êµ¬ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}: {tool.description}\")\n",
    "\n",
    "    return client, tools\n",
    "\n",
    "\n",
    "# í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸\n",
    "await setup_mcp_client()  # Jupyterì—ì„œ ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP ì „ì†¡ ë°©ì‹ ì‚¬ìš©\n",
    "\n",
    "ì›ê²© ì„œë²„ë‚˜ HTTP ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¡ HTTP ì „ì†¡ ë°©ì‹ ì„¤ì • ì˜ˆì œ:\n",
      "{'remote_math': {'url': 'http://localhost:8000/mcp', 'transport': 'streamable_http', 'headers': {'Authorization': 'Bearer YOUR_TOKEN'}}, 'remote_weather': {'url': 'http://api.weather.example.com/mcp', 'transport': 'streamable_http'}}\n"
     ]
    }
   ],
   "source": [
    "# HTTP ê¸°ë°˜ MCP ì„œë²„ ì„¤ì • ì˜ˆì œ\n",
    "http_server_config = {\n",
    "    \"remote_math\": {\n",
    "        \"url\": \"http://localhost:8000/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "        \"headers\": {\"Authorization\": \"Bearer YOUR_TOKEN\"},  # ì„ íƒì : ì¸ì¦ í—¤ë” ë“±\n",
    "    },\n",
    "    \"remote_weather\": {\n",
    "        \"url\": \"http://api.weather.example.com/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"ğŸ“¡ HTTP ì „ì†¡ ë°©ì‹ ì„¤ì • ì˜ˆì œ:\")\n",
    "print(http_server_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: React Agentì™€ MCP í†µí•©\n",
    "\n",
    "React AgentëŠ” ì¶”ë¡ (Reason)ê³¼ í–‰ë™(Act)ì„ ë°˜ë³µí•˜ëŠ” íŒ¨í„´ì„ êµ¬í˜„í•©ë‹ˆë‹¤. MCP ë„êµ¬ì™€ í•¨ê»˜ ì‚¬ìš©í•˜ë©´ ê°•ë ¥í•œ ì—ì´ì „íŠ¸ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– Agent Response 1:\n",
      "25ì˜ ì œê³±ì€ 625ì…ë‹ˆë‹¤.\n",
      "\n",
      "ğŸ¤– Agent Response 2:\n",
      "ì„œìš¸ì˜ í˜„ì¬ ë‚ ì”¨ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "\n",
      "- **ì˜¨ë„**: 2Â°C\n",
      "- **ë‚ ì”¨ ìƒíƒœ**: ë°”ëŒì´ ë§ì´ ë¶ˆê³  ìˆìŠµë‹ˆë‹¤.\n",
      "- **ìŠµë„**: 68%\n",
      "- **ë°”ëŒ ì†ë„**: 26 km/h\n",
      "\n",
      "ë‚ ì”¨ì— ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤!\n",
      "\n",
      "ğŸ¤– Agent Response 3:\n",
      "ì„œìš¸ì˜ ì˜¨ë„ 2Â°CëŠ” í™”ì”¨ë¡œ ë³€í™˜í•˜ë©´ 35.6Â°Fì…ë‹ˆë‹¤.\n",
      "\n",
      "âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "async def create_mcp_react_agent():\n",
    "    \"\"\"MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” React Agentë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\"\"\"\n",
    "\n",
    "    # MCP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "    server_configs = {\n",
    "        \"math\": {\"command\": \"python\", \"args\": [\"math_server.py\"], \"transport\": \"stdio\"},\n",
    "        \"weather\": {\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"weather_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    # MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„± ë° ë„êµ¬ ê°€ì ¸ì˜¤ê¸°\n",
    "    client = MultiServerMCPClient(server_configs)\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    # LLM ì„¤ì •\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # React Agent ìƒì„±\n",
    "    agent = create_react_agent(\n",
    "        llm, tools, checkpointer=InMemorySaver()  # ìƒíƒœ ì €ì¥ì„ ìœ„í•œ ì²´í¬í¬ì¸í„°\n",
    "    )\n",
    "\n",
    "    return agent, client\n",
    "\n",
    "\n",
    "# ì—ì´ì „íŠ¸ ì‚¬ìš© ì˜ˆì œ\n",
    "async def test_react_agent():\n",
    "    \"\"\"React Agent í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    agent, client = await create_mcp_react_agent()\n",
    "\n",
    "    # ëŒ€í™” ì„¤ì •\n",
    "    config = {\"configurable\": {\"thread_id\": \"test-thread-1\"}}\n",
    "\n",
    "    # ì§ˆë¬¸ 1: ìˆ˜í•™ ê³„ì‚°\n",
    "    response = await agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(\"25ì˜ ì œê³±ì€ ì–¼ë§ˆì¸ê°€ìš”?\")]}, config\n",
    "    )\n",
    "    print(\"\\nğŸ¤– Agent Response 1:\")\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "    # ì§ˆë¬¸ 2: ë‚ ì”¨ ì •ë³´\n",
    "    response = await agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(\"ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.\")]}, config\n",
    "    )\n",
    "    print(\"\\nğŸ¤– Agent Response 2:\")\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "    # ì§ˆë¬¸ 3: ë³µí•© ì§ˆë¬¸\n",
    "    response = await agent.ainvoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    \"ë§Œì•½ ì„œìš¸ì˜ ì˜¨ë„ê°€ ì„­ì”¨ë¼ë©´, í™”ì”¨ë¡œ ë³€í™˜í•˜ë©´ ì–¼ë§ˆì¸ê°€ìš”? \"\n",
    "                    \"(í™”ì”¨ = ì„­ì”¨ * 9/5 + 32)\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    )\n",
    "    print(\"\\nğŸ¤– Agent Response 3:\")\n",
    "    print(response[\"messages\"][-1].content)\n",
    "\n",
    "    # MultiServerMCPClientëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë¨\n",
    "    print(\"\\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ (Jupyterì—ì„œ)\n",
    "await test_react_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: ToolNodeì™€ MCP í†µí•©\n",
    "\n",
    "ToolNodeë¥¼ ì‚¬ìš©í•˜ë©´ ë” ì„¸ë°€í•œ ì œì–´ê°€ ê°€ëŠ¥í•œ ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš°ë¥¼ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¤– Agent: \n",
      "\n",
      "ğŸ”§ Tool executed\n",
      "\n",
      "ğŸ¤– Agent: \n",
      "\n",
      "ğŸ”§ Tool executed\n",
      "\n",
      "ğŸ¤– Agent: ì„œìš¸ì˜ í˜„ì¬ ì˜¨ë„ëŠ” 4ë„ì…ë‹ˆë‹¤. ë”°ë¼ì„œ 20ë„ì˜ ì œê³±ì„ ê³„ì‚°í•œ ê²°ê³¼ëŠ” 400ì…ë‹ˆë‹¤.\n",
      "\n",
      "âœ… ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ìƒíƒœ ì •ì˜\n",
    "@dataclass\n",
    "class AgentState:\n",
    "    \"\"\"ì—ì´ì „íŠ¸ ìƒíƒœ\"\"\"\n",
    "\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    context: Dict[str, Any] = None  # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´\n",
    "\n",
    "\n",
    "async def create_mcp_workflow():\n",
    "    \"\"\"MCP ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° ìƒì„±\"\"\"\n",
    "\n",
    "    # MCP í´ë¼ì´ì–¸íŠ¸ ì„¤ì •\n",
    "    server_configs = {\n",
    "        \"math\": {\"command\": \"python\", \"args\": [\"math_server.py\"], \"transport\": \"stdio\"},\n",
    "        \"weather\": {\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"weather_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    client = MultiServerMCPClient(server_configs)\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    # LLM ì„¤ì • (ë„êµ¬ ë°”ì¸ë”©)\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    # ì›Œí¬í”Œë¡œìš° ê·¸ë˜í”„ ìƒì„±\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # ë…¸ë“œ ì •ì˜\n",
    "    async def agent_node(state: AgentState):\n",
    "        \"\"\"LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±\"\"\"\n",
    "        response = await llm_with_tools.ainvoke(state.messages)\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # ToolNode ìƒì„±\n",
    "    tool_node = ToolNode(tools)\n",
    "\n",
    "    # ì¡°ê±´ë¶€ ë¼ìš°íŒ… í•¨ìˆ˜\n",
    "    def should_continue(state: AgentState):\n",
    "        \"\"\"ë„êµ¬ í˜¸ì¶œì´ í•„ìš”í•œì§€ í™•ì¸\"\"\"\n",
    "        last_message = state.messages[-1]\n",
    "\n",
    "        # ë„êµ¬ í˜¸ì¶œì´ ìˆìœ¼ë©´ tool_nodeë¡œ\n",
    "        if hasattr(last_message, \"tool_calls\") and last_message.tool_calls:\n",
    "            return \"tools\"\n",
    "        # ì—†ìœ¼ë©´ ì¢…ë£Œ\n",
    "        return END\n",
    "\n",
    "    # ê·¸ë˜í”„ êµ¬ì„±\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\n",
    "        \"agent\", should_continue, {\"tools\": \"tools\", END: END}\n",
    "    )\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "    # ì»´íŒŒì¼\n",
    "    app = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "    return app, client\n",
    "\n",
    "\n",
    "# ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\n",
    "async def test_workflow():\n",
    "    \"\"\"ì»¤ìŠ¤í…€ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸\"\"\"\n",
    "    app, client = await create_mcp_workflow()\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": \"workflow-test-1\"}}\n",
    "\n",
    "    # ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‹¤í–‰\n",
    "    async for event in app.astream(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    \"ì„œìš¸ì˜ ë‚ ì”¨ë¥¼ í™•ì¸í•˜ê³ , ì˜¨ë„ê°€ 20ë„ ì´ìƒì´ë©´ \"\n",
    "                    \"20ì˜ ì œê³±ì„ ê³„ì‚°í•´ì£¼ì„¸ìš”.\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        config,\n",
    "    ):\n",
    "        for key, value in event.items():\n",
    "            if key == \"agent\":\n",
    "                print(f\"\\nğŸ¤– Agent: {value['messages'][-1].content}\")\n",
    "            elif key == \"tools\":\n",
    "                print(f\"\\nğŸ”§ Tool executed\")\n",
    "\n",
    "    # MultiServerMCPClientëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë¨\n",
    "    print(\"\\nâœ… ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ (Jupyterì—ì„œ)\n",
    "await test_workflow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: ë‹¤ì¤‘ MCP ì„œë²„ ê´€ë¦¬\n",
    "\n",
    "ì—¬ëŸ¬ MCP ì„œë²„ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” ê³ ê¸‰ íŒ¨í„´ì„ ì‚´í´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ë™ì  ì„œë²„ ê´€ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì„œë²„ 'math' ì¶”ê°€ë¨\n",
      "âœ… ì„œë²„ 'weather' ì¶”ê°€ë¨\n",
      "\n",
      "ğŸš€ ì´ˆê¸°í™” ì™„ë£Œ!\n",
      "ğŸ“¦ ë¡œë“œëœ ì„œë²„: ['math', 'weather']\n",
      "ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: 6ê°œ\n",
      "\n",
      "ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\n",
      "  1. add: Add two numbers together.\n",
      "  2. multiply: Multiply two numbers.\n",
      "  3. divide: Divide two numbers.\n",
      "  4. power: Calculate base raised to the power of exponent.\n",
      "  5. get_weather: Get current weather for a city.\n",
      "  6. get_forecast: Get weather forecast for a city.\n",
      "ğŸ§¹ ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "class MCPServerManager:\n",
    "    \"\"\"MCP ì„œë²„ë¥¼ ë™ì ìœ¼ë¡œ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.server_configs = {}\n",
    "        self.client = None\n",
    "        self.tools = []\n",
    "\n",
    "    def add_server(self, name: str, config: dict):\n",
    "        \"\"\"ì„œë²„ êµ¬ì„± ì¶”ê°€\"\"\"\n",
    "        self.server_configs[name] = config\n",
    "        print(f\"âœ… ì„œë²„ '{name}' ì¶”ê°€ë¨\")\n",
    "\n",
    "    def remove_server(self, name: str):\n",
    "        \"\"\"ì„œë²„ êµ¬ì„± ì œê±°\"\"\"\n",
    "        if name in self.server_configs:\n",
    "            del self.server_configs[name]\n",
    "            print(f\"âŒ ì„œë²„ '{name}' ì œê±°ë¨\")\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ë° ë„êµ¬ ë¡œë“œ\"\"\"\n",
    "        # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬\n",
    "        self.client = None\n",
    "\n",
    "        self.client = MultiServerMCPClient(self.server_configs)\n",
    "        self.tools = await self.client.get_tools()\n",
    "\n",
    "        print(f\"\\nğŸš€ ì´ˆê¸°í™” ì™„ë£Œ!\")\n",
    "        print(f\"ğŸ“¦ ë¡œë“œëœ ì„œë²„: {list(self.server_configs.keys())}\")\n",
    "        print(f\"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(self.tools)}ê°œ\")\n",
    "\n",
    "        return self.tools\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"ì •ë¦¬ ì‘ì—…\"\"\"\n",
    "        # MultiServerMCPClientëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë¨\n",
    "        self.client = None\n",
    "        self.tools = []\n",
    "        print(\"ğŸ§¹ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "    def get_tool_by_name(self, tool_name: str):\n",
    "        \"\"\"ì´ë¦„ìœ¼ë¡œ ë„êµ¬ ì°¾ê¸°\"\"\"\n",
    "        for tool in self.tools:\n",
    "            if tool.name == tool_name:\n",
    "                return tool\n",
    "        return None\n",
    "\n",
    "    def list_tools(self):\n",
    "        \"\"\"ë„êµ¬ ëª©ë¡ ì¶œë ¥\"\"\"\n",
    "        print(\"\\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬:\")\n",
    "        for i, tool in enumerate(self.tools, 1):\n",
    "            print(f\"  {i}. {tool.name}: {tool.description}\")\n",
    "\n",
    "\n",
    "# ì„œë²„ ë§¤ë‹ˆì € ì‚¬ìš© ì˜ˆì œ\n",
    "async def demo_server_manager():\n",
    "    \"\"\"ì„œë²„ ë§¤ë‹ˆì € ë°ëª¨\"\"\"\n",
    "    manager = MCPServerManager()\n",
    "\n",
    "    # ì„œë²„ ì¶”ê°€\n",
    "    manager.add_server(\n",
    "        \"math\", {\"command\": \"python\", \"args\": [\"math_server.py\"], \"transport\": \"stdio\"}\n",
    "    )\n",
    "\n",
    "    manager.add_server(\n",
    "        \"weather\",\n",
    "        {\"command\": \"python\", \"args\": [\"weather_server.py\"], \"transport\": \"stdio\"},\n",
    "    )\n",
    "\n",
    "    # ì´ˆê¸°í™”\n",
    "    await manager.initialize()\n",
    "\n",
    "    # ë„êµ¬ ëª©ë¡ í‘œì‹œ\n",
    "    manager.list_tools()\n",
    "\n",
    "    # ì •ë¦¬\n",
    "    await manager.cleanup()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ (Jupyterì—ì„œ)\n",
    "await demo_server_manager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„ ì „ëµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ¥ ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...\n",
      "  âœ… math: ì •ìƒ (4 ë„êµ¬)\n",
      "  âœ… weather: ì •ìƒ (2 ë„êµ¬)\n",
      "\n",
      "ğŸ”„ ì—°ê²° ì‹œë„ 1/3...\n",
      "âœ… ì—°ê²° ì„±ê³µ! 6ê°œ ë„êµ¬ ë¡œë“œë¨\n",
      "\n",
      "ğŸ“Š ë„êµ¬ í˜¸ì¶œ ê²°ê³¼: {'success': True, 'result': '8.0'}\n",
      "ğŸ§¹ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "class RobustMCPClient:\n",
    "    \"\"\"ì˜¤ë¥˜ ì²˜ë¦¬ì™€ ì¬ì‹œë„ ê¸°ëŠ¥ì„ ê°–ì¶˜ ê°•ê±´í•œ MCP í´ë¼ì´ì–¸íŠ¸\"\"\"\n",
    "\n",
    "    def __init__(self, server_configs: dict, max_retries: int = 3):\n",
    "        self.server_configs = server_configs\n",
    "        self.max_retries = max_retries\n",
    "        self.client = None\n",
    "        self.failed_servers = set()\n",
    "\n",
    "    async def connect_with_retry(self) -> Optional[MultiServerMCPClient]:\n",
    "        \"\"\"ì¬ì‹œë„ ë¡œì§ì„ í¬í•¨í•œ ì—°ê²°\"\"\"\n",
    "\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                print(f\"\\nğŸ”„ ì—°ê²° ì‹œë„ {attempt + 1}/{self.max_retries}...\")\n",
    "\n",
    "                # ì‹¤íŒ¨í•œ ì„œë²„ ì œì™¸í•˜ê³  ì—°ê²° ì‹œë„\n",
    "                active_configs = {\n",
    "                    name: config\n",
    "                    for name, config in self.server_configs.items()\n",
    "                    if name not in self.failed_servers\n",
    "                }\n",
    "\n",
    "                if not active_configs:\n",
    "                    print(\"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì„œë²„ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                    return None\n",
    "\n",
    "                self.client = MultiServerMCPClient(active_configs)\n",
    "                tools = await self.client.get_tools()\n",
    "\n",
    "                print(f\"âœ… ì—°ê²° ì„±ê³µ! {len(tools)}ê°œ ë„êµ¬ ë¡œë“œë¨\")\n",
    "                return self.client\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "                if attempt < self.max_retries - 1:\n",
    "                    wait_time = 2**attempt  # ì§€ìˆ˜ ë°±ì˜¤í”„\n",
    "                    print(f\"â³ {wait_time}ì´ˆ í›„ ì¬ì‹œë„...\")\n",
    "                    await asyncio.sleep(wait_time)\n",
    "                else:\n",
    "                    print(\"âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼\")\n",
    "                    return None\n",
    "\n",
    "    async def call_tool_safe(self, tool_name: str, **kwargs):\n",
    "        \"\"\"ì•ˆì „í•œ ë„êµ¬ í˜¸ì¶œ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)\"\"\"\n",
    "        try:\n",
    "            if not self.client:\n",
    "                await self.connect_with_retry()\n",
    "\n",
    "            # ë„êµ¬ ì°¾ê¸°\n",
    "            tools = await self.client.get_tools()\n",
    "            tool = next((t for t in tools if t.name == tool_name), None)\n",
    "\n",
    "            if not tool:\n",
    "                raise ValueError(f\"ë„êµ¬ '{tool_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "            # ë„êµ¬ ì‹¤í–‰\n",
    "            result = await tool.ainvoke(kwargs)\n",
    "            return {\"success\": True, \"result\": result}\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"success\": False, \"error\": str(e)}\n",
    "\n",
    "    async def health_check(self):\n",
    "        \"\"\"ì„œë²„ ìƒíƒœ í™•ì¸\"\"\"\n",
    "        print(\"\\nğŸ¥ ì„œë²„ ìƒíƒœ í™•ì¸ ì¤‘...\")\n",
    "\n",
    "        health_status = {}\n",
    "        for server_name in self.server_configs:\n",
    "            try:\n",
    "                # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì—°ê²°\n",
    "                test_client = MultiServerMCPClient(\n",
    "                    {server_name: self.server_configs[server_name]}\n",
    "                )\n",
    "                tools = await test_client.get_tools()\n",
    "                # MultiServerMCPClientëŠ” context managerë¥¼ ì§€ì›í•˜ê±°ë‚˜ ë³„ë„ cleanupì´ í•„ìš”ì—†ì„ ìˆ˜ ìˆìŒ\n",
    "\n",
    "                health_status[server_name] = {\n",
    "                    \"status\": \"healthy\",\n",
    "                    \"tools_count\": len(tools),\n",
    "                }\n",
    "                print(f\"  âœ… {server_name}: ì •ìƒ ({len(tools)} ë„êµ¬)\")\n",
    "\n",
    "            except Exception as e:\n",
    "                health_status[server_name] = {\"status\": \"unhealthy\", \"error\": str(e)}\n",
    "                print(f\"  âŒ {server_name}: ì˜¤ë¥˜ - {e}\")\n",
    "\n",
    "        return health_status\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬\"\"\"\n",
    "        # MultiServerMCPClientëŠ” ë³„ë„ì˜ cleanupì´ í•„ìš”ì—†ì„ ìˆ˜ ìˆìŒ\n",
    "        self.client = None\n",
    "        self.failed_servers.clear()\n",
    "        print(\"ğŸ§¹ í´ë¼ì´ì–¸íŠ¸ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì œ\n",
    "async def test_robust_client():\n",
    "    \"\"\"ê°•ê±´í•œ í´ë¼ì´ì–¸íŠ¸ í…ŒìŠ¤íŠ¸\"\"\"\n",
    "\n",
    "    configs = {\n",
    "        \"math\": {\"command\": \"python\", \"args\": [\"math_server.py\"], \"transport\": \"stdio\"},\n",
    "        \"weather\": {\n",
    "            \"command\": \"python\",\n",
    "            \"args\": [\"weather_server.py\"],\n",
    "            \"transport\": \"stdio\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    client = RobustMCPClient(configs, max_retries=3)\n",
    "\n",
    "    # ìƒíƒœ í™•ì¸\n",
    "    await client.health_check()\n",
    "\n",
    "    # ì—°ê²°\n",
    "    await client.connect_with_retry()\n",
    "\n",
    "    # ì•ˆì „í•œ ë„êµ¬ í˜¸ì¶œ\n",
    "    result = await client.call_tool_safe(\"add\", a=5, b=3)\n",
    "    print(f\"\\nğŸ“Š ë„êµ¬ í˜¸ì¶œ ê²°ê³¼: {result}\")\n",
    "\n",
    "    # ì •ë¦¬\n",
    "    await client.cleanup()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ (Jupyterì—ì„œ)\n",
    "await test_robust_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 7: ì‹¤ì „ ì˜ˆì œ - ë³µì¡í•œ ì—ì´ì „íŠ¸ êµ¬ì¶•\n",
    "\n",
    "ëª¨ë“  ê°œë…ì„ ì¢…í•©í•˜ì—¬ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ë³µì¡í•œ ì—ì´ì „íŠ¸ë¥¼ êµ¬ì¶•í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "### ì˜ˆì œ: ë°ì´í„° ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… data_analysis_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# ë°ì´í„° ë¶„ì„ ì„œë²„ ìƒì„±\n",
    "data_analysis_server = '''\n",
    "#!/usr/bin/env python\n",
    "\"\"\"Data analysis MCP server.\"\"\"\n",
    "\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "from typing import Annotated, List, Dict\n",
    "import json\n",
    "import statistics\n",
    "\n",
    "mcp = FastMCP(\"Data Analysis\")\n",
    "\n",
    "@mcp.tool()\n",
    "def calculate_statistics(\n",
    "    data: Annotated[List[float], \"List of numbers\"]\n",
    ") -> Dict:\n",
    "    \"\"\"Calculate basic statistics for a dataset.\"\"\"\n",
    "    if not data:\n",
    "        return {\"error\": \"Empty dataset\"}\n",
    "    \n",
    "    return {\n",
    "        \"count\": len(data),\n",
    "        \"mean\": statistics.mean(data),\n",
    "        \"median\": statistics.median(data),\n",
    "        \"stdev\": statistics.stdev(data) if len(data) > 1 else 0,\n",
    "        \"min\": min(data),\n",
    "        \"max\": max(data)\n",
    "    }\n",
    "\n",
    "@mcp.tool()\n",
    "def detect_outliers(\n",
    "    data: Annotated[List[float], \"List of numbers\"],\n",
    "    threshold: Annotated[float, \"Z-score threshold\"] = 2.0\n",
    ") -> Dict:\n",
    "    \"\"\"Detect outliers using z-score method.\"\"\"\n",
    "    if len(data) < 3:\n",
    "        return {\"error\": \"Need at least 3 data points\"}\n",
    "    \n",
    "    mean = statistics.mean(data)\n",
    "    stdev = statistics.stdev(data)\n",
    "    \n",
    "    outliers = []\n",
    "    for i, value in enumerate(data):\n",
    "        z_score = abs((value - mean) / stdev) if stdev > 0 else 0\n",
    "        if z_score > threshold:\n",
    "            outliers.append({\"index\": i, \"value\": value, \"z_score\": z_score})\n",
    "    \n",
    "    return {\n",
    "        \"outliers\": outliers,\n",
    "        \"count\": len(outliers),\n",
    "        \"percentage\": len(outliers) / len(data) * 100\n",
    "    }\n",
    "\n",
    "@mcp.tool()\n",
    "def generate_report(\n",
    "    title: Annotated[str, \"Report title\"],\n",
    "    data: Annotated[Dict, \"Data to include in report\"]\n",
    ") -> str:\n",
    "    \"\"\"Generate a formatted analysis report.\"\"\"\n",
    "    report = f\"# {title}\\\\n\\\\n\"\n",
    "    report += f\"Generated at: {datetime.now().isoformat()}\\\\n\\\\n\"\n",
    "    \n",
    "    for section, content in data.items():\n",
    "        report += f\"## {section}\\\\n\"\n",
    "        if isinstance(content, dict):\n",
    "            for key, value in content.items():\n",
    "                report += f\"- {key}: {value}\\\\n\"\n",
    "        else:\n",
    "            report += f\"{content}\\\\n\"\n",
    "        report += \"\\\\n\"\n",
    "    \n",
    "    return report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "'''\n",
    "\n",
    "with open(\"data_analysis_server.py\", \"w\") as f:\n",
    "    f.write(data_analysis_server)\n",
    "\n",
    "print(\"âœ… data_analysis_server.py íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\n",
      "ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: 9ê°œ\n",
      "\n",
      "ğŸ“Š ì˜ˆì œ 1: íŒë§¤ ë°ì´í„° ë¶„ì„\n",
      "### ë°ì´í„° ë¶„ì„ ê²°ê³¼\n",
      "\n",
      "#### 1. ê¸°ë³¸ í†µê³„ëŸ‰\n",
      "- **ë°ì´í„° ê°œìˆ˜ (Count)**: 12\n",
      "- **í‰ê·  (Mean)**: 147.92 ì²œ ê°œ\n",
      "- **ì¤‘ì•™ê°’ (Median)**: 137.5 ì²œ ê°œ\n",
      "- **í‘œì¤€í¸ì°¨ (Standard Deviation)**: 50.97 ì²œ ê°œ\n",
      "- **ìµœì†Œê°’ (Min)**: 100.0 ì²œ ê°œ\n",
      "- **ìµœëŒ€ê°’ (Max)**: 300.0 ì²œ ê°œ\n",
      "\n",
      "#### 2. ì´ìƒì¹˜ íƒì§€\n",
      "- **ì´ìƒì¹˜ ê°œìˆ˜**: 1\n",
      "- **ì´ìƒì¹˜ ë¹„ìœ¨**: 8.33%\n",
      "- **ì´ìƒì¹˜ ê°’**: 300.0 ì²œ ê°œ\n",
      "- **ì´ìƒì¹˜ì˜ z-score**: 2.98\n",
      "\n",
      "#### 3. ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
      "- í‰ê·  íŒë§¤ëŸ‰ì€ 147.92 ì²œ ê°œë¡œ, ì¤‘ì•™ê°’ 137.5 ì²œ ê°œë³´ë‹¤ ë†’ìŠµë‹ˆë‹¤. ì´ëŠ” ë°ì´í„°ì˜ ë¶„í¬ê°€ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì³ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "- í‘œì¤€í¸ì°¨ê°€ 50.97 ì²œ ê°œë¡œ ìƒë‹¹íˆ í¬ê¸° ë•Œë¬¸ì—, íŒë§¤ëŸ‰ì˜ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤.\n",
      "- 300.0 ì²œ ê°œì˜ íŒë§¤ëŸ‰ì€ ë‹¤ë¥¸ ë°ì´í„° í¬ì¸íŠ¸ì— ë¹„í•´ ë§¤ìš° ë†’ì€ ê°’ìœ¼ë¡œ, ì´ëŠ” ì´ìƒì¹˜ë¡œ ê°„ì£¼ë©ë‹ˆë‹¤. ì´ ê°’ì€ ì „ì²´ ë°ì´í„°ì˜ í‰ê· ê³¼ ì¤‘ì•™ê°’ì— í° ì˜í–¥ì„ ë¯¸ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### 4. ë¶„ì„ ë³´ê³ ì„œ ìƒì„±\n",
      "ë³´ê³ ì„œ ìƒì„±ì— ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë³´ê³ ì„œ ë‚´ìš©ì„ ìˆ˜ë™ìœ¼ë¡œ ì‘ì„±í•˜ê² ìŠµë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "### ì›”ë³„ íŒë§¤ëŸ‰ ë¶„ì„ ë³´ê³ ì„œ\n",
      "\n",
      "**ë¶„ì„ ê°œìš”**: ë³¸ ë³´ê³ ì„œëŠ” ì›”ë³„ íŒë§¤ëŸ‰ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ê¸°ë³¸ í†µê³„ëŸ‰, ì´ìƒì¹˜ íƒì§€ ë° ì¸ì‚¬ì´íŠ¸ë¥¼ ë„ì¶œí•˜ì˜€ìŠµë‹ˆë‹¤.\n",
      "\n",
      "**ê¸°ë³¸ í†µê³„ëŸ‰**:\n",
      "- ë°ì´í„° ê°œìˆ˜: 12\n",
      "- í‰ê· : 147.92 ì²œ ê°œ\n",
      "- ì¤‘ì•™ê°’: 137.5 ì²œ ê°œ\n",
      "- í‘œì¤€í¸ì°¨: 50.97 ì²œ ê°œ\n",
      "- ìµœì†Œê°’: 100.0 ì²œ ê°œ\n",
      "- ìµœëŒ€ê°’: 300.0 ì²œ ê°œ\n",
      "\n",
      "**ì´ìƒì¹˜ íƒì§€**:\n",
      "- ì´ìƒì¹˜ ê°œìˆ˜: 1 (300.0 ì²œ ê°œ)\n",
      "- ì´ìƒì¹˜ ë¹„ìœ¨: 8.33%\n",
      "\n",
      "**ì¸ì‚¬ì´íŠ¸**:\n",
      "- íŒë§¤ëŸ‰ì˜ í‰ê· ê³¼ ì¤‘ì•™ê°’ì˜ ì°¨ì´ëŠ” ë°ì´í„°ì˜ ë¹„ëŒ€ì¹­ì„±ì„ ë‚˜íƒ€ë‚´ë©°, ì´ìƒì¹˜ê°€ ì „ì²´ ë°ì´í„°ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "- í–¥í›„ íŒë§¤ ì „ëµ ìˆ˜ë¦½ ì‹œ, ì´ìƒì¹˜ì˜ ì›ì¸ì„ ë¶„ì„í•˜ê³ , ì´ë¥¼ ë°˜ì˜í•œ ì˜ˆì¸¡ ëª¨ë¸ì„ ê°œë°œí•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "---\n",
      "\n",
      "ì´ ë³´ê³ ì„œëŠ” ë°ì´í„° ë¶„ì„ì˜ ê¸°ì´ˆì ì¸ ì´í•´ë¥¼ ë•ê¸° ìœ„í•œ ìë£Œë¡œ í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë¶„ì„ì´ë‚˜ ì§ˆë¬¸ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“ ì§€ ë§ì”€í•´ ì£¼ì„¸ìš”.\n",
      "\n",
      "ğŸ“Š ì˜ˆì œ 2: ë‘ ì§€ì  íŒë§¤ ë¹„êµ\n",
      "### ë°ì´í„°ì…‹ ë¹„êµ ë¶„ì„\n",
      "\n",
      "#### 1. í‰ê· ê³¼ ì¤‘ì•™ê°’ì˜ ì°¨ì´\n",
      "- **ì§€ì  A**:\n",
      "  - í‰ê· : 116.67\n",
      "  - ì¤‘ì•™ê°’: 117.5\n",
      "- **ì§€ì  B**:\n",
      "  - í‰ê· : 117.5\n",
      "  - ì¤‘ì•™ê°’: 117.5\n",
      "\n",
      "**ì°¨ì´ì **: \n",
      "- ì§€ì  Aì˜ í‰ê· ì´ ì¤‘ì•™ê°’ë³´ë‹¤ ì•½ê°„ ë‚®ê³ , ì§€ì  BëŠ” í‰ê· ê³¼ ì¤‘ì•™ê°’ì´ ë™ì¼í•©ë‹ˆë‹¤. ì´ëŠ” ì§€ì  Aì˜ ë°ì´í„°ê°€ ì•½ê°„ ë¹„ëŒ€ì¹­ì ì¼ ìˆ˜ ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "#### 2. ë¶„ì‚°ë„ ë¹„êµ\n",
      "- **ì§€ì  A**:\n",
      "  - í‘œì¤€í¸ì°¨: 10.80\n",
      "- **ì§€ì  B**:\n",
      "  - í‘œì¤€í¸ì°¨: 16.36\n",
      "\n",
      "**ë¹„êµ**: \n",
      "- ì§€ì  Aì˜ ë°ì´í„°ëŠ” ì§€ì  Bë³´ë‹¤ ë” ë°€ì§‘ë˜ì–´ ìˆìœ¼ë©°, ì§€ì  BëŠ” ë” ë„“ì€ ë²”ìœ„ì˜ ê°’ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ì§€ì  Bì˜ ë°ì´í„°ê°€ ë” ë³€ë™ì„±ì´ í¬ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.\n",
      "\n",
      "#### 3. ì´ìƒì¹˜ ë¹„ìœ¨\n",
      "- **ì§€ì  A**: ì´ìƒì¹˜ ì—†ìŒ (0%)\n",
      "- **ì§€ì  B**: ì´ìƒì¹˜ ì—†ìŒ (0%)\n",
      "\n",
      "**ê²°ë¡ **: ë‘ ì§€ì  ëª¨ë‘ ì´ìƒì¹˜ê°€ ì—†ìœ¼ë©°, ë°ì´í„°ê°€ ì •ìƒì ìœ¼ë¡œ ë¶„í¬í•˜ê³  ìˆìŒì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "#### 4. ì£¼ìš” ì°¨ì´ì ê³¼ ìœ ì‚¬ì \n",
      "- **ìœ ì‚¬ì **:\n",
      "  - ë‘ ì§€ì  ëª¨ë‘ ì¤‘ì•™ê°’ì´ ë™ì¼í•˜ê±°ë‚˜ ë¹„ìŠ·í•˜ë©°, ì´ìƒì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
      "  \n",
      "- **ì°¨ì´ì **:\n",
      "  - ì§€ì  AëŠ” í‰ê· ì´ ì¤‘ì•™ê°’ë³´ë‹¤ ë‚®ê³ , ì§€ì  BëŠ” í‰ê· ê³¼ ì¤‘ì•™ê°’ì´ ë™ì¼í•©ë‹ˆë‹¤.\n",
      "  - ì§€ì  BëŠ” ë” ë†’ì€ í‘œì¤€í¸ì°¨ë¥¼ ê°€ì§€ê³  ìˆì–´ ë°ì´í„°ì˜ ë³€ë™ì„±ì´ í½ë‹ˆë‹¤.\n",
      "\n",
      "#### 5. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n",
      "- **ì§€ì  A**ëŠ” ë°ì´í„°ê°€ ë” ì•ˆì •ì ì´ë©° ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì´ëŠ” ê³ ê°ì˜ ìˆ˜ìš”ê°€ ì¼ì •í•˜ê²Œ ìœ ì§€ë˜ëŠ” ê²½ìš°ì— ìœ ë¦¬í•©ë‹ˆë‹¤.\n",
      "- **ì§€ì  B**ëŠ” ë” í° ë³€ë™ì„±ì„ ë³´ì´ë¯€ë¡œ, ë§ˆì¼€íŒ… ì „ëµì´ë‚˜ ì¬ê³  ê´€ë¦¬ì—ì„œ ë” ìœ ì—°í•œ ì ‘ê·¼ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • ì‹œì¦Œì´ë‚˜ ì´ë²¤íŠ¸ì— ë”°ë¼ ìˆ˜ìš”ê°€ ê¸‰ì¦í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ì— ëŒ€í•œ ì¤€ë¹„ê°€ í•„ìš”í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë¶„ì„ì„ í†µí•´ ê° ì§€ì ì˜ íŠ¹ì„±ì„ ì´í•´í•˜ê³ , ë¹„ì¦ˆë‹ˆìŠ¤ ì „ëµì„ ìˆ˜ë¦½í•˜ëŠ” ë° ë„ì›€ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ğŸ“Š ì˜ˆì œ 3: í–¥í›„ íŠ¸ë Œë“œ ì˜ˆì¸¡\n",
      "### íŠ¸ë Œë“œ ì˜ˆì¸¡ ë³´ê³ ì„œ\n",
      "\n",
      "#### 1. íŠ¸ë Œë“œ ë°©í–¥\n",
      "- **ìƒìŠ¹**: ê³¼ê±° ë°ì´í„°ì—ì„œ ì „ë°˜ì ìœ¼ë¡œ ìƒìŠ¹í•˜ëŠ” ê²½í–¥ì´ ë³´ì…ë‹ˆë‹¤. ë§ˆì§€ë§‰ ê°’ì¸ 122ëŠ” ì´ì „ ê°’ë“¤ë³´ë‹¤ ë†’ìœ¼ë©°, í‰ê· ê°’(110.375)ë„ ìƒìŠ¹ì„¸ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.\n",
      "\n",
      "#### 2. ì˜ˆìƒ ê°’ ë²”ìœ„\n",
      "- **ì˜ˆìƒ ê°’**: ë‹¤ìŒ 3ê°œ ê¸°ê°„ì˜ ì˜ˆìƒ ê°’ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:\n",
      "  - **1ê¸°**: 125 (í˜„ì¬ ê°’ 122ì— ì•½ 3% ìƒìŠ¹)\n",
      "  - **2ê¸°**: 128 (1ê¸° ê°’ì— ì•½ 2.4% ìƒìŠ¹)\n",
      "  - **3ê¸°**: 132 (2ê¸° ê°’ì— ì•½ 3.1% ìƒìŠ¹)\n",
      "  \n",
      "- **ì˜ˆìƒ ê°’ ë²”ìœ„**: \n",
      "  - 1ê¸°: 123 - 127\n",
      "  - 2ê¸°: 126 - 130\n",
      "  - 3ê¸°: 130 - 134\n",
      "\n",
      "#### 3. ì‹ ë¢°ë„\n",
      "- **ì‹ ë¢°ë„**: ê³¼ê±° ë°ì´í„°ì—ì„œ ì´ìƒì¹˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ê³ , í‘œì¤€í¸ì°¨ê°€ 7.69ë¡œ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ì•„ ì˜ˆì¸¡ì˜ ì‹ ë¢°ë„ê°€ ë†’ìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì™¸ë¶€ ìš”ì¸ì— ë”°ë¼ ë³€ë™ì„±ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "#### 4. ì£¼ì˜ì‚¬í•­\n",
      "- **ì£¼ì˜ì‚¬í•­**: \n",
      "  - ê²½ì œì , ì‚¬íšŒì  ìš”ì¸ì— ë”°ë¼ ì˜ˆì¸¡ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - ë°ì´í„°ì˜ ì–‘ì´ ì ì–´ ì¥ê¸°ì ì¸ ì˜ˆì¸¡ì—ëŠ” í•œê³„ê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "  - ì˜ˆì¸¡ì€ ê³¼ê±° ë°ì´í„°ì— ê¸°ë°˜í•˜ë¯€ë¡œ, ë¯¸ë˜ì˜ ë¶ˆí™•ì‹¤ì„±ì„ í•­ìƒ ê³ ë ¤í•´ì•¼ í•©ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ë³´ê³ ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ í–¥í›„ ì „ëµì„ ìˆ˜ë¦½í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.\n",
      "ğŸ§¹ ì—ì´ì „íŠ¸ ì •ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ë³µì¡í•œ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸\n",
    "class DataAnalysisAgent:\n",
    "    \"\"\"MCPë¥¼ í™œìš©í•œ ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.client = None\n",
    "        self.agent = None\n",
    "        self.analysis_history = []\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"ì—ì´ì „íŠ¸ ì´ˆê¸°í™”\"\"\"\n",
    "        # MCP ì„œë²„ êµ¬ì„±\n",
    "        server_configs = {\n",
    "            \"math\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"math_server.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            },\n",
    "            \"weather\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"weather_server.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            },\n",
    "            \"data_analysis\": {\n",
    "                \"command\": \"python\",\n",
    "                \"args\": [\"data_analysis_server.py\"],\n",
    "                \"transport\": \"stdio\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "        # MCP í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "        self.client = MultiServerMCPClient(server_configs)\n",
    "        tools = await self.client.get_tools()\n",
    "\n",
    "        # LLM ì„¤ì •\n",
    "        llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "        # ì»¤ìŠ¤í…€ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "        system_prompt = \"\"\"\n",
    "        You are a professional data analyst assistant. Your role is to:\n",
    "        1. Analyze data using available tools\n",
    "        2. Identify patterns and outliers\n",
    "        3. Provide actionable insights\n",
    "        4. Generate comprehensive reports\n",
    "        \n",
    "        Always be thorough and explain your analysis clearly.\n",
    "        \"\"\"\n",
    "\n",
    "        # React Agent ìƒì„±\n",
    "        self.agent = create_react_agent(\n",
    "            llm, tools, prompt=system_prompt, checkpointer=InMemorySaver()\n",
    "        )\n",
    "\n",
    "        print(\"âœ… ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ\")\n",
    "        print(f\"ğŸ”§ ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬: {len(tools)}ê°œ\")\n",
    "\n",
    "    async def analyze_dataset(self, data: List[float], context: str = \"\"):\n",
    "        \"\"\"ë°ì´í„°ì…‹ ë¶„ì„\"\"\"\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": f\"analysis-{len(self.analysis_history)}\"}\n",
    "        }\n",
    "\n",
    "        # ë¶„ì„ ìš”ì²­ êµ¬ì„±\n",
    "        request = f\"\"\"\n",
    "        ë‹¤ìŒ ë°ì´í„°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "        ë°ì´í„°: {data}\n",
    "        \n",
    "        ë¶„ì„ ìš”êµ¬ì‚¬í•­:\n",
    "        1. ê¸°ë³¸ í†µê³„ëŸ‰ ê³„ì‚°\n",
    "        2. ì´ìƒì¹˜ íƒì§€ (z-score 2.0 ê¸°ì¤€)\n",
    "        3. ì¸ì‚¬ì´íŠ¸ ë„ì¶œ\n",
    "        4. ë¶„ì„ ë³´ê³ ì„œ ìƒì„±\n",
    "        \n",
    "        ì»¨í…ìŠ¤íŠ¸: {context if context else \"ì—†ìŒ\"}\n",
    "        \"\"\"\n",
    "\n",
    "        # ì—ì´ì „íŠ¸ ì‹¤í–‰\n",
    "        response = await self.agent.ainvoke(\n",
    "            {\"messages\": [HumanMessage(request)]}, config\n",
    "        )\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        analysis_result = {\n",
    "            \"timestamp\": datetime.now().isoformat(),\n",
    "            \"data\": data,\n",
    "            \"context\": context,\n",
    "            \"analysis\": response[\"messages\"][-1].content,\n",
    "        }\n",
    "        self.analysis_history.append(analysis_result)\n",
    "\n",
    "        return analysis_result\n",
    "\n",
    "    async def compare_datasets(\n",
    "        self,\n",
    "        dataset1: List[float],\n",
    "        dataset2: List[float],\n",
    "        labels: tuple = (\"Dataset 1\", \"Dataset 2\"),\n",
    "    ):\n",
    "        \"\"\"ë‘ ë°ì´í„°ì…‹ ë¹„êµ ë¶„ì„\"\"\"\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": f\"comparison-{len(self.analysis_history)}\"}\n",
    "        }\n",
    "\n",
    "        request = f\"\"\"\n",
    "        ë‘ ë°ì´í„°ì…‹ì„ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”:\n",
    "        \n",
    "        {labels[0]}: {dataset1}\n",
    "        {labels[1]}: {dataset2}\n",
    "        \n",
    "        ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¹„êµí•´ì£¼ì„¸ìš”:\n",
    "        1. í‰ê· ê³¼ ì¤‘ì•™ê°’ì˜ ì°¨ì´\n",
    "        2. ë¶„ì‚°ë„ ë¹„êµ\n",
    "        3. ì´ìƒì¹˜ ë¹„ìœ¨\n",
    "        4. ì£¼ìš” ì°¨ì´ì ê³¼ ìœ ì‚¬ì \n",
    "        5. ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.agent.ainvoke(\n",
    "            {\"messages\": [HumanMessage(request)]}, config\n",
    "        )\n",
    "\n",
    "        return response[\"messages\"][-1].content\n",
    "\n",
    "    async def forecast_trend(self, historical_data: List[float], periods: int = 3):\n",
    "        \"\"\"íŠ¸ë Œë“œ ì˜ˆì¸¡\"\"\"\n",
    "        config = {\n",
    "            \"configurable\": {\"thread_id\": f\"forecast-{len(self.analysis_history)}\"}\n",
    "        }\n",
    "\n",
    "        request = f\"\"\"\n",
    "        ê³¼ê±° ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–¥í›„ {periods}ê°œ ê¸°ê°„ì˜ íŠ¸ë Œë“œë¥¼ ì˜ˆì¸¡í•´ì£¼ì„¸ìš”:\n",
    "        \n",
    "        ê³¼ê±° ë°ì´í„°: {historical_data}\n",
    "        \n",
    "        ë‹¤ìŒì„ í¬í•¨í•´ì£¼ì„¸ìš”:\n",
    "        1. íŠ¸ë Œë“œ ë°©í–¥ (ìƒìŠ¹/í•˜ë½/íš¡ë³´)\n",
    "        2. ì˜ˆìƒ ê°’ ë²”ìœ„\n",
    "        3. ì‹ ë¢°ë„\n",
    "        4. ì£¼ì˜ì‚¬í•­\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.agent.ainvoke(\n",
    "            {\"messages\": [HumanMessage(request)]}, config\n",
    "        )\n",
    "\n",
    "        return response[\"messages\"][-1].content\n",
    "\n",
    "    async def cleanup(self):\n",
    "        \"\"\"ì •ë¦¬ ì‘ì—…\"\"\"\n",
    "        # MultiServerMCPClientëŠ” ìë™ìœ¼ë¡œ ì •ë¦¬ë¨\n",
    "        self.client = None\n",
    "        self.agent = None\n",
    "        print(\"ğŸ§¹ ì—ì´ì „íŠ¸ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì œ\n",
    "async def demo_data_analysis():\n",
    "    \"\"\"ë°ì´í„° ë¶„ì„ ì—ì´ì „íŠ¸ ë°ëª¨\"\"\"\n",
    "\n",
    "    agent = DataAnalysisAgent()\n",
    "    await agent.initialize()\n",
    "\n",
    "    try:\n",
    "        # ì˜ˆì œ 1: ë‹¨ì¼ ë°ì´í„°ì…‹ ë¶„ì„\n",
    "        print(\"\\nğŸ“Š ì˜ˆì œ 1: íŒë§¤ ë°ì´í„° ë¶„ì„\")\n",
    "        sales_data = [100, 120, 115, 130, 125, 140, 135, 150, 145, 160, 300, 155]\n",
    "        result = await agent.analyze_dataset(\n",
    "            sales_data, context=\"ì›”ë³„ íŒë§¤ëŸ‰ (ë‹¨ìœ„: ì²œ ê°œ)\"\n",
    "        )\n",
    "        print(result[\"analysis\"])\n",
    "\n",
    "        # ì˜ˆì œ 2: ë°ì´í„°ì…‹ ë¹„êµ\n",
    "        print(\"\\nğŸ“Š ì˜ˆì œ 2: ë‘ ì§€ì  íŒë§¤ ë¹„êµ\")\n",
    "        branch_a = [100, 110, 120, 115, 125, 130]\n",
    "        branch_b = [95, 105, 115, 120, 130, 140]\n",
    "        comparison = await agent.compare_datasets(\n",
    "            branch_a, branch_b, labels=(\"ì§€ì  A\", \"ì§€ì  B\")\n",
    "        )\n",
    "        print(comparison)\n",
    "\n",
    "        # ì˜ˆì œ 3: íŠ¸ë Œë“œ ì˜ˆì¸¡\n",
    "        print(\"\\nğŸ“Š ì˜ˆì œ 3: í–¥í›„ íŠ¸ë Œë“œ ì˜ˆì¸¡\")\n",
    "        historical = [100, 105, 103, 108, 112, 115, 118, 122]\n",
    "        forecast = await agent.forecast_trend(historical, periods=3)\n",
    "        print(forecast)\n",
    "\n",
    "    finally:\n",
    "        await agent.cleanup()\n",
    "\n",
    "\n",
    "# ì‹¤í–‰ (Jupyterì—ì„œ)\n",
    "await demo_data_analysis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
