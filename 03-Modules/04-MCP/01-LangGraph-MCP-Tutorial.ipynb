{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangGraph MCP (Model Context Protocol) 튜토리얼\n",
    "\n",
    "이 튜토리얼에서는 LangGraph와 MCP(Model Context Protocol)를 통합하여 강력한 AI 에이전트를 구축하는 방법을 배웁니다.\n",
    "\n",
    "## 학습 목표\n",
    "- MCP의 개념과 아키텍처 이해\n",
    "- MultiServerMCPClient를 사용한 다중 서버 관리\n",
    "- React Agent 및 ToolNode와 MCP 통합\n",
    "- 실전 예제를 통한 복잡한 에이전트 구축\n",
    "\n",
    "## 목차\n",
    "1. **MCP 개요 및 설치**\n",
    "2. **기본 MCP 서버 생성**\n",
    "3. **MultiServerMCPClient 설정**\n",
    "4. **React Agent와 MCP 통합**\n",
    "5. **ToolNode와 MCP 통합**\n",
    "6. **다중 MCP 서버 관리**\n",
    "7. **실전 예제 - 복잡한 에이전트 구축**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MCP 기본 개념\n",
    "\n",
    "### MCP(Model Context Protocol)란?\n",
    "\n",
    "MCP는 애플리케이션이 언어 모델에 도구와 컨텍스트를 제공하는 방법을 표준화한 오픈 프로토콜입니다.\n",
    "\n",
    "#### 주요 특징:\n",
    "- 🔧 **표준화된 도구 인터페이스**: 일관된 방식으로 도구 정의 및 사용\n",
    "- 🌐 **다양한 전송 메커니즘**: stdio, HTTP, WebSocket 등 지원\n",
    "- 🔄 **동적 도구 검색**: 런타임에 도구 자동 검색 및 로드\n",
    "- 🏗️ **확장 가능한 아키텍처**: 여러 서버를 동시에 연결 가능\n",
    "\n",
    "### 설치\n",
    "\n",
    "MCP를 사용하기 위해 필요한 패키지를 설치합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "\n",
    "# MCP\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 변수 설정\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# 비동기 호출 활성화\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "LangGraph-MCP\n"
     ]
    }
   ],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangGraph-MCP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: 기본 MCP 서버 생성\n",
    "\n",
    "MCP 서버는 도구를 제공하는 독립적인 프로세스입니다. FastMCP를 사용하여 간단한 서버를 만들어봅시다.\n",
    "\n",
    "- `server/mcp_server_local.py`\n",
    "- `server/mcp_server_rag.py`\n",
    "- `server/mcp_server_remote.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: MultiServerMCPClient 설정\n",
    "\n",
    "MultiServerMCPClient를 사용하면 여러 MCP 서버를 동시에 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiServerMCPClient 설정 예제\n",
    "async def setup_mcp_client(server_configs: List[Dict[str, Any]]):\n",
    "    \"\"\"MCP 클라이언트를 설정하고 도구를 가져옵니다.\"\"\"\n",
    "\n",
    "    # MCP 클라이언트 생성\n",
    "    client = MultiServerMCPClient(server_configs)\n",
    "\n",
    "    # 도구 가져오기\n",
    "    tools = await client.get_tools()\n",
    "\n",
    "    print(f\"✅ {len(tools)} 개의 MCP 도구가 로드되었습니다:\")\n",
    "    for tool in tools:\n",
    "        print(f\"  - {tool.name}\")\n",
    "\n",
    "    return client, tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서버 구성 정의\n",
    "server_configs = {\n",
    "    \"weather\": {\n",
    "        \"command\": \"uv\",\n",
    "        \"args\": [\"run\", \"python\", \"server/mcp_server_local.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# MCP 클라이언트 생성\n",
    "client, tools = await setup_mcp_client(server_configs=server_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# React Agent 생성\n",
    "agent = create_react_agent(\n",
    "    llm, tools, checkpointer=InMemorySaver()  # 상태 저장을 위한 체크포인터\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import astream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "response = await astream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [(\"human\", \"안녕하세요. 서울의 날씨를 알려주세요.\")]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HTTP 전송 방식 사용\n",
    "\n",
    "원격 서버나 HTTP 엔드포인트를 사용하는 경우 먼저 Remote MCP 서버를 구동해야 합니다.\n",
    "\n",
    "```bash\n",
    "uv run python server/mcp_server_remote.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HTTP 기반 MCP 서버 설정 예제\n",
    "http_server_config = {\n",
    "    \"current_time\": {\n",
    "        \"url\": \"http://127.0.0.1:8002/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# MCP 클라이언트 생성\n",
    "client, http_tools = await setup_mcp_client(server_configs=http_server_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# React Agent 생성\n",
    "agent = create_react_agent(\n",
    "    llm, http_tools, checkpointer=InMemorySaver()  # 상태 저장을 위한 체크포인터\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import astream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "response = await astream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [(\"human\", \"안녕하세요. 현재 시간을 알려주세요.\")]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MCP Inspector 사용\n",
    "\n",
    "`npx @modelcontextprotocol/inspector` 명령어를 실행하여 브라우저에서 MCP 서버를 테스트할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mcp_inspector](./assets/mcp-inspector.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 1 개의 MCP 도구가 로드되었습니다:\n",
      "  - retrieve\n"
     ]
    }
   ],
   "source": [
    "# HTTP 기반 MCP 서버 설정 예제\n",
    "http_server_config = {\n",
    "    \"rag\": {\n",
    "        \"command\": \"uv\",\n",
    "        \"args\": [\"run\", \"python\", \"server/mcp_server_rag.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# MCP 클라이언트 생성\n",
    "client, rag_tools = await setup_mcp_client(server_configs=http_server_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 설정\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "\n",
    "# React Agent 생성\n",
    "rag_agent = create_react_agent(\n",
    "    llm, rag_tools, checkpointer=InMemorySaver()  # 상태 저장을 위한 체크포인터\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "SPRi AI Brief |\n",
      "2023-12월호\n",
      "삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개\n",
      "KEY Contents\n",
      "n 삼성전자가 온디바이스에서 작동 가능하며 언어, 코드, 이미지의 3개 모델로 구성된 자체 개발 생성\n",
      "AI 모델 ‘삼성 가우스’를 공개\n",
      "n 삼성전자는 삼성 가우스를 다양한 제품에 단계적으로 탑재할 계획으로, 온디바이스 작동이 가능한\n",
      "삼성 가우스는 외부로 사용자 정보가 유출될 위험이 없다는 장점을 보유\n",
      "£언어, 코드, 이미지의 3개 모델로 구성된 삼성 가우스, 온디바이스 작동 지원\n",
      "n 삼성전자가 2023년 11월 8일 열린 ‘삼성 AI 포럼 2023’ 행사에서 자체 개발한 생성 AI 모델\n",
      "‘삼성 가우스’를 최초 공개\n",
      "∙ 정규분포 이론을 정립한 천재 수학자 가우스(Gauss)의 이름을 본뜬 삼성 가우스는 다양한 상황에\n",
      "최적화된 크기의 모델 선택이 가능\n",
      "∙ 삼성 가우스는 라이선스나 개인정보를 침해하지 않는 안전한 데이터를 통해 학습되었으며,\n",
      "온디바이스에서 작동하도록 설계되어 외부로 사용자의 정보가 유출되지 않는 장점을 보유\n",
      "∙ 삼성전자는 삼성 가우스를 활용한 온디바이스 AI 기술도 소개했으며, 생성 AI 모델을 다양한 제품에\n",
      "단계적으로 탑재할 계획\n",
      "n 삼성 가우스는 △텍스트를 생성하는 언어모델 △코드를 생성하는 코드 모델 △이미지를 생성하는\n",
      "이미지 모델의 3개 모델로 구성\n",
      "∙ 언어 모델은 클라우드와 온디바이스 대상 다양한 모델로 구성되며, 메일 작성, 문서 요약, 번역 업무의\n",
      "처리를 지원\n",
      "∙ 코드 모델 기반의 AI 코딩 어시스턴트 ‘코드아이(code.i)’는 대화형 인터페이스로 서비스를 제공하며\n",
      "사내 소프트웨어 개발에 최적화\n",
      "∙ 이미지 모델은 창의적인 이미지를 생성하고 기존 이미지를 원하는 대로 바꿀 수 있도록 지원하며\n",
      "저해상도 이미지의 고해상도 전환도 지원\n",
      "n IT 전문지 테크리퍼블릭(TechRepublic)은 온디바이스 AI가 주요 기술 트렌드로 부상했다며,\n",
      "2024년부터 가우스를 탑재한 삼성 스마트폰이 메타의 라마(Llama)2를 탑재한 퀄컴 기기 및 구글\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10\n",
      "과업에 활용되는 특수 AI로 분류했으며, 특수 AI에서는 5단계까지 달성되었으나, 범용 AI는 현재 1단계 수준\n",
      "<구글 딥마인드의 범용 AI 분류 프레임워크>\n",
      "성능 특수 AI 예시 범용 AI 예시\n",
      "0단계: AI 아님 계산기 소프트웨어, 컴파일러 아마존 메커니컬 터크\n",
      "1단계: 신진(숙련되지 않은 인간) GOFAI(Good Old Fashioned Artificial Intelligence) 챗GPT, 바드, 라마2\n",
      "스마트 스피커(애플 시리, 아마존 알렉사, 구글\n",
      "2단계: 유능(숙련된 인간의 50% 이상) 미달성\n",
      "어시스턴트), IBM 왓슨\n",
      "3단계: 전문가(숙련된 인간의 90% 이상) 문법 교정기(그래머리), 생성 이미지 모델(달리2) 미달성\n",
      "4단계: 거장(숙련된 인간의 99% 이상) 딥블루, 알파고 미달성\n",
      "5단계: 초인간(인간을 100% 능가) 알파폴드, 알파제로, 스톡피시 미달성\n",
      "☞ 출처 : Arxiv.org, Levels of AGI: Operationalizing Progress on the Path to AGI, 2023.11.04.\n",
      "16\n",
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "▹ 영국 과학혁신기술부, AI 안전 연구소 설립 발표······························································15\n",
      "▹ 구글 딥마인드, 범용 AI 모델의 기능과 동작에 대한 분류 체계 발표······························16\n",
      "▹ 갈릴레오의 LLM 환각 지수 평가에서 GPT-4가 가장 우수 ···········································17\n",
      "4. 인력/교육\n",
      "▹ 영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아·······························18\n",
      "Ⅱ\n",
      ". 주요 행사\n",
      "▹CES 2024·····························································································································19\n",
      "▹AIMLA 2024·························································································································19\n",
      "▹AAAI Conference on Artificial Intelligence··································································19\n",
      "∙ 생성 AI 개발에 필요한 컴퓨팅과 데이터 처리 요구사항을 지원하기 위해 AI 플랫폼(PAI),\n",
      "데이터베이스 솔루션, 컨테이너 서비스와 같은 클라우드 신제품도 발표\n",
      "n 알리바바 클라우드는 AI 개발을 촉진하기 위해 올해 말까지 720억 개 매개변수를 가진 통이치엔원\n",
      "모델을 오픈소스화한다는 계획도 공개\n",
      "☞ 출처 : Alibaba Cloud, Alibaba Cloud Launches Tongyi Qianwen 2.0 and Industry-specific Models to Support\n",
      "Customers Reap Benefits of Generative AI, 2023.10.31.\n",
      "n (정보 교류 활성화) 현행 개인정보보호와 데이터 규제 하에서 연구소와 정책입안자, 국제 파트너,\n",
      "학계, 시민사회 및 일반 대중과 정보 공유 채널을 구축\n",
      "∙ AI 안전성 정상회의(AI Safety Summit)에서 합의된 대로 첨단 AI 모델의 평가 후 해당 모델이 배포된\n",
      "타국의 정부 및 연구소와 평가 결과를 공유하고, 학계와 대중이 AI 시스템의 피해와 취약점을 보고할 수\n",
      "있는 명확한 절차를 수립\n",
      "☞ 출처 : Gov.uk, Introducing the AI Safety Institute, 2023.11.02.\n",
      "Venturebeat, Researchers turn to Harry Potter to make AI forget about copyrighted material, 2023.10.06.\n",
      "∙ 구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어\n",
      "기업 허깅 페이스(Hugging Face)에도 투자\n",
      "∙ 구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 AI\n",
      "시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\n",
      "☞ 출처 : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\n",
      "Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "삼성전자가 개발한 생성형 AI의 이름은 '삼성 가우스'입니다. '삼성 가우스'는 언어, 코드, 이미지의 3개 모델로 구성되어 있으며, 온디바이스에서 작동 가능하도록 설계되어 사용자 정보 유출 위험이 없는 것이 특징입니다."
     ]
    }
   ],
   "source": [
    "from langchain_teddynote.messages import astream_graph, random_uuid\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "\n",
    "_ = await astream_graph(\n",
    "    rag_agent,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"삼성전자가 개발한 생성형 AI 의 이름은? mcp 서버를 사용해서 검색해주세요.\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36mtools\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "∙ 구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어\n",
      "기업 허깅 페이스(Hugging Face)에도 투자\n",
      "∙ 구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 AI\n",
      "시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\n",
      "☞ 출처 : The Wall Street Journal, Google Commits $2 Billion in Funding to AI Startup Anthropic, 2023.10.27.\n",
      "Bloomberg, AI Startup Anthropic to Use Google Chips in Expanded Partnership, 2023.11.09.\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화\n",
      "KEY Contents\n",
      "n 구글이 앤스로픽에 최대 20억 달러 투자에 합의하고 5억 달러를 우선 투자했으며, 앤스로픽은\n",
      "구글과 클라우드 서비스 사용 계약도 체결\n",
      "n 3대 클라우드 사업자인 구글, 마이크로소프트, 아마존은 차세대 AI 모델의 대표 기업인\n",
      "앤스로픽 및 오픈AI와 협력을 확대하는 추세\n",
      "£구글, 앤스로픽에 최대 20억 달러 투자 합의 및 클라우드 서비스 제공\n",
      "n 구글이 2023년 10월 27일 앤스로픽에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억\n",
      "달러를 우선 투자하고 향후 15억 달러를 추가로 투자할 방침\n",
      "∙ 구글은 2023년 2월 앤스로픽에 이미 5억 5,000만 달러를 투자한 바 있으며, 아마존도 지난 9월\n",
      "앤스로픽에 최대 40억 달러의 투자 계획을 공개\n",
      "∙ 한편, 2023년 11월 8일 블룸버그 보도에 따르면 앤스로픽은 구글의 클라우드 서비스 사용을 위해\n",
      "4년간 30억 달러 규모의 계약을 체결\n",
      "∙ 오픈AI 창업자 그룹의 일원이었던 다리오(Dario Amodei)와 다니엘라 아모데이(Daniela Amodei)\n",
      "남매가 2021년 설립한 앤스로픽은 챗GPT의 대항마 ‘클로드(Claude)’ LLM을 개발\n",
      "n 아마존과 구글의 앤스로픽 투자에 앞서, 마이크로소프트는 차세대 AI 모델의 대표 주자인 오픈\n",
      "AI와 협력을 확대\n",
      "∙ 마이크로소프트는 오픈AI에 앞서 투자한 30억 달러에 더해 2023년 1월 추가로 100억 달러를\n",
      "투자하기로 하면서 오픈AI의 지분 49%를 확보했으며, 오픈AI는 마이크로소프트의 애저(Azure)\n",
      "클라우드 플랫폼을 사용해 AI 모델을 훈련\n",
      "£구글, 클라우드 경쟁력 강화를 위해 생성 AI 투자 확대\n",
      "n 구글은 수익률이 높은 클라우드 컴퓨팅 시장에서 아마존과 마이크로소프트를 따라잡고자 생성 AI를\n",
      "통한 기업 고객의 클라우드 지출 확대를 위해 AI 투자를 지속\n",
      "∙ 구글은 앤스로픽 외에도 AI 동영상 제작 도구를 개발하는 런웨이(Runway)와 오픈소스 소프트웨어\n",
      "기업 허깅 페이스(Hugging Face)에도 투자\n",
      "∙ 구글은 챗GPT의 기반 기술과 직접 경쟁할 수 있는 차세대 LLM ‘제미니(Gemini)’를 포함한 자체 AI\n",
      "시스템 개발에도 수십억 달러를 투자했으며, 2024년 제미니를 출시할 계획\n",
      "위험 대응 방안에 관한 산업계와 정부, 시민사회의 통찰력 확보에 도움이 될 전망으로, 포럼은 향후 몇\n",
      "달 안에 기금 지원을 위한 제안 요청을 받을 계획\n",
      "n 프런티어 모델 포럼은 출범 이후 업계 전반에 걸쳐 AI 레드팀 구성에 관한 모범사례 공유를 추진하는\n",
      "한편, 첨단 AI 모델의 취약점이나 잠재적으로 위험한 기능 및 위험 완화 관련 정보를 공유할 수\n",
      "있는 공개 절차도 개발 중\n",
      "☞ 출처: Google, Anthropic, Google, Microsoft and OpenAI announce Executive Director of the Frontier Model\n",
      "Forum and over $10 million for a new AI Safety Fund, 2023.10.25.\n",
      "1. 정책/법제 2. 기업/산업 3. 기술/연구 4. 인력/교육\n",
      "미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성\n",
      "KEY Contents\n",
      "n 구글, 앤스로픽, 마이크로소프트, 오픈AI가 참여하는 프런티어 모델 포럼이 자선단체와 함께 AI\n",
      "안전 연구를 위한 1,000만 달러 규모의 AI 안전 기금을 조성\n",
      "n 프런티어 모델 포럼은 AI 모델의 취약점을 발견하고 검증하는 레드팀 활동을 지원하기 위한\n",
      "모델 평가 기법 개발에 자금을 중점 지원할 계획\n",
      "£프런티어 모델 포럼, 자선단체와 함께 AI 안전 연구를 위한 기금 조성\n",
      "n 구글, 앤스로픽, 마이크로소프트, 오픈AI가 출범한 프런티어 모델 포럼이 2023년 10월 25일 AI 안전\n",
      "연구를 위한 기금을 조성한다고 발표\n",
      "∙ 참여사들은 맥거번 재단(Patrick J. McGovern Foundation), 데이비드 앤 루실 패커드 재단(The\n",
      "David and Lucile Packard Foundation) 등의 자선단체와 함께 AI 안전 연구를 위한 기금에\n",
      "1,000만 달러 이상을 기부\n",
      "∙ 또한 신기술의 거버넌스와 안전 분야에서 전문성을 갖춘 브루킹스 연구소 출신의 크리스 메서롤(Chris\n",
      "Meserole)을 포럼의 상무이사로 임명\n",
      "n 최근 AI 기술이 급속히 발전하면서 AI 안전에 관한 연구가 부족한 시점에, 포럼은 이러한 격차를 해소\n",
      "하기 위해 AI 안전 기금을 조성\n",
      "∙ 참여사들은 지난 7월 백악관 주재의 AI 안전 서약에서 외부자의 AI 시스템 취약점 발견과 신고를\n",
      "촉진하기로 약속했으며, 약속을 이행하기 위해 기금을 활용해 외부 연구집단의 AI 시스템 평가에\n",
      "자금을 지원할 계획\n",
      "£AI 안전 기금으로 AI 레드팀을 위한 모델 평가 기법 개발을 중점 지원할 계획\n",
      "n 프런티어 모델 포럼은 AI 안전 기금을 통해 AI 레드팀 활동을 위한 새로운 모델 평가 기법의 개발을\n",
      "중점 지원할 예정\n",
      "∙ 포럼에 따르면 AI 레드팀에 대한 자금 지원은 AI 모델의 안전과 보안 기준의 개선과 함께 AI 시스템\n",
      "위험 대응 방안에 관한 산업계와 정부, 시민사회의 통찰력 확보에 도움이 될 전망으로, 포럼은 향후 몇\n",
      "달 안에 기금 지원을 위한 제안 요청을 받을 계획\n",
      "n 프런티어 모델 포럼은 출범 이후 업계 전반에 걸쳐 AI 레드팀 구성에 관한 모범사례 공유를 추진하는\n",
      "한편, 첨단 AI 모델의 취약점이나 잠재적으로 위험한 기능 및 위험 완화 관련 정보를 공유할 수\n",
      "2023년 12월호\n",
      "Ⅰ\n",
      ". 인공지능 산업 동향 브리프\n",
      "1. 정책/법제\n",
      "▹ 미국, 안전하고 신뢰할 수 있는 AI 개발과 사용에 관한 행정명령 발표 ·························1\n",
      "▹ G7, 히로시마 AI 프로세스를 통해 AI 기업 대상 국제 행동강령에 합의···························2\n",
      "▹ 영국 AI 안전성 정상회의에 참가한 28개국, AI 위험에 공동 대응 선언···························3\n",
      "▹ 미국 법원, 예술가들이 생성 AI 기업에 제기한 저작권 소송 기각·····································4\n",
      "▹ 미국 연방거래위원회, 저작권청에 소비자 보호와 경쟁 측면의 AI 의견서 제출·················5\n",
      "▹ EU AI 법 3자 협상, 기반모델 규제 관련 견해차로 난항···················································6\n",
      "2. 기업/산업\n",
      "▹ 미국 프런티어 모델 포럼, 1,000만 달러 규모의 AI 안전 기금 조성································7\n",
      "▹ 코히어, 데이터 투명성 확보를 위한 데이터 출처 탐색기 공개 ·······································8\n",
      "▹ 알리바바 클라우드, 최신 LLM ‘통이치엔원 2.0’ 공개 ······················································9\n",
      "▹ 삼성전자, 자체 개발 생성 AI ‘삼성 가우스’ 공개 ···························································10\n",
      "▹ 구글, 앤스로픽에 20억 달러 투자로 생성 AI 협력 강화 ················································11\n",
      "▹ IDC, 2027년 AI 소프트웨어 매출 2,500억 달러 돌파 전망···········································12\n",
      "▹ 빌 게이츠, AI 에이전트로 인한 컴퓨터 사용의 패러다임 변화 전망································13\n",
      "▹ 유튜브, 2024년부터 AI 생성 콘텐츠 표시 의무화····························································14\n",
      "3. 기술/연구\n",
      "어시스턴트를 적용한 구글 픽셀(Pixel)과 경쟁할 것으로 예상\n",
      "☞ 출처 : 삼성전자, ‘삼성 AI 포럼’서 자체 개발 생성형 AI ‘삼성 가우스’ 공개, 2023.11.08.\n",
      "삼성전자, ‘삼성 개발자 콘퍼런스 코리아 2023’ 개최, 2023.11.14.\n",
      "TechRepublic, Samsung Gauss: Samsung Research Reveals Generative AI, 2023.11.08.\n",
      "10\n",
      "n IDC에 따르면 경제적 불확실성과 시장 역학의 변화에도 AI와 자동화 기술에 대한 기업들의 투자\n",
      "의지는 확고하며, 기업들은 AI 도입이 사업 성공과 경쟁우위에 필수적이라고 인식\n",
      "∙ IDC 설문조사에 따르면 향후 12개월 동안 응답자의 3분의 1은 기업이 특정 사용 사례나 응용 영역에서\n",
      "외부 AI 소프트웨어의 구매를 고려하거나 외부 AI 소프트웨어와 내부 자원의 결합을 고려\n",
      "n 한편, AI 소프트웨어 시장에 포함되지 않는 생성 AI 플랫폼과 애플리케이션은 2027년까지 283억\n",
      "달러의 매출을 창출할 전망\n",
      "☞ 출처 : IDC, IDC Forecasts Revenue for Artificial Intelligence Software Will Reach $279 Billion Worldwide in\n",
      "2027, 2023.10.31.\n",
      "12\n",
      "영국 옥스퍼드 인터넷 연구소, AI 기술자의 임금이 평균 21% 높아\n",
      "KEY Contents\n",
      "n 옥스퍼드 인터넷 연구소의 연구에 따르면 특정 기술의 경제적 가치는 다른 기술과 결합\n",
      "가능성이 높을수록 높게 평가됨\n",
      "n AI의 확산은 기술의 경제적 가치에 크게 영향을 미치며, AI 기술을 가진 근로자는 평균 21%,\n",
      "최대 40% 높은 임금을 받을 수 있음\n",
      "£AI 기술 중 머신러닝, 텐서플로우, 딥러닝의 임금 프리미엄이 높게 평가\n",
      "n 옥스퍼드 인터넷 연구소(Oxford Internet Institute)가 2023년 10월 24일 962개 기술과 2만 5천\n",
      "명을 대상으로 한 연구에서 AI를 포함한 주요 기술의 경제적 가치를 분석한 결과를 발표\n",
      "∙ 연구에 따르면 한 기술의 경제적 가치는 근로자의 여타 역량과 얼마나 잘 결합하는지를 보여주는\n",
      "‘상보성(complementarity)’에 따라 결정됨\n",
      "∙ 특정 기술은 다른 기술과 결합 가능성이 높을수록 경제적 가치가 높아지며, 일례로 데이터 분석과 같은\n",
      "기술은 여타 고부가가치 기술과 결합할 수 있어 가치가 높지만, 사진 리터칭 같은 기술은 특정 기술과만\n",
      "결합할 수 있어 가치가 낮게 평가됨\n",
      "∙ 대부분 직업은 여러 기술의 조합이 필요하며, 근로자의 재교육에서 경제적 효율성을 높이려면 기존 기술과\n",
      "신기술 간 상보성을 극대화할 필요\n",
      "n AI의 확산은 기술의 경제적 가치에 크게 영향을 미치는 요소로, AI 기술을 가진 근로자는 평균적으로\n",
      "21% 높은 임금을 획득 가능\n",
      "∙ AI 기술 중 근로자에 대한 경제적 가치(시간당 임금 증가율 기준) 측면에서 상위 5개 기술은\n",
      "머신러닝(+40%), 텐서플로우(+38%), 딥러닝(+27%), 자연어처리(+19%), 데이터 과학(+17%) 순\n",
      "<AI 기술 유형 평균 기술 대비 갖는 임금 프리미엄>\n",
      "☞ 출처 : Oxford Internet Institute, AI comes out on top: Oxford Study identifies the economic value of specific skills, 2023.10.24.\n",
      "18\n",
      "==================================================\n",
      "🔄 Node: \u001b[1;36magent\u001b[0m 🔄\n",
      "- - - - - - - - - - - - - - - - - - - - - - - - - \n",
      "구글은 Anthropic에 최대 20억 달러를 투자하기로 합의했으며, 이 중 5억 달러를 우선 투자했습니다. 또한 Anthropic은 구글과 클라우드 서비스 사용 계약도 체결했습니다."
     ]
    }
   ],
   "source": [
    "_ = await astream_graph(\n",
    "    rag_agent,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"구글이 Anthropic 에 투자하기로 한 금액을 검색해줘\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: React Agent와 MCP 통합\n",
    "\n",
    "React Agent는 추론(Reason)과 행동(Act)을 반복하는 패턴을 구현합니다. MCP 도구와 함께 사용하면 강력한 에이전트를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_mcp_react_agent(server_configs: dict):\n",
    "    \"\"\"MCP 도구를 사용하는 React Agent를 생성합니다.\"\"\"\n",
    "\n",
    "    # MCP 클라이언트 생성 및 도구 가져오기\n",
    "    client, tools = await setup_mcp_client(server_configs=server_configs)\n",
    "\n",
    "    # LLM 설정\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "    # React Agent 생성\n",
    "    agent = create_react_agent(\n",
    "        llm, tools, checkpointer=InMemorySaver()  # 상태 저장을 위한 체크포인터\n",
    "    )\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP 서버 Config 설정\n",
    "server_configs = {\n",
    "    \"weather\": {\n",
    "        \"command\": \"uv\",\n",
    "        \"args\": [\"run\", \"python\", \"server/mcp_server_local.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"current_time\": {\n",
    "        \"url\": \"http://127.0.0.1:8002/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    },\n",
    "}\n",
    "\n",
    "# MCP ReAct Agent 생성\n",
    "agent = await create_mcp_react_agent(server_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_teddynote.messages import random_uuid, astream_graph\n",
    "\n",
    "\n",
    "config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "await astream_graph(\n",
    "    agent, inputs={\"messages\": [(\"human\", \"현재 시간을 알려주세요\")]}, config=config\n",
    ")\n",
    "\n",
    "await astream_graph(\n",
    "    agent,\n",
    "    inputs={\"messages\": [(\"human\", \"현재 서울의 날씨도 알려주세요\")]},\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: ToolNode와 MCP 통합\n",
    "\n",
    "ToolNode를 사용하면 더 세밀한 제어가 가능한 커스텀 워크플로우를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_teddynote.graphs import visualize_graph\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing import Annotated, List, Dict, Any\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import TypedDict\n",
    "from langchain_tavily import TavilySearch\n",
    "\n",
    "\n",
    "# 상태 정의\n",
    "class AgentState(TypedDict):\n",
    "    \"\"\"에이전트 상태\"\"\"\n",
    "\n",
    "    messages: Annotated[List[BaseMessage], add_messages]\n",
    "    context: Dict[str, Any] = None  # 추가 컨텍스트 정보\n",
    "\n",
    "\n",
    "async def create_mcp_workflow(server_configs: dict):\n",
    "    \"\"\"MCP 도구를 사용하는 커스텀 워크플로우 생성\"\"\"\n",
    "\n",
    "    # MCP 클라이언트 생성\n",
    "    client, tools = await setup_mcp_client(server_configs=server_configs)\n",
    "\n",
    "    # Tavily 검색 도구 추가\n",
    "    tool = TavilySearch(max_results=2)\n",
    "    tools.append(tool)\n",
    "\n",
    "    # LLM 설정 (도구 바인딩)\n",
    "    llm = ChatOpenAI(model=\"gpt-4.1-mini\", temperature=0)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "    # 워크플로우 그래프 생성\n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    # 노드 정의\n",
    "    async def agent_node(state: AgentState):\n",
    "        \"\"\"LLM을 호출하여 응답 생성\"\"\"\n",
    "        response = await llm_with_tools.ainvoke(state[\"messages\"])\n",
    "        return {\"messages\": [response]}\n",
    "\n",
    "    # ToolNode 생성\n",
    "    tool_node = ToolNode(tools)\n",
    "\n",
    "    # 그래프 구성\n",
    "    workflow.add_node(\"agent\", agent_node)\n",
    "    workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "    workflow.add_edge(START, \"agent\")\n",
    "    workflow.add_conditional_edges(\"agent\", tools_condition)\n",
    "    workflow.add_edge(\"tools\", \"agent\")\n",
    "    workflow.add_edge(\"agent\", END)\n",
    "\n",
    "    # 컴파일\n",
    "    app = workflow.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "    visualize_graph(app)\n",
    "\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP 서버 Config 설정\n",
    "server_configs = {\n",
    "    \"weather\": {\n",
    "        \"command\": \"uv\",\n",
    "        \"args\": [\"run\", \"python\", \"server/mcp_server_local.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"current_time\": {\n",
    "        \"url\": \"http://127.0.0.1:8002/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_app = await create_mcp_workflow(server_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = await astream_graph(\n",
    "    mcp_app, inputs={\"messages\": [(\"human\", \"현재 시간을 알려주세요\")]}, config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = await astream_graph(\n",
    "    mcp_app,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            (\"human\", \"오늘 뉴스를 검색해주세요. 검색시 시간을 조회한 뒤 처리하세요.\")\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: 외부 MCP 서버에서 3rd Party 도구 사용하기\n",
    "\n",
    "**Smithery AI란?**\n",
    "\n",
    "- 사이트: https://smithery.ai/\n",
    "\n",
    "- Smithery AI는 AI 에이전트 서비스의 허브 역할을 하는 플랫폼입니다. \n",
    "\n",
    "에이전트형 AI(예: 대형 언어 모델)가 외부 도구나 정보와 효율적으로 연결될 수 있도록 설계된 MCP 서버들을 검색하고 배포하는 역할을 수행합니다. 즉, AI가 다양한 외부 서비스와 손쉽게 통신할 수 있게 하는 중개자이자 생태계 허브입니다.\n",
    "\n",
    "이 모든 서비스의 연결은 **MCP(Model Context Protocol)** 표준 프로토콜을 따릅니다. 이를 통해 AI가 검색, 프로그래밍, 파일 관리, 다양한 API 연동 등 여러 외부 기능을 하나의 허브(플랫폼)만으로 편리하게 활용할 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCP 서버 Config 설정\n",
    "server_configs = {\n",
    "    \"weather\": {\n",
    "        \"command\": \"uv\",\n",
    "        \"args\": [\"run\", \"python\", \"server/mcp_server_local.py\"],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "    \"current_time\": {\n",
    "        \"url\": \"http://127.0.0.1:8002/mcp\",\n",
    "        \"transport\": \"streamable_http\",\n",
    "    },\n",
    "    \"context7-mcp\": {\n",
    "        \"command\": \"npx\",\n",
    "        \"args\": [\n",
    "            \"-y\",\n",
    "            \"@smithery/cli@latest\",\n",
    "            \"run\",\n",
    "            \"@upstash/context7-mcp\",\n",
    "            \"--key\",\n",
    "            \"7c5b4b8f-cb2a-4c2b-b0e0-d3cc49fc7a85\",\n",
    "        ],\n",
    "        \"transport\": \"stdio\",\n",
    "    },\n",
    "}\n",
    "\n",
    "mcp_app = await create_mcp_workflow(server_configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await astream_graph(\n",
    "    mcp_app,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"최신 LangGraph 도큐먼트에서 ReAct Agent 관련 내용을 검색하세요. 그런 다음 Tavily 검색을 수행하는 ReAct Agent를 생성하세요. 사용 LLM=gpt-4.1-mini\",\n",
    "            )\n",
    "        ]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
