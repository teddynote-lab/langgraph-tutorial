{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c45936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.postgres import PostgresStore\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import os\n",
    "\n",
    "# í™˜ê²½ë³€ìˆ˜ ì„¤ì •\n",
    "POSTGRES_USER = os.getenv(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.getenv(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_HOST = os.getenv(\"POSTGRES_HOST\")\n",
    "POSTGRES_PORT = os.getenv(\"POSTGRES_PORT\")\n",
    "POSTGRES_DB = os.getenv(\"POSTGRES_DB\")\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë¬¸ìì—´ ìƒì„±\n",
    "DB_URI = f\"postgres://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{POSTGRES_HOST}:{POSTGRES_PORT}/{POSTGRES_DB}?sslmode=require\"\n",
    "\n",
    "# ì“°ê¸° ì„¤ì •\n",
    "write_config = {\"configurable\": {\"thread_id\": \"1\", \"checkpoint_ns\": \"test1\"}}\n",
    "\n",
    "# ì½ê¸° ì„¤ì •\n",
    "read_config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„¤ì •\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    checkpointer.setup()\n",
    "    store.setup()\n",
    "\n",
    "    checkpoint = {\n",
    "        \"v\": 4,\n",
    "        \"ts\": datetime.now().isoformat(),\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"channel_values\": {\"my_key\": \"teddy\", \"node\": \"node\"},\n",
    "        \"channel_versions\": {\"__start__\": 2, \"my_key\": 3, \"start:node\": 3, \"node\": 3},\n",
    "        \"versions_seen\": {\n",
    "            \"__input__\": {},\n",
    "            \"__start__\": {\"__start__\": 1},\n",
    "            \"node\": {\"start:node\": 2},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    checkpointer.put(\n",
    "        write_config,\n",
    "        checkpoint,\n",
    "        {\"step\": -1, \"source\": \"input\", \"parents\": {}, \"user_id\": \"1\"},\n",
    "        {},\n",
    "    )\n",
    "\n",
    "    # ëª©ë¡ ì¡°íšŒ\n",
    "    print(list(checkpointer.list(read_config)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95ac651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.memory import create_memory_extractor\n",
    "\n",
    "memory_extractor = create_memory_extractor(model=\"gpt-4.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6eda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.base import BaseStore\n",
    "from typing import Any\n",
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig,\n",
    "    *,\n",
    "    store: BaseStore,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Call the LLM model and manage user memory.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): The current state containing messages.\n",
    "        config (RunnableConfig): The runnable configuration.\n",
    "        store (BaseStore): The memory store.\n",
    "    \"\"\"\n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ user_id ì¶”ì¶œ\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # ìœ ì €ì˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([f\"{memory.key}: {memory.value}\" for memory in memories])\n",
    "    system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ê¸°ì–µ ìš”ì²­ ì‹œ ë©”ëª¨ë¦¬ ì €ì¥\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"remember\" in last_message.content.lower():\n",
    "        result = memory_extractor.invoke({\"input\": str(state[\"messages\"][-1].content)})\n",
    "        for memory in result.memories:\n",
    "            print(memory)\n",
    "            print(\"-\" * 100)\n",
    "            store.put(namespace, str(uuid.uuid4()), {memory.key: memory.value})\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202f4f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # ê·¸ë˜í”„ ìƒì„±\n",
    "    builder = StateGraph(MessagesState)\n",
    "    builder.add_node(\"call_model\", call_model)\n",
    "    builder.add_edge(START, \"call_model\")\n",
    "\n",
    "    # ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "    graph_with_memory = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store,\n",
    "    )\n",
    "\n",
    "    def run_graph(\n",
    "        msg,\n",
    "        thread_id,\n",
    "        user_id,\n",
    "    ):\n",
    "        config = {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": thread_id,\n",
    "                \"user_id\": user_id,\n",
    "            }\n",
    "        }\n",
    "        print(f\"\\n[UserğŸ™‹] {msg}\")\n",
    "        stream_graph(\n",
    "            graph_with_memory,\n",
    "            inputs={\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "            config=config,\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\", \"1\", \"someone\")\n",
    "\n",
    "    run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\", \"2\", \"someone\")\n",
    "\n",
    "    run_graph(\"ë‚´ ì´ë¦„ì€ í…Œë””ì•¼ remember\", \"3\", \"someone\")\n",
    "\n",
    "    run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\", \"100\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca37f016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
