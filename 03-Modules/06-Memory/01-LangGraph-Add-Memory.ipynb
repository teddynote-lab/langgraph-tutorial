{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 LangGraph 메모리 시스템 완벽 가이드\n",
    "\n",
    "## 📚 개요\n",
    "\n",
    "AI 애플리케이션이 진정한 가치를 제공하려면 **메모리(Memory)**가 필수적입니다. LangGraph는 두 가지 강력한 메모리 시스템을 제공합니다:\n",
    "\n",
    "1. **단기 메모리(Short-term Memory)**: 대화 세션 내에서 컨텍스트 유지\n",
    "2. **장기 메모리(Long-term Memory)**: 세션을 넘어 사용자별 정보 저장\n",
    "\n",
    "## 🎯 학습 목표\n",
    "\n",
    "이 튜토리얼을 완료하면 다음을 마스터하게 됩니다:\n",
    "\n",
    "1. **단기 메모리** 구현 - Checkpointer를 활용한 대화 지속성\n",
    "2. **장기 메모리** 구축 - Store를 활용한 영구 데이터 저장\n",
    "3. **메모리 관리** 전략 - 메시지 트리밍, 요약, 삭제\n",
    "4. **시맨틱 검색** - 임베딩 기반 메모리 검색\n",
    "5. **프로덕션 배포** - PostgreSQL, Redis 등 실제 환경 적용\n",
    "\n",
    "## 🔑 핵심 개념 미리보기\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│                  LangGraph Memory System                  │\n",
    "├──────────────────────────┬──────────────────────────────┤\n",
    "│    Short-term Memory      │      Long-term Memory         │\n",
    "├──────────────────────────┼──────────────────────────────┤\n",
    "│ • Thread-level            │ • User-level                  │\n",
    "│ • Checkpointer            │ • Store                       │\n",
    "│ • Multi-turn chats        │ • Persistent data             │\n",
    "│ • Session context         │ • Cross-session               │\n",
    "└──────────────────────────┴──────────────────────────────┘\n",
    "```\n",
    "\n",
    "## 💡 중요 원칙\n",
    "\n",
    "> **\"메모리는 AI 에이전트를 단순한 도구에서 지능적인 파트너로 변화시킵니다\"**\n",
    "> \n",
    "> _Memory transforms AI agents from simple tools to intelligent partners_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지 임포트\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 환경 변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# API 키 설정\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"your-api-key\")\n",
    "\n",
    "print(\"✅ 환경 설정 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: 단기 메모리 (Short-term Memory) 🎯\n",
    "\n",
    "## 1.1 단기 메모리란?\n",
    "\n",
    "단기 메모리는 **대화 세션 내에서** 컨텍스트를 유지하는 메커니즘입니다. 이는 다음과 같은 특징을 가집니다:\n",
    "\n",
    "- **Thread 기반**: 각 대화는 고유한 thread_id로 식별\n",
    "- **Checkpointer 사용**: 상태를 저장하고 복원\n",
    "- **Multi-turn 대화**: 이전 대화 내용을 기억\n",
    "\n",
    "### 핵심 컴포넌트: Checkpointer\n",
    "\n",
    "Checkpointer는 그래프의 상태를 저장하고 복원하는 역할을 합니다. 개발 환경에서는 `InMemorySaver`를, 프로덕션에서는 데이터베이스 기반 Checkpointer를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Checkpointer 생성 - 메모리에 상태를 저장\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "\n",
    "# 간단한 챗봇 그래프 생성\n",
    "def call_model(state: MessagesState):\n",
    "    \"\"\"Call the LLM with the current messages\"\"\"\n",
    "    # 현재 메시지로 LLM 호출\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "    # 응답을 메시지 리스트에 추가\n",
    "    return {\"messages\": response}\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", END)\n",
    "\n",
    "# Checkpointer와 함께 컴파일 - 핵심!\n",
    "graph = builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"✅ 단기 메모리가 활성화된 그래프 생성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 단기 메모리 실습: Multi-turn 대화\n",
    "\n",
    "이제 같은 thread에서 여러 번 대화를 나누며 봇이 이전 대화를 기억하는지 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thread ID 설정 - 대화 세션 식별자\n",
    "config = {\"configurable\": {\"thread_id\": \"conversation_1\"}}  # 고유한 대화 식별자\n",
    "\n",
    "# 첫 번째 메시지 - 자기소개\n",
    "print(\"👤 User: 안녕! 나는 철수야\")\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"안녕! 나는 철수야\"}]},\n",
    "    config,  # thread_id 전달\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "# 두 번째 메시지 - 이름 확인\n",
    "print(\"👤 User: 내 이름이 뭐라고 했지?\")\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"내 이름이 뭐라고 했지?\"}]},\n",
    "    config,  # 같은 thread_id 사용\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\\n\")\n",
    "\n",
    "# 다른 thread로 테스트 - 메모리 분리 확인\n",
    "config_2 = {\"configurable\": {\"thread_id\": \"conversation_2\"}}\n",
    "\n",
    "print(\"--- 새로운 대화 세션 ---\")\n",
    "print(\"👤 User: 내 이름이 뭐야?\")\n",
    "result = graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"내 이름이 뭐야?\"}]},\n",
    "    config_2,  # 다른 thread_id\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\")\n",
    "print(\"\\n💡 다른 thread에서는 이전 대화를 기억하지 못합니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 프로덕션 환경: PostgreSQL Checkpointer\n",
    "\n",
    "실제 서비스에서는 데이터베이스 기반 Checkpointer를 사용해야 합니다. 여기서는 PostgreSQL 예제를 보여드립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostgreSQL Checkpointer 예제 (실제 실행 시 DB 연결 필요)\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def create_production_graph():\n",
    "    \"\"\"Create a production-ready graph with PostgreSQL checkpointer\"\"\"\n",
    "\n",
    "    # 실제 환경에서는 아래 주석을 해제하고 사용\n",
    "    from langgraph.checkpoint.postgres import PostgresSaver\n",
    "\n",
    "    DB_URI = \"postgresql://postgres:postgres@localhost:5432/mydb\"\n",
    "\n",
    "    with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "        # 첫 실행 시 테이블 생성\n",
    "        # checkpointer.setup()\n",
    "\n",
    "        builder = StateGraph(MessagesState)\n",
    "        builder.add_node(\"call_model\", call_model)\n",
    "        builder.add_edge(START, \"call_model\")\n",
    "        builder.add_edge(\"call_model\", END)\n",
    "\n",
    "        graph = builder.compile(checkpointer=checkpointer)\n",
    "        return graph\n",
    "\n",
    "    print(\"📝 프로덕션 환경 코드 예제:\")\n",
    "    print(\n",
    "        \"\"\"\n",
    "    DB_URI = \"postgresql://user:pass@host:port/db\"\n",
    "    \n",
    "    with PostgresSaver.from_conn_string(DB_URI) as checkpointer:\n",
    "        graph = builder.compile(checkpointer=checkpointer)\n",
    "    \"\"\"\n",
    "    )\n",
    "    return None\n",
    "\n",
    "\n",
    "create_production_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Subgraph에서의 메모리\n",
    "\n",
    "서브그래프를 사용할 때는 부모 그래프에만 Checkpointer를 설정하면 자동으로 전파됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class SubgraphState(TypedDict):\n",
    "    \"\"\"State for subgraph example\"\"\"\n",
    "\n",
    "    message: str\n",
    "    counter: int\n",
    "\n",
    "\n",
    "# 서브그래프 생성\n",
    "def create_subgraph():\n",
    "    \"\"\"Create a subgraph\"\"\"\n",
    "\n",
    "    def subgraph_node(state: SubgraphState):\n",
    "        # 카운터 증가\n",
    "        return {\n",
    "            \"message\": state[\"message\"] + \" (서브그래프 처리)\",\n",
    "            \"counter\": state[\"counter\"] + 1,\n",
    "        }\n",
    "\n",
    "    subgraph_builder = StateGraph(SubgraphState)\n",
    "    subgraph_builder.add_node(\"process\", subgraph_node)\n",
    "    subgraph_builder.add_edge(START, \"process\")\n",
    "    subgraph_builder.add_edge(\"process\", END)\n",
    "\n",
    "    # 서브그래프는 checkpointer 없이 컴파일\n",
    "    return subgraph_builder.compile()\n",
    "\n",
    "\n",
    "# 부모 그래프 생성\n",
    "def main_node(state: SubgraphState):\n",
    "    \"\"\"Main graph node\"\"\"\n",
    "    return {\n",
    "        \"message\": state[\"message\"] + \" (메인 처리)\",\n",
    "        \"counter\": state[\"counter\"] + 10,\n",
    "    }\n",
    "\n",
    "\n",
    "# 서브그래프 생성\n",
    "subgraph = create_subgraph()\n",
    "\n",
    "# 메인 그래프 구성\n",
    "main_builder = StateGraph(SubgraphState)\n",
    "main_builder.add_node(\"main\", main_node)\n",
    "main_builder.add_node(\"subgraph\", subgraph)  # 서브그래프를 노드로 추가\n",
    "\n",
    "main_builder.add_edge(START, \"main\")\n",
    "main_builder.add_edge(\"main\", \"subgraph\")\n",
    "main_builder.add_edge(\"subgraph\", END)\n",
    "\n",
    "# 부모 그래프만 checkpointer와 함께 컴파일\n",
    "parent_checkpointer = InMemorySaver()\n",
    "parent_graph = main_builder.compile(checkpointer=parent_checkpointer)\n",
    "\n",
    "# 실행\n",
    "result = parent_graph.invoke(\n",
    "    {\"message\": \"시작\", \"counter\": 0}, {\"configurable\": {\"thread_id\": \"sub_test\"}}\n",
    ")\n",
    "\n",
    "print(f\"✅ 서브그래프 실행 결과:\")\n",
    "print(f\"  메시지: {result['message']}\")\n",
    "print(f\"  카운터: {result['counter']}\")\n",
    "print(\"\\n💡 부모 그래프의 checkpointer가 서브그래프에도 자동 적용됩니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 장기 메모리 (Long-term Memory) 💾\n",
    "\n",
    "## 2.1 장기 메모리란?\n",
    "\n",
    "장기 메모리는 **세션을 넘어서** 사용자별 또는 애플리케이션 레벨의 데이터를 저장합니다:\n",
    "\n",
    "- **사용자 프로필**: 선호도, 설정, 개인 정보\n",
    "- **대화 히스토리**: 과거 상호작용 기록\n",
    "- **학습된 정보**: 시스템이 시간이 지남에 따라 학습한 내용\n",
    "\n",
    "### 핵심 컴포넌트: Store\n",
    "\n",
    "Store는 key-value 형식으로 데이터를 영구 저장하는 시스템입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.store.memory import InMemoryStore\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.store.base import BaseStore\n",
    "import uuid\n",
    "\n",
    "# 메모리 스토어 생성\n",
    "store = InMemoryStore()\n",
    "\n",
    "\n",
    "# 사용자 정보를 저장하는 그래프\n",
    "class UserState(MessagesState):\n",
    "    \"\"\"State with user context\"\"\"\n",
    "\n",
    "    user_id: str\n",
    "\n",
    "\n",
    "def chat_with_memory(\n",
    "    state: UserState, config: RunnableConfig, *, store: BaseStore  # store 주입\n",
    "):\n",
    "    \"\"\"Chat function with long-term memory\"\"\"\n",
    "\n",
    "    # 사용자 ID 가져오기\n",
    "    user_id = config[\"configurable\"].get(\"user_id\", \"default_user\")\n",
    "\n",
    "    # 네임스페이스 정의 - 사용자별 메모리 분리\n",
    "    namespace = (\"users\", user_id)\n",
    "\n",
    "    # 마지막 메시지 확인\n",
    "    last_message = state[\"messages\"][-1]\n",
    "\n",
    "    # \"기억해\" 키워드가 있으면 저장\n",
    "    if \"기억해\" in last_message.content:\n",
    "        # 메모리에 저장할 내용 추출\n",
    "        memory_content = last_message.content.replace(\"기억해:\", \"\").strip()\n",
    "        # Store에 저장\n",
    "        store.put(namespace, str(uuid.uuid4()), {\"memory\": memory_content})\n",
    "\n",
    "        return {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"알겠습니다. '{memory_content}'를 기억하겠습니다.\",\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    # \"뭐 기억하고 있어?\" 키워드가 있으면 조회\n",
    "    elif \"뭐 기억하고 있어\" in last_message.content:\n",
    "        # 저장된 메모리 검색\n",
    "        memories = store.search(namespace, query=\"*\")  # 모든 메모리 조회\n",
    "\n",
    "        if memories:\n",
    "            memory_list = [item.value[\"memory\"] for item in memories]\n",
    "            response = \"제가 기억하고 있는 내용:\\n\" + \"\\n\".join(\n",
    "                f\"• {m}\" for m in memory_list\n",
    "            )\n",
    "        else:\n",
    "            response = \"아직 기억하고 있는 내용이 없습니다.\"\n",
    "\n",
    "        return {\"messages\": [{\"role\": \"assistant\", \"content\": response}]}\n",
    "\n",
    "    # 일반 대화\n",
    "    else:\n",
    "        # 기존 메모리를 컨텍스트로 사용\n",
    "        memories = store.search(namespace, query=\"*\")\n",
    "        context = \"\"\n",
    "        if memories:\n",
    "            context = \"\\n\".join([item.value[\"memory\"] for item in memories])\n",
    "            system_prompt = f\"당신은 도움이 되는 어시스턴트입니다. 사용자에 대해 알고 있는 정보: {context}\"\n",
    "        else:\n",
    "            system_prompt = \"당신은 도움이 되는 어시스턴트입니다.\"\n",
    "\n",
    "        # LLM 호출\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "        response = llm.invoke(messages)\n",
    "\n",
    "        return {\"messages\": response}\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "memory_builder = StateGraph(UserState)\n",
    "memory_builder.add_node(\"chat\", chat_with_memory)\n",
    "memory_builder.add_edge(START, \"chat\")\n",
    "memory_builder.add_edge(\"chat\", END)\n",
    "\n",
    "# Store와 Checkpointer 모두 사용\n",
    "memory_graph = memory_builder.compile(\n",
    "    checkpointer=InMemorySaver(), store=store  # 단기 메모리  # 장기 메모리\n",
    ")\n",
    "\n",
    "print(\"✅ 장기 메모리가 활성화된 그래프 생성 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 장기 메모리 실습: 세션 간 정보 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫 번째 세션 - 정보 저장\n",
    "config_session1 = {\"configurable\": {\"thread_id\": \"session_1\", \"user_id\": \"user_123\"}}\n",
    "\n",
    "print(\"=== 세션 1: 정보 저장 ===\")\n",
    "print(\"\\n👤 User: 기억해: 내 이름은 김철수이고 개발자야\")\n",
    "result = memory_graph.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": \"기억해: 내 이름은 김철수이고 개발자야\"}\n",
    "        ]\n",
    "    },\n",
    "    config_session1,\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n👤 User: 기억해: 나는 파이썬을 좋아해\")\n",
    "result = memory_graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"기억해: 나는 파이썬을 좋아해\"}]},\n",
    "    config_session1,\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\")\n",
    "\n",
    "# 두 번째 세션 - 다른 thread_id지만 같은 user_id\n",
    "config_session2 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session_2\",  # 다른 세션\n",
    "        \"user_id\": \"user_123\",  # 같은 사용자\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n=== 세션 2: 새로운 대화 (다른 thread_id) ===\")\n",
    "print(\"\\n👤 User: 뭐 기억하고 있어?\")\n",
    "result = memory_graph.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"뭐 기억하고 있어?\"}]}, config_session2\n",
    ")\n",
    "print(f\"🤖 Bot: {result['messages'][-1].content}\")\n",
    "\n",
    "print(\"\\n💡 다른 세션에서도 사용자 정보를 기억합니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Tool에서 메모리 접근\n",
    "\n",
    "에이전트의 도구(Tool)에서도 메모리에 접근할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "# Tool에서 State 접근 예제\n",
    "class AgentState(MessagesState):\n",
    "    \"\"\"State for agent with tools\"\"\"\n",
    "\n",
    "    user_preference: str\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_user_preference(\n",
    "    state: Annotated[AgentState, InjectedState],  # State 주입\n",
    ") -> str:\n",
    "    \"\"\"Get user preference from state\"\"\"\n",
    "    preference = state.get(\"user_preference\", \"없음\")\n",
    "    return f\"사용자 선호도: {preference}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def update_user_preference(\n",
    "    new_preference: str, state: Annotated[AgentState, InjectedState]\n",
    ") -> str:\n",
    "    \"\"\"Update user preference in state\"\"\"\n",
    "    # Tool에서 state 업데이트는 Command를 통해 수행\n",
    "    return f\"선호도를 '{new_preference}'로 업데이트했습니다.\"\n",
    "\n",
    "\n",
    "# 도구 사용 예제\n",
    "def agent_with_tools(state: AgentState):\n",
    "    \"\"\"Agent that can use tools\"\"\"\n",
    "    # 여기서는 간단한 예제만 보여줌\n",
    "    last_message = state[\"messages\"][-1].content\n",
    "\n",
    "    if \"선호도\" in last_message:\n",
    "        # Tool 호출 시뮬레이션\n",
    "        tool_result = get_user_preference.invoke({\"state\": state})\n",
    "        return {\"messages\": [{\"role\": \"assistant\", \"content\": tool_result}]}\n",
    "\n",
    "    return {\"messages\": [{\"role\": \"assistant\", \"content\": \"무엇을 도와드릴까요?\"}]}\n",
    "\n",
    "\n",
    "print(\"✅ Tool에서 메모리 접근 패턴 정의 완료!\")\n",
    "print(\"\\n💡 InjectedState를 사용하여 Tool에서 state에 접근할 수 있습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 메모리 관리 전략 🔧\n",
    "\n",
    "## 3.1 메시지 트리밍 (Trimming)\n",
    "\n",
    "긴 대화에서 LLM의 컨텍스트 윈도우 제한을 관리하기 위해 메시지를 트리밍합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import trim_messages, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "# 메시지 트리밍 예제\n",
    "def demonstrate_trimming():\n",
    "    \"\"\"Demonstrate message trimming strategies\"\"\"\n",
    "\n",
    "    # 긴 대화 히스토리 시뮬레이션\n",
    "    messages = [\n",
    "        HumanMessage(content=\"안녕하세요\"),\n",
    "        AIMessage(content=\"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        HumanMessage(content=\"날씨가 어때요?\"),\n",
    "        AIMessage(content=\"오늘은 맑은 날씨입니다.\"),\n",
    "        HumanMessage(content=\"추천 음식이 있나요?\"),\n",
    "        AIMessage(content=\"파스타를 추천합니다.\"),\n",
    "        HumanMessage(content=\"레시피를 알려주세요\"),\n",
    "        AIMessage(content=\"토마토 파스타 레시피입니다...\"),\n",
    "        HumanMessage(content=\"감사합니다\"),\n",
    "        AIMessage(content=\"천만에요!\"),\n",
    "    ]\n",
    "\n",
    "    print(f\"원본 메시지 수: {len(messages)}\\n\")\n",
    "\n",
    "    # 전략 1: 최근 N개 메시지만 유지\n",
    "    trimmed_last = trim_messages(\n",
    "        messages,\n",
    "        strategy=\"last\",\n",
    "        max_tokens=100,  # 대략 100 토큰만 유지\n",
    "        start_on=\"human\",  # 사람 메시지로 시작\n",
    "        end_on=(\"human\", \"ai\"),  # 사람 또는 AI 메시지로 끝\n",
    "    )\n",
    "\n",
    "    print(\"전략 1 - 최근 메시지 유지:\")\n",
    "    for msg in trimmed_last:\n",
    "        role = \"User\" if isinstance(msg, HumanMessage) else \"Bot\"\n",
    "        print(f\"  {role}: {msg.content[:30]}...\")\n",
    "\n",
    "    # 전략 2: 첫 메시지와 최근 메시지 유지\n",
    "    trimmed_mixed = trim_messages(\n",
    "        messages,\n",
    "        strategy=\"first\",\n",
    "        max_tokens=100,\n",
    "        include_system=False,\n",
    "    )\n",
    "\n",
    "    print(\"\\n전략 2 - 첫 메시지 유지:\")\n",
    "    for msg in trimmed_mixed:\n",
    "        role = \"User\" if isinstance(msg, HumanMessage) else \"Bot\"\n",
    "        print(f\"  {role}: {msg.content[:30]}...\")\n",
    "\n",
    "    return trimmed_last\n",
    "\n",
    "\n",
    "trimmed = demonstrate_trimming()\n",
    "print(f\"\\n✅ 트리밍 후 메시지 수: {len(trimmed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프에서 트리밍 적용\n",
    "class TrimmedState(MessagesState):\n",
    "    \"\"\"State with message trimming\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def call_model_with_trimming(state: TrimmedState):\n",
    "    \"\"\"Call model with automatic message trimming\"\"\"\n",
    "\n",
    "    # 메시지 트리밍 - 최대 500 토큰만 유지\n",
    "    trimmed_messages = trim_messages(\n",
    "        state[\"messages\"],\n",
    "        strategy=\"last\",\n",
    "        max_tokens=500,\n",
    "        start_on=\"human\",\n",
    "        end_on=(\"human\", \"ai\"),\n",
    "        include_system=True,  # 시스템 메시지 포함\n",
    "    )\n",
    "\n",
    "    # 트리밍된 메시지로 LLM 호출\n",
    "    response = llm.invoke(trimmed_messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 트리밍이 적용된 그래프 생성\n",
    "trimming_builder = StateGraph(TrimmedState)\n",
    "trimming_builder.add_node(\"chat\", call_model_with_trimming)\n",
    "trimming_builder.add_edge(START, \"chat\")\n",
    "trimming_builder.add_edge(\"chat\", END)\n",
    "\n",
    "trimming_graph = trimming_builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "print(\"✅ 자동 트리밍이 적용된 그래프 생성 완료!\")\n",
    "print(\"\\n💡 긴 대화에서도 컨텍스트 윈도우 제한을 자동으로 관리합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 메시지 삭제 (Deletion)\n",
    "\n",
    "특정 메시지를 영구적으로 삭제하여 메모리를 관리할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "\n",
    "class DeletionState(MessagesState):\n",
    "    \"\"\"State for message deletion example\"\"\"\n",
    "\n",
    "    pass\n",
    "\n",
    "\n",
    "def delete_old_messages(state: DeletionState):\n",
    "    \"\"\"Delete messages older than threshold\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 5개 이상의 메시지가 있으면 오래된 메시지 삭제\n",
    "    if len(messages) > 5:\n",
    "        # 처음 2개 메시지 삭제\n",
    "        messages_to_delete = [RemoveMessage(id=msg.id) for msg in messages[:2]]\n",
    "        return {\"messages\": messages_to_delete}\n",
    "\n",
    "    return {}\n",
    "\n",
    "\n",
    "def chat_and_cleanup(state: DeletionState):\n",
    "    \"\"\"Chat with automatic cleanup\"\"\"\n",
    "    # 먼저 오래된 메시지 정리\n",
    "    cleanup_result = delete_old_messages(state)\n",
    "\n",
    "    # LLM 호출\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 응답과 정리 결과 병합\n",
    "    messages_update = [response]\n",
    "    if \"messages\" in cleanup_result:\n",
    "        messages_update = cleanup_result[\"messages\"] + messages_update\n",
    "\n",
    "    return {\"messages\": messages_update}\n",
    "\n",
    "\n",
    "# 삭제 로직이 포함된 그래프\n",
    "deletion_builder = StateGraph(DeletionState)\n",
    "deletion_builder.add_node(\"chat\", chat_and_cleanup)\n",
    "deletion_builder.add_edge(START, \"chat\")\n",
    "deletion_builder.add_edge(\"chat\", END)\n",
    "\n",
    "deletion_graph = deletion_builder.compile(checkpointer=InMemorySaver())\n",
    "\n",
    "print(\"✅ 자동 메시지 삭제가 적용된 그래프 생성 완료!\")\n",
    "print(\"\\n💡 오래된 메시지를 자동으로 삭제하여 메모리를 효율적으로 관리합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 메시지 요약 (Summarization)\n",
    "\n",
    "오래된 메시지를 요약하여 컨텍스트를 압축할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "\n",
    "class SummarizationState(MessagesState):\n",
    "    \"\"\"State with summarization support\"\"\"\n",
    "\n",
    "    summary: str = \"\"  # 대화 요약 저장\n",
    "\n",
    "\n",
    "def summarize_conversation(messages: list) -> str:\n",
    "    \"\"\"Summarize a list of messages\"\"\"\n",
    "    # 요약을 위한 프롬프트\n",
    "    summary_prompt = \"\"\"\n",
    "    Please summarize the following conversation in 2-3 sentences,\n",
    "    focusing on key information and context:\n",
    "    \n",
    "    {conversation}\n",
    "    \"\"\"\n",
    "\n",
    "    # 대화 내용 포맷팅\n",
    "    conversation = \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in messages])\n",
    "\n",
    "    # LLM으로 요약 생성 (실제로는 별도의 요약 모델 사용 권장)\n",
    "    summary_response = llm.invoke(\n",
    "        [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": summary_prompt.format(conversation=conversation),\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return summary_response.content\n",
    "\n",
    "\n",
    "def chat_with_summarization(state: SummarizationState):\n",
    "    \"\"\"Chat with automatic summarization\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "\n",
    "    # 10개 이상의 메시지가 있으면 요약\n",
    "    if len(messages) > 10:\n",
    "        # 처음 5개 메시지 요약\n",
    "        messages_to_summarize = messages[:5]\n",
    "        summary = summarize_conversation(messages_to_summarize)\n",
    "\n",
    "        # 요약을 시스템 메시지로 추가하고 오래된 메시지 삭제\n",
    "        new_messages = [\n",
    "            SystemMessage(content=f\"Previous conversation summary: {summary}\")\n",
    "        ] + messages[\n",
    "            5:\n",
    "        ]  # 요약된 메시지는 제거\n",
    "\n",
    "        # 상태 업데이트\n",
    "        return {\"messages\": new_messages, \"summary\": summary}\n",
    "\n",
    "    # 일반 응답\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "print(\"✅ 대화 요약 기능 구현 완료!\")\n",
    "print(\"\\n💡 긴 대화를 자동으로 요약하여 컨텍스트를 효율적으로 관리합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: 시맨틱 검색 (Semantic Search) 🔍\n",
    "\n",
    "## 4.1 임베딩 기반 메모리 검색\n",
    "\n",
    "Store에 시맨틱 검색을 활성화하면 의미적으로 유사한 메모리를 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 시맨틱 검색이 활성화된 Store 생성\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "semantic_store = InMemoryStore(\n",
    "    index={\n",
    "        \"embed\": embeddings,  # 임베딩 모델\n",
    "        \"dims\": 1536,  # 임베딩 차원\n",
    "    }\n",
    ")\n",
    "\n",
    "# 메모리 저장\n",
    "user_namespace = (\"user_456\", \"memories\")\n",
    "\n",
    "# 다양한 메모리 저장\n",
    "memories_to_store = [\n",
    "    {\"id\": \"1\", \"text\": \"나는 피자를 좋아해\"},\n",
    "    {\"id\": \"2\", \"text\": \"내 직업은 데이터 사이언티스트야\"},\n",
    "    {\"id\": \"3\", \"text\": \"파이썬과 머신러닝을 주로 다뤄\"},\n",
    "    {\"id\": \"4\", \"text\": \"주말에는 등산을 즐겨해\"},\n",
    "    {\"id\": \"5\", \"text\": \"커피보다 차를 선호해\"},\n",
    "]\n",
    "\n",
    "for memory in memories_to_store:\n",
    "    semantic_store.put(user_namespace, memory[\"id\"], {\"text\": memory[\"text\"]})\n",
    "\n",
    "print(\"✅ 시맨틱 메모리 저장 완료!\\n\")\n",
    "\n",
    "# 시맨틱 검색 테스트\n",
    "queries = [\"음식 취향\", \"프로그래밍\", \"여가 활동\"]\n",
    "\n",
    "print(\"🔍 시맨틱 검색 결과:\\n\")\n",
    "for query in queries:\n",
    "    # 쿼리와 유사한 메모리 검색\n",
    "    results = semantic_store.search(\n",
    "        user_namespace, query=query, limit=2  # 상위 2개 결과\n",
    "    )\n",
    "\n",
    "    print(f\"Query: '{query}'\")\n",
    "    for item in results:\n",
    "        print(f\"  → {item.value['text']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 시맨틱 메모리를 활용한 대화 시스템"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_semantic_memory(state: MessagesState, *, store: BaseStore):\n",
    "    \"\"\"Chat function with semantic memory search\"\"\"\n",
    "\n",
    "    # 사용자의 마지막 메시지\n",
    "    user_message = state[\"messages\"][-1].content\n",
    "\n",
    "    # 관련 메모리 검색\n",
    "    namespace = (\"user_456\", \"memories\")\n",
    "    relevant_memories = store.search(namespace, query=user_message, limit=3)\n",
    "\n",
    "    # 컨텍스트 구성\n",
    "    context = \"\"\n",
    "    if relevant_memories:\n",
    "        context = \"사용자에 대한 관련 정보:\\n\"\n",
    "        context += \"\\n\".join([f\"• {item.value['text']}\" for item in relevant_memories])\n",
    "\n",
    "    # 시스템 프롬프트 구성\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a helpful assistant with access to user's personal information.\n",
    "    Use the following context to provide personalized responses:\n",
    "    \n",
    "    {context}\n",
    "    \n",
    "    Respond naturally and incorporate relevant information when appropriate.\n",
    "    \"\"\"\n",
    "\n",
    "    # LLM 호출\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + state[\"messages\"]\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 시맨틱 메모리 그래프 생성\n",
    "semantic_builder = StateGraph(MessagesState)\n",
    "semantic_builder.add_node(\"chat\", chat_with_semantic_memory)\n",
    "semantic_builder.add_edge(START, \"chat\")\n",
    "semantic_builder.add_edge(\"chat\", END)\n",
    "\n",
    "semantic_graph = semantic_builder.compile(store=semantic_store)\n",
    "\n",
    "# 테스트\n",
    "print(\"💬 시맨틱 메모리 기반 대화 테스트:\\n\")\n",
    "\n",
    "test_messages = [\n",
    "    \"오늘 점심 뭐 먹을까?\",\n",
    "    \"새로운 프로젝트를 시작하려고 하는데 조언 좀 해줘\",\n",
    "    \"주말 계획이 있어?\",\n",
    "]\n",
    "\n",
    "for msg in test_messages:\n",
    "    print(f\"👤 User: {msg}\")\n",
    "    result = semantic_graph.invoke({\"messages\": [{\"role\": \"user\", \"content\": msg}]})\n",
    "    print(f\"🤖 Bot: {result['messages'][-1].content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: 프로덕션 배포 🚀\n",
    "\n",
    "## 5.1 데이터베이스 Checkpointer 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로덕션 Checkpointer 옵션\n",
    "production_options = {\n",
    "    \"PostgreSQL\": {\n",
    "        \"package\": \"langgraph-checkpoint-postgres\",\n",
    "        \"class\": \"PostgresSaver\",\n",
    "        \"connection\": \"postgresql://user:pass@host:port/db\",\n",
    "        \"features\": [\"ACID 준수\", \"복잡한 쿼리 지원\", \"엔터프라이즈 표준\"],\n",
    "        \"setup\": \"checkpointer.setup()  # 첫 실행 시\",\n",
    "    },\n",
    "    \"MongoDB\": {\n",
    "        \"package\": \"langgraph-checkpoint-mongodb\",\n",
    "        \"class\": \"MongoDBSaver\",\n",
    "        \"connection\": \"mongodb://localhost:27017\",\n",
    "        \"features\": [\"NoSQL 유연성\", \"수평 확장성\", \"JSON 네이티브\"],\n",
    "        \"setup\": \"클러스터 생성 필요\",\n",
    "    },\n",
    "    \"Redis\": {\n",
    "        \"package\": \"langgraph-checkpoint-redis\",\n",
    "        \"class\": \"RedisSaver\",\n",
    "        \"connection\": \"redis://localhost:6379\",\n",
    "        \"features\": [\"초고속 메모리 DB\", \"캐싱 최적화\", \"Pub/Sub 지원\"],\n",
    "        \"setup\": \"checkpointer.setup()  # 첫 실행 시\",\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"📊 프로덕션 Checkpointer 비교:\\n\")\n",
    "for db, info in production_options.items():\n",
    "    print(f\"### {db}\")\n",
    "    print(f\"  패키지: {info['package']}\")\n",
    "    print(f\"  클래스: {info['class']}\")\n",
    "    print(f\"  연결: {info['connection']}\")\n",
    "    print(f\"  특징: {', '.join(info['features'])}\")\n",
    "    print(f\"  설정: {info['setup']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 프로덕션 Store 구현 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_production_setup():\n",
    "    \"\"\"Production setup example with both checkpointer and store\"\"\"\n",
    "\n",
    "    print(\"🏭 프로덕션 환경 설정 예제:\\n\")\n",
    "\n",
    "    # PostgreSQL 예제\n",
    "    postgres_example = \"\"\"\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.store.postgres import PostgresStore\n",
    "\n",
    "DB_URI = \"postgresql://user:password@localhost:5432/langgraph_db\"\n",
    "\n",
    "# Context manager로 자동 리소스 관리\n",
    "with (\n",
    "    PostgresStore.from_conn_string(DB_URI) as store,\n",
    "    PostgresSaver.from_conn_string(DB_URI) as checkpointer,\n",
    "):\n",
    "    # 첫 실행 시 테이블 생성\n",
    "    store.setup()\n",
    "    checkpointer.setup()\n",
    "    \n",
    "    # 그래프 컴파일\n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,  # 단기 메모리\n",
    "        store=store  # 장기 메모리\n",
    "    )\n",
    "    \n",
    "    # 그래프 실행\n",
    "    result = graph.invoke(input_data, config)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"### PostgreSQL 설정:\")\n",
    "    print(postgres_example)\n",
    "\n",
    "    # Redis 예제\n",
    "    redis_example = \"\"\"\n",
    "from langgraph.checkpoint.redis import RedisSaver\n",
    "from langgraph.store.redis import RedisStore\n",
    "\n",
    "REDIS_URI = \"redis://localhost:6379\"\n",
    "\n",
    "# Redis 연결\n",
    "with (\n",
    "    RedisStore.from_conn_string(REDIS_URI) as store,\n",
    "    RedisSaver.from_conn_string(REDIS_URI) as checkpointer,\n",
    "):\n",
    "    store.setup()\n",
    "    checkpointer.setup()\n",
    "    \n",
    "    graph = builder.compile(\n",
    "        checkpointer=checkpointer,\n",
    "        store=store\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n### Redis 설정:\")\n",
    "    print(redis_example)\n",
    "\n",
    "    return \"프로덕션 설정 예제 완료\"\n",
    "\n",
    "\n",
    "create_production_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 베스트 프랙티스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 관리 베스트 프랙티스\n",
    "best_practices = {\n",
    "    \"아키텍처 설계\": [\n",
    "        \"단기/장기 메모리 명확히 구분\",\n",
    "        \"적절한 네임스페이스 전략 수립\",\n",
    "        \"메모리 계층 구조 설계\",\n",
    "    ],\n",
    "    \"성능 최적화\": [\n",
    "        \"메시지 트리밍으로 컨텍스트 관리\",\n",
    "        \"캐싱 적극 활용\",\n",
    "        \"인덱싱으로 검색 성능 향상\",\n",
    "    ],\n",
    "    \"데이터 관리\": [\"정기적인 메모리 정리\", \"백업 전략 수립\", \"민감 정보 암호화\"],\n",
    "    \"모니터링\": [\"메모리 사용량 추적\", \"응답 시간 모니터링\", \"에러 로깅 및 알림\"],\n",
    "    \"확장성\": [\"수평 확장 가능한 아키텍처\", \"로드 밸런싱 고려\", \"샤딩 전략 수립\"],\n",
    "}\n",
    "\n",
    "print(\"📋 메모리 관리 베스트 프랙티스:\\n\")\n",
    "for category, practices in best_practices.items():\n",
    "    print(f\"### {category}\")\n",
    "    for practice in practices:\n",
    "        print(f\"  ✓ {practice}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 🎉 축하합니다!\n",
    "\n",
    "LangGraph의 메모리 시스템을 완벽하게 마스터했습니다!\n",
    "\n",
    "## ✅ 학습 완료 항목\n",
    "\n",
    "1. **단기 메모리 (Short-term Memory)**\n",
    "   - Checkpointer를 활용한 대화 지속성\n",
    "   - Thread 기반 세션 관리\n",
    "   - 프로덕션 Checkpointer (PostgreSQL, MongoDB, Redis)\n",
    "\n",
    "2. **장기 메모리 (Long-term Memory)**\n",
    "   - Store를 활용한 영구 데이터 저장\n",
    "   - 사용자별 정보 관리\n",
    "   - Tool에서의 메모리 접근\n",
    "\n",
    "3. **메모리 관리 전략**\n",
    "   - 메시지 트리밍 (Trimming)\n",
    "   - 메시지 삭제 (Deletion)\n",
    "   - 대화 요약 (Summarization)\n",
    "\n",
    "4. **시맨틱 검색**\n",
    "   - 임베딩 기반 메모리 검색\n",
    "   - 의미적 유사도 활용\n",
    "\n",
    "5. **프로덕션 배포**\n",
    "   - 데이터베이스 통합\n",
    "   - 베스트 프랙티스\n",
    "\n",
    "## 🚀 다음 단계\n",
    "\n",
    "### 실전 프로젝트 아이디어\n",
    "\n",
    "1. **개인화된 AI 어시스턴트**\n",
    "   - 사용자 선호도 학습\n",
    "   - 대화 히스토리 분석\n",
    "   - 맞춤형 추천 시스템\n",
    "\n",
    "2. **고객 서비스 봇**\n",
    "   - 고객 정보 관리\n",
    "   - 이전 상담 내역 참조\n",
    "   - 문제 해결 패턴 학습\n",
    "\n",
    "3. **교육용 튜터 시스템**\n",
    "   - 학습 진도 추적\n",
    "   - 개인별 약점 분석\n",
    "   - 맞춤형 학습 경로 제공\n",
    "\n",
    "### 추가 학습 자료\n",
    "\n",
    "- **고급 메모리 패턴**: 계층적 메모리, 에피소드 메모리\n",
    "- **분산 시스템**: 멀티 노드 메모리 동기화\n",
    "- **보안**: 메모리 암호화, 접근 제어\n",
    "- **최적화**: 메모리 압축, 인덱싱 전략\n",
    "\n",
    "## 💡 핵심 팁\n",
    "\n",
    "1. **목적에 맞는 메모리 선택**: 단기 vs 장기 메모리 구분\n",
    "2. **확장성 고려**: 처음부터 프로덕션 환경 고려\n",
    "3. **성능 모니터링**: 메모리 사용량과 응답 시간 추적\n",
    "4. **보안 우선**: 민감한 정보는 반드시 암호화\n",
    "5. **점진적 개선**: 작게 시작하여 필요에 따라 확장\n",
    "\n",
    "이제 여러분은 LangGraph의 강력한 메모리 시스템을 활용하여 \n",
    "진정한 지능형 AI 애플리케이션을 구축할 준비가 되었습니다! 🎯"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
