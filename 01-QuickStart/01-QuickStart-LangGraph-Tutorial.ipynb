{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-00",
   "metadata": {},
   "source": [
    "# 🚀 LangGraph QuickStart - 입문자를 위한 실전 튜토리얼\n",
    "\n",
    "## 🎯 목표와 대상\n",
    "\n",
    "이 노트북은 **LangGraph**를 처음 접하는 분을 위한 **실전 중심 튜토리얼** 입니다. \n",
    "\n",
    "### 📋 이 튜토리얼에서 만들 기능\n",
    "\n",
    "- **🧠 기억력**: 이전 대화를 유지하는 상태 관리\n",
    "- **🔍 검색 연동**: 외부 검색 도구로 최신 정보 확보  \n",
    "- **🙋 인간 개입**: 승인 기반 Human-in-the-Loop\n",
    "- **⏪ 상태 이력**: 체크포인트 기반 롤백 및 재실행\n",
    "\n",
    "### 🏗️ 진행 로드맵\n",
    "\n",
    "- **단계 1: 기본 챗봇 구축** — StateGraph, 메시지 흐름\n",
    "- **단계 2: 도구 통합** — Tool 바인딩, 조건부 라우팅\n",
    "- **단계 3: 메모리 추가** — 체크포인트, Thread ID\n",
    "- **단계 4: Human-in-the-Loop** — interrupt, 승인 흐름\n",
    "- **단계 5: 상태 커스터마이징** — 커스텀 State, Tool 업데이트\n",
    "- **단계 6: 상태 이력 관리** — 이력 탐색, 롤백, 재실행\n",
    "\n",
    "### 🛠️ 핵심 컴포넌트\n",
    "\n",
    "- **🏗️ StateGraph**: 대화 프로세스 정의\n",
    "- **🔨 Node**: 작업을 수행하는 함수 단위\n",
    "- **🛤️ Edge**: 노드 간 실행 경로\n",
    "- **📝 State**: 메시지와 컨텍스트 저장소\n",
    "- **💾 Checkpointing**: 실행 시점 저장 및 복원\n",
    "\n",
    "### ✅ 학습 성과\n",
    "\n",
    "- **나만의 AI 비서**를 처음부터 끝까지 구현  \n",
    "- **LangGraph 핵심 개념**의 실전 이해  \n",
    "- **실무 적용 가능한 구조**와 패턴 확보  \n",
    "- **확장 가능한 아키텍처** 설계 감각 습득\n",
    "\n",
    "### 🔧 준비물\n",
    "\n",
    "- **Python 3.11 이상**  \n",
    "- **OpenAI API 키**  \n",
    "- **Tavily Search API 키**  \n",
    "- **LangSmith API 키** (선택)\n",
    "\n",
    "### 📌 진행 방식\n",
    "\n",
    "설명은 간결하게, 예시는 즉시 실행 가능한 코드로 제공합니다. 과장된 표현은 지양하고, 필요한 곳에만 이모지를 사용해 가독성을 높였습니다.  \n",
    "\n",
    "**함께 구축해봅시다.** 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-01",
   "metadata": {},
   "source": [
    "## 🛠️ 환경 설정 - 최소 요구사항 정리\n",
    "\n",
    "실행에 필요한 설정을 간단히 정리합니다. 과한 비유는 생략하고 필요한 항목만 빠르게 맞춥니다. 👇\n",
    "\n",
    "### 🔧 준비 항목\n",
    "\n",
    "1. **🔑 API 키 설정** — OpenAI, Tavily, (선택) LangSmith\n",
    "2. **📊 추적 설정** — LangSmith로 실행 추적 (선택)\n",
    "\n",
    "### 💡 이유\n",
    "\n",
    "- **🔒 보안**: 키를 환경변수로 안전하게 관리\n",
    "- **📈 모니터링**: 실행 경로와 비용 추적\n",
    "- **🐛 디버깅**: 오류 발생 지점 신속 파악\n",
    "\n",
    "바로 이어서 설정을 진행합니다. 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangGraph-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: 기본 챗봇 구축 🤖\n",
    "\n",
    "## 🎯 목적\n",
    "\n",
    "가장 단순한 형태의 **메시지 기반 챗봇**을 구성합니다. 불필요한 수사는 줄이고, 구조와 흐름을 명확히 보여드립니다.\n",
    "\n",
    "### 구성 요소\n",
    "\n",
    "- **🏗️ StateGraph**: 전체 흐름 정의\n",
    "- **📝 State**: 메시지 저장 구조\n",
    "- **🔨 Node**: 처리 함수 (LLM 호출)\n",
    "- **🛤️ Edge**: 실행 경로 연결\n",
    "- **⚙️ Compile/Invoke**: 실행 준비 및 호출\n",
    "\n",
    "### 왜 이렇게 구성하나요?\n",
    "\n",
    "- **확장성**: 기능 추가가 용이\n",
    "- **가독성**: 처리 단계를 분리해 이해 용이  \n",
    "- **운영성**: 장애 구간을 빠르게 식별 가능\n",
    "\n",
    "이제 바로 구현으로 들어갑니다. 🚀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의: 챗봇의 상태를 나타내는 타입\n",
    "class State(TypedDict):\n",
    "    \"\"\"챗봇의 상태를 정의하는 타입\n",
    "\n",
    "    messages: 대화 메시지 리스트\n",
    "    - add_messages 함수를 통해 새 메시지가 추가됨 (덮어쓰기가 아닌 추가)\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# StateGraph 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "print(\"✅ StateGraph 생성 완료!\")\n",
    "print(\"📌 State는 messages 키를 가지며, add_messages 리듀서를 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-06",
   "metadata": {},
   "source": [
    "### 🧠 LLM 선택 및 설정\n",
    "\n",
    "실습에서는 **GPT-4.1**을 사용합니다. 목적은 안정적인 답변이므로 `temperature=0` 으로 설정합니다.\n",
    "\n",
    "- **모델**: gpt-4.1  \n",
    "- **전략**: 일관성 우선 (창의성 최소화)  \n",
    "- **이유**: 튜토리얼 재현성과 검증 용이성 확보\n",
    "\n",
    "필요 시, 조직 환경의 모델로 교체해도 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 선택\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08",
   "metadata": {},
   "source": [
    "### 🔨 챗봇 노드 추가\n",
    "\n",
    "대화 메시지를 입력받아 LLM에 전달하고, 응답 메시지를 상태에 추가합니다.\n",
    "\n",
    "- **입력**: `State[\"messages\"]`  \n",
    "- **처리**: LLM 호출 후 응답 생성  \n",
    "- **출력**: 새 메시지 1개 추가\n",
    "\n",
    "필요한 최소 설명만으로 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"챗봇 노드 함수\n",
    "\n",
    "    현재 상태의 메시지를 받아 LLM에 전달하고,\n",
    "    응답을 새 메시지로 추가하여 반환합니다.\n",
    "    \"\"\"\n",
    "    # LLM을 호출하여 응답 생성\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 응답을 메시지 리스트에 추가하여 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 그래프에 노드 추가\n",
    "# 첫 번째 인자: 노드의 고유 이름\n",
    "# 두 번째 인자: 노드가 사용될 때 호출될 함수\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### 🚪 진입점과 종료점 설정\n",
    "\n",
    "실행 경로를 명확히 정의합니다.\n",
    "\n",
    "- **START**: 입력 수신  \n",
    "- **chatbot**: LLM 호출 및 응답 생성  \n",
    "- **END**: 결과 반환\n",
    "\n",
    "가장 단순한 실행 흐름을 먼저 완성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진입점: 그래프 실행이 시작되는 지점\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 종료점: 그래프 실행이 끝나는 지점\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "print(\"✅ 진입점과 종료점 설정 완료!\")\n",
    "print(\"📌 실행 흐름: START → chatbot → END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### ⚡ 그래프 컴파일\n",
    "\n",
    "구성한 그래프를 실행 가능한 형태로 컴파일합니다. 사전 검증을 통해 런타임 오류를 줄이고, 실행 준비를 마칩니다.\n",
    "\n",
    "- **검증**: 연결 관계, 의존성 확인  \n",
    "- **최적화**: 실행 준비 및 성능 기본 튜닝  \n",
    "- **안정성**: 사전 검사로 오류 가능성 축소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"✅ 그래프 컴파일 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### 👀 그래프 시각화\n",
    "\n",
    "구성한 그래프를 시각화해 구조를 빠르게 확인합니다.\n",
    "\n",
    "- **노드**: 처리 단위  \n",
    "- **엣지**: 실행 경로  \n",
    "- **START/END**: 시작/종료 포인트\n",
    "\n",
    "시각화는 구조 검증과 이해를 빠르게 돕습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### 🎉 챗봇 실행\n",
    "\n",
    "간단한 질문으로 그래프를 실행해 정상 동작을 확인합니다.\n",
    "\n",
    "- **질문 예시**: \"LangGraph에 대해 알려주세요\"  \n",
    "- **흐름**: START → chatbot → END  \n",
    "- **주의**: `recursion_limit`, `thread_id` 등 설정값은 재현성에 영향을 줍니다.\n",
    "\n",
    "바로 실행해보겠습니다. 🎧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 질문 입력\n",
    "user_input = \"안녕하세요! LangGraph에 대해 알려주세요.\"\n",
    "\n",
    "# Config 설정(recursion_limit: 재귀 깊이 제한, thread_id: 스레드 아이디)\n",
    "config = RunnableConfig(recursion_limit=20, thread_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"안녕하세요! LangGraph에 대해 알려주세요.\")]\n",
    "}\n",
    "\n",
    "# 그래프 스트리밍\n",
    "stream_graph(graph, inputs=inputs, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 도구(Tools) 추가 🔧\n",
    "\n",
    "## 🎯 목적\n",
    "실시간 정보가 필요한 요청에 대응하기 위해 외부 검색 도구를 통합합니다.\n",
    "\n",
    "### 왜 필요한가\n",
    "- **지식 한계 보완**: 모델 학습 시점 이후의 정보 조회\n",
    "- **팩트 체크**: 출처 기반 검증 강화\n",
    "- **실무 친화성**: 최신 데이터 기반 응답\n",
    "\n",
    "### 핵심 개념\n",
    "- **Tool Binding**: LLM이 도구를 호출할 수 있도록 연결\n",
    "- **Tool Node**: 외부 API 호출을 담당하는 노드\n",
    "- **Conditional Edges**: 도구 사용 여부를 자동으로 분기\n",
    "\n",
    "### 기대 효과\n",
    "- **실시간성**, **정확성**, **확장성** 향상"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공유\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"add two numbers\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Tavily 검색 도구 설정\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, add]\n",
    "\n",
    "# 도구 테스트\n",
    "result = tool.invoke(\"LangGraph란 무엇인가요?\")\n",
    "print(f\"검색 결과 수: {len(result['results'])}개\")\n",
    "print(f\"첫 번째 결과 제목: {result['results'][0]['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### 🏗️ 도구 사용 그래프 구성\n",
    "\n",
    "기본 흐름에 도구 호출 경로를 추가합니다.\n",
    "\n",
    "- 기존: 사용자 → chatbot → END\n",
    "- 변경: 사용자 → chatbot ⇄ tools → chatbot → END\n",
    "\n",
    "핵심 요소\n",
    "- **Tool 바인딩**  \n",
    "- **ToolNode 추가**  \n",
    "- **조건부 분기 적용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret1 = llm_with_tools.invoke(\"LangGraph 가 뭐야?\")\n",
    "ret2 = llm_with_tools.invoke(\"LangGraph 가 뭐야? 검색해서 알려줘\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "display_message_tree(ret1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_message_tree(ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의 (동일)\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# 새로운 그래프 빌더 생성\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# LLM에 도구 바인딩 - LLM이 도구를 사용할 수 있도록 설정\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"도구를 사용할 수 있는 챗봇 노드\"\"\"\n",
    "    # 도구가 바인딩된 LLM 호출\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ToolNode 추가 - 도구를 실행하는 노드\n",
    "tool_node = ToolNode(tools=tools)\n",
    "builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### 🚦 조건부 라우팅(Conditional Edges)\n",
    "\n",
    "요청에 따라 자동으로 경로를 선택합니다.\n",
    "\n",
    "- **외부 검색 필요**: \"tools\" 로 이동  \n",
    "- **내부 처리 가능**: 종료\n",
    "\n",
    "핵심: `tools_condition` 이 마지막 AI 메시지의 `tool_calls` 존재 여부를 확인합니다.\n",
    "\n",
    "이 구조로 불필요한 도구 호출을 줄이고 응답 속도를 확보합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### 🔍 tools_condition 동작 요약\n",
    "\n",
    "`tools_condition` 은 마지막 AI 메시지에 도구 호출이 있는지 확인해 분기합니다.\n",
    "\n",
    "- `tool_calls` 있음 → \"tools\"  \n",
    "- `tool_calls` 없음 → \"__end__\"\n",
    "\n",
    "간단한 구현 예시는 아래와 같습니다.\n",
    "\n",
    "```python\n",
    "def tools_condition(state) -> Literal[\"tools\", \"__end__\"]:\n",
    "    # 마지막 메시지 추출\n",
    "    ai_message = state[-1] if isinstance(state, list) else state[\"messages\"][-1]\n",
    "    # 분기 판단\n",
    "    return \"tools\" if getattr(ai_message, \"tool_calls\", []) else \"__end__\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건부 엣지 추가\n",
    "# tools_condition은 메시지에 tool_calls가 있으면 \"tools\"로,\n",
    "# 없으면 END로 라우팅합니다\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # 사전 정의된 조건 함수 사용\n",
    ")\n",
    "\n",
    "# 도구 실행 후 다시 챗봇으로 돌아가기\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 시작점 설정\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_with_tools = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### 👀 업그레이드 그래프 시각화\n",
    "\n",
    "변경된 구조를 시각화해 분기와 루프를 확인합니다.\n",
    "\n",
    "- 새 노드: `tools`  \n",
    "- 분기: `chatbot` → 판단 → `tools` 또는 종료  \n",
    "- 루프: `tools` → `chatbot`\n",
    "\n",
    "시각화를 통해 설정이 의도대로 적용되었는지 빠르게 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 시각화\n",
    "visualize_graph(graph_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### 🚀 도구 사용 테스트\n",
    "\n",
    "실시간 정보가 필요한 질문으로 동작을 확인합니다.\n",
    "\n",
    "- **예시 질문**: \"2025년 LangGraph 사용 사례 알려주세요.\"  \n",
    "- **기대 흐름**: `chatbot` → `tools` → `chatbot` → END  \n",
    "- **확인 포인트**: 검색 호출 여부, 결과 정리 품질, 응답 자연스러움\n",
    "\n",
    "이제 실행해 결과를 확인합니다. 🧪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "stream_graph(\n",
    "    graph_with_tools,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"2025년 LangGraph 사용 사례 알려주세요.\")]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 메모리 추가 💾\n",
    "\n",
    "## 🎯 목적\n",
    "세션 간에도 사용자 정보를 유지하는 **영구 상태 관리**를 추가합니다.\n",
    "\n",
    "### Before\n",
    "- 세션이 바뀌면 이전 정보 소실\n",
    "\n",
    "### After\n",
    "- 사용자별로 중요한 정보를 저장하고 재사용\n",
    "\n",
    "### 핵심 개념\n",
    "- **💾 Checkpointer**: 대화 상태 저장/복원\n",
    "- **🏷️ Thread ID**: 세션 식별자\n",
    "- **🗂️ Persistent State**: 누적 이력 기반 컨텍스트\n",
    "\n",
    "### 기대 효과\n",
    "- **연속 대화**, **개인화**, **컨텍스트 안정성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "\n",
    "\n",
    "# Pydantic 모델 정의\n",
    "class MemoryItem(BaseModel):\n",
    "    \"\"\"개별 메모리 아이템\"\"\"\n",
    "\n",
    "    key: str = Field(description=\"메모리 키 (예: user_name, preference, fact)\")\n",
    "    value: str = Field(description=\"메모리 값\")\n",
    "    category: str = Field(\n",
    "        description=\"카테고리 (personal_info, preference, interest, relationship, fact, etc.)\"\n",
    "    )\n",
    "    importance: int = Field(description=\"중요도 (1-5, 5가 가장 중요)\", ge=1, le=5)\n",
    "    confidence: float = Field(description=\"추출 신뢰도 (0.0-1.0)\", ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "class ExtractedMemories(BaseModel):\n",
    "    \"\"\"추출된 메모리 컬렉션\"\"\"\n",
    "\n",
    "    memories: List[MemoryItem] = Field(description=\"추출된 메모리 아이템 리스트\")\n",
    "    summary: str = Field(description=\"대화 내용 요약\")\n",
    "    timestamp: str = Field(\n",
    "        default_factory=lambda: datetime.now().isoformat(), description=\"추출 시간\"\n",
    "    )\n",
    "\n",
    "\n",
    "# 기본 시스템 프롬프트\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are an expert memory extraction assistant. Your task is to extract important information from user conversations and convert them into structured key-value pairs for long-term memory storage.\n",
    "\n",
    "Extract ALL relevant information from the conversation, including:\n",
    "- Personal information (name, age, location, occupation, etc.)\n",
    "- Preferences and interests\n",
    "- Relationships and social connections\n",
    "- Important facts or events mentioned\n",
    "- Opinions and beliefs\n",
    "- Goals and aspirations\n",
    "- Any other notable information\n",
    "\n",
    "For each piece of information:\n",
    "1. Create a concise, searchable key\n",
    "2. Store the complete value\n",
    "3. Categorize appropriately\n",
    "4. Assess importance (1-5 scale)\n",
    "5. Evaluate extraction confidence (0.0-1.0)\"\"\"\n",
    "\n",
    "\n",
    "def create_memory_extractor(\n",
    "    model: Optional[str] = \"gpt-4.1\",\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    메모리 추출기를 생성합니다.\n",
    "\n",
    "    Args:\n",
    "        model: 사용할 언어 모델. None일 경우 기본 ChatOpenAI 모델 사용\n",
    "        system_prompt: 시스템 프롬프트. None일 경우 기본 프롬프트 사용\n",
    "\n",
    "    Returns:\n",
    "        메모리 추출 체인\n",
    "    \"\"\"\n",
    "    # Output Parser 생성\n",
    "    memory_parser = PydanticOutputParser(pydantic_object=ExtractedMemories)\n",
    "\n",
    "    # 시스템 프롬프트 설정\n",
    "    if system_prompt is None:\n",
    "        system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "    # 전체 프롬프트 템플릿 구성\n",
    "    template = f\"\"\"{system_prompt}\n",
    "\n",
    "User Input: {{input}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\n",
    "Remember to:\n",
    "- Extract multiple memory items if the conversation contains various pieces of information\n",
    "- Use clear, consistent key naming conventions\n",
    "- Preserve context in values when necessary\n",
    "- Be comprehensive but avoid redundancy\n",
    "\"\"\"\n",
    "\n",
    "    # 프롬프트 생성\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\n",
    "            \"format_instructions\": memory_parser.get_format_instructions()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # 모델 설정\n",
    "    model = AzureChatOpenAI(\n",
    "        deployment_name=\"gpt-4.1-mini\",  # 사용하는 모델명(deployment_name)\n",
    "        api_version=\"2024-12-01-preview\",\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    )\n",
    "\n",
    "    # 메모리 추출 체인 생성\n",
    "    memory_extractor = prompt | model | memory_parser\n",
    "\n",
    "    return memory_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_teddynote.memory import create_memory_extractor\n",
    "import uuid\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "memory_extractor = create_memory_extractor(model=\"gpt-4.1\")\n",
    "\n",
    "\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig,\n",
    "    *,\n",
    "    store: BaseStore,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Call the LLM model and manage user memory.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): The current state containing messages.\n",
    "        config (RunnableConfig): The runnable configuration.\n",
    "        store (BaseStore): The memory store.\n",
    "    \"\"\"\n",
    "    # 마지막 메시지에서 user_id 추출\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    print(namespace)\n",
    "\n",
    "    # 유저의 메모리 검색\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([f\"{memory.key}: {memory.value}\" for memory in memories])\n",
    "    system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "    # 사용자가 기억 요청 시 메모리 저장\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"remember\" in last_message.content.lower():\n",
    "        result = memory_extractor.invoke({\"input\": str(state[\"messages\"][-1].content)})\n",
    "        for memory in result.memories:\n",
    "            print(memory)\n",
    "            print(\"-\" * 100)\n",
    "            store.put(namespace, str(uuid.uuid4()), {memory.key: memory.value})\n",
    "\n",
    "    # LLM 호출\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "# 메모리 체크포인터 생성\n",
    "# 실제 프로덕션에서는 PostgresSaver 사용 권장\n",
    "memory_saver = InMemorySaver()\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_with_memory = builder.compile(\n",
    "    checkpointer=memory_saver,\n",
    "    store=memory_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    msg,\n",
    "    thread_id=\"default\",\n",
    "    user_id=\"default\",\n",
    "):\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id + user_id,\n",
    "            \"user_id\": user_id,\n",
    "        }\n",
    "    }\n",
    "    print(f\"\\n[유저🙋] {msg}\")\n",
    "    stream_graph(\n",
    "        graph_with_memory,\n",
    "        inputs={\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "        config=config,\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"안녕? 내 이름은 테디야\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고?\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고?\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### 🧠 장기 기억 저장: `remember` 키워드\n",
    "\n",
    "메시지에 `remember` 가 포함되면 중요 정보를 장기 저장소에 기록합니다.\n",
    "\n",
    "- **예시**: \"내 이름은 테디야 remember\"  \n",
    "- **저장 대상**: 이름, 직업, 선호 등 사용자 프로필성 정보  \n",
    "- **기본 원칙**: 일반 대화는 단기 컨텍스트로만 유지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 테디야 remember\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "### 🌟 Thread 간 지속성\n",
    "\n",
    "사용자 기반 장기 기억은 Thread 가 달라도 유지됩니다.\n",
    "\n",
    "- **Short-term Memory**: Thread 컨텍스트(세션 단위)\n",
    "- **Long-term Memory**: User ID 기반 프로필(세션 간 유지)\n",
    "\n",
    "실무에서도 사용자 정보는 클라이언트가 달라도 유지되는 것이 일반적입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고 했더라?\", \"3\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\n",
    "    \"내 직업은 AI Engineer 야. 내 취미는 Netflix 보기 야. remember\", \"4\", \"someone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 스레드에서 실행\n",
    "run_graph(\"내 이름, 직업, 취미 알려줘\", \"100\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 user_id 로 실행한 경우\n",
    "run_graph(\"내 이름, 직업, 취미 알려줘\", \"100\", \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### 🔍 State 확인\n",
    "\n",
    "현재 저장된 상태를 조회해 메시지 이력과 체크포인트 정보를 확인합니다.\n",
    "\n",
    "- **메시지 수**  \n",
    "- **체크포인트 ID**  \n",
    "- **최근 메시지 내용**\n",
    "\n",
    "상태 조회는 디버깅과 검증에 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Config 설정\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"100\" + \"someone\",\n",
    "        \"user_id\": \"someone\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 현재 상태 가져오기\n",
    "snapshot = graph_with_memory.get_state(config)\n",
    "\n",
    "print(\"📊 현재 상태 정보:\")\n",
    "print(f\"- 메시지 수: {len(snapshot.values['messages'])}개\")\n",
    "print(f\"- 체크포인트 ID: {snapshot.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "# 최근 메시지 몇 개 표시\n",
    "print(\"\\n[최근 메시지]\")\n",
    "for msg in snapshot.values[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, \"type\") else \"unknown\"\n",
    "    content = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "    print(f\"  [{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Human-in-the-Loop 🙋\n",
    "\n",
    "## 🎯 목적\n",
    "고위험/중요 작업에 대해 AI가 스스로 멈추고 인간 승인을 요청하는 승인 기반 흐름을 도입합니다.\n",
    "\n",
    "### 언제 승인이 필요한가\n",
    "- **💰 금융 처리**: 결제/이체/투자\n",
    "- **🏥 의료 조언**: 처방/치료 권고\n",
    "- **📧 대외 커뮤니케이션**: 공지/발송\n",
    "- **🔐 보안 변경**: 권한/설정\n",
    "\n",
    "### 핵심 개념\n",
    "- **⏸️ interrupt**: 실행 일시정지 및 승인 대기\n",
    "- **📋 Command**: 승인/거부 후 재개 명령\n",
    "- **👔 Human Approval**: 승인 워크플로우(검토 → 결정 → 재개)\n",
    "\n",
    "### 아키텍처\n",
    "```\n",
    "사용자 요청 → AI 분석 → ⏸️ 승인 필요 판단\n",
    "                  ↓\n",
    "               인간 검토 → ✅ 승인 / ❌ 거부\n",
    "                  ↓\n",
    "                 ▶️ 재개 및 안전 실행\n",
    "```\n",
    "\n",
    "### 기대 효과\n",
    "- **안전성 향상**, **신뢰성 확보**, **협업 강화**, **정책 준수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from an expert(human).\"\"\"\n",
    "    # interrupt를 호출하여 실행 일시 중지\n",
    "    # 사람의 응답을 기다림\n",
    "    human_response = interrupt({\"query\": query})\n",
    "\n",
    "    # 사람의 응답 반환\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### 🏗️ HITL 그래프 구성\n",
    "\n",
    "`human_assistance` 도구를 통해 승인 지점을 구현합니다.\n",
    "\n",
    "- **역할**: 필요 시 interrupt 로 중단 후 인간 답변 대기  \n",
    "- **흐름**: chatbot → tools(`human_assistance`) → chatbot → END  \n",
    "- **주의**: interrupt 와 병렬 도구 호출은 함께 사용하지 않습니다(재개 시 중복 호출 방지)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 리스트 업데이트\n",
    "tools_with_human = [human_assistance]\n",
    "\n",
    "# 새로운 그래프 구성\n",
    "graph_builder_hitl = StateGraph(State)\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm_with_human_tools = llm.bind_tools(tools_with_human)\n",
    "\n",
    "\n",
    "def chatbot_with_human(state: State):\n",
    "    \"\"\"Human Interuption 요청할 수 있는 챗봇\"\"\"\n",
    "    message = llm_with_human_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # interrupt 중 병렬 도구 호출 방지\n",
    "    # (재개 시 도구 호출이 반복되는 것을 방지)\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert (\n",
    "            len(message.tool_calls) <= 1\n",
    "        ), \"병렬 도구 호출은 interrupt와 함께 사용할 수 없습니다\"\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder_hitl.add_node(\"chatbot_with_human\", chatbot_with_human)\n",
    "\n",
    "# ToolNode 추가\n",
    "tool_node_hitl = ToolNode(tools=tools_with_human)\n",
    "graph_builder_hitl.add_node(\"tools\", tool_node_hitl)\n",
    "\n",
    "# 엣지 추가\n",
    "graph_builder_hitl.add_conditional_edges(\"chatbot_with_human\", tools_condition)\n",
    "graph_builder_hitl.add_edge(\"tools\", \"chatbot_with_human\")\n",
    "graph_builder_hitl.add_edge(START, \"chatbot_with_human\")\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "memory_hitl = InMemorySaver()\n",
    "graph_hitl = graph_builder_hitl.compile(checkpointer=memory_hitl)\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "### 🎬 HITL 테스트\n",
    "\n",
    "사람에게 조언을 요청하는 질문으로 interrupt 와 재개 흐름을 검증합니다.\n",
    "\n",
    "- **질문**: \"LangGraph 잘하고 싶은데, 사람에게 조언을 듣고 싶어요.\"  \n",
    "- **기대 흐름**: chatbot → tools(`human_assistance`) → interrupt → 재개(Command) → 답변 완성  \n",
    "- **확인 포인트**: 중단 지점, 체크포인트 ID, 재개 후 일관성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import random_uuid\n",
    "\n",
    "# 인간 지원을 요청하는 메시지\n",
    "user_input = \"LangGraph 가 뭐야? 사람한테 듣고 싶어.\"\n",
    "config_hitl = {\"configurable\": {\"thread_id\": random_uuid()}}\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "stream_graph(\n",
    "    graph_hitl,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=config_hitl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 확인 - 어느 노드에서 중단되었는지 확인\n",
    "snapshot = graph_hitl.get_state(config_hitl)\n",
    "print(f\"\\n📊 현재 상태:\")\n",
    "print(f\"  다음 실행할 노드: {snapshot.next}\")\n",
    "print(f\"  체크포인트 ID: {snapshot.config['configurable']['checkpoint_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인간의 응답으로 실행 재개\n",
    "human_response = \"\"\"## 전문가의 조언: \n",
    "- YouTube 테디노트: https://www.youtube.com/c/teddynote\n",
    "- 고급 개발자 강의 [패스트캠퍼스 RAG 비법노트](https://fastcampus.co.kr/data_online_teddy)\n",
    "\"\"\"\n",
    "\n",
    "# Command 객체로 재개\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "print(f\"\\n💡 사람의 응답: {human_response}\\n\")\n",
    "\n",
    "# 재개\n",
    "stream_graph(graph_hitl, inputs=human_command, config=config_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: 상태 커스터마이징\n",
    "\n",
    "## 🎯 목적\n",
    "메시지 외 업무 데이터까지 다루는 **커스텀 상태**와 **도구 기반 상태 업데이트**를 도입합니다.\n",
    "\n",
    "### 핵심 개념\n",
    "- **Custom State Fields**: 메시지 외 검토용/결과용 필드 추가\n",
    "- **State Updates from Tools**: 도구 결과로 상태 자동 갱신\n",
    "- **Manual State Updates**: 필요 시 수동으로 상태 수정\n",
    "\n",
    "### 아키텍처 패턴\n",
    "```\n",
    "사용자 입력 → 정보 수집(도구) → 임시 저장(State)\n",
    "             ↓\n",
    "           검토/수정 → 최종 결과(State)\n",
    "```\n",
    "\n",
    "### 기대 효과\n",
    "- **복합 상태 관리**, **프로세스 자동화**, **품질 보증**, **유연한 수정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "\n",
    "\n",
    "# 확장된 State 정의\n",
    "class CustomState(TypedDict):\n",
    "    \"\"\"커스텀 필드가 추가된 상태\"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    human_feedback: str  # 사람의 피드백"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-56",
   "metadata": {},
   "source": [
    "### 상태 업데이트 도구\n",
    "\n",
    "도구 실행 결과를 `Command(update=...)` 로 상태에 반영하는 패턴을 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def human_review(\n",
    "    human_feedback, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request human review for information.\"\"\"\n",
    "    # 인간에게 검토 요청\n",
    "    human_response = interrupt(\n",
    "        {\"question\": \"이 정보가 맞나요?\", \"human_feedback\": human_feedback}\n",
    "    )\n",
    "\n",
    "    feedback = human_response.get(\"human_feedback\", \"\")\n",
    "\n",
    "    if feedback.strip() == \"\":\n",
    "        # 사용자가 AI 의 답변에 동의하는 경우\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [ToolMessage(human_response, tool_call_id=tool_call_id)]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # 사용자가 AI 의 답변에 동의하지 않는 경우\n",
    "        corrected_information = f\"# 사용자에 의해 수정된 피드백: {feedback}\"\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    ToolMessage(corrected_information, tool_call_id=tool_call_id)\n",
    "                ]\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-58",
   "metadata": {},
   "source": [
    "### 커스텀 상태 그래프\n",
    "\n",
    "커스텀 필드를 포함한 `CustomState` 로 그래프를 구성하고, 도구를 통한 상태 업데이트 루프를 적용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 리스트\n",
    "tools_custom = [human_review]\n",
    "\n",
    "# 새로운 그래프 구성\n",
    "custom_graph_builder = StateGraph(CustomState)  # CustomState 사용\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm_with_custom_tools = llm.bind_tools(tools_custom)\n",
    "\n",
    "\n",
    "def chatbot_custom(state: CustomState):\n",
    "    \"\"\"커스텀 상태를 사용하는 챗봇\"\"\"\n",
    "    message = llm_with_custom_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert len(message.tool_calls) <= 1\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# 노드와 엣지 추가\n",
    "custom_graph_builder.add_node(\"chatbot\", chatbot_custom)\n",
    "tool_node_custom = ToolNode(tools=tools_custom)\n",
    "custom_graph_builder.add_node(\"tools\", tool_node_custom)\n",
    "\n",
    "custom_graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "custom_graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "custom_graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 컴파일\n",
    "memory_custom = InMemorySaver()\n",
    "custom_graph = custom_graph_builder.compile(checkpointer=memory_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-60",
   "metadata": {},
   "source": [
    "그래프 시각화로 노드와 조건부 분기, 루프 구성을 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 시각화\n",
    "visualize_graph(custom_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-62",
   "metadata": {},
   "source": [
    "### 커스텀 상태 테스트\n",
    "\n",
    "`human_review` 도구 호출에서 interrupt 로 중단된 뒤, 재개 시 상태가 올바르게 갱신되는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph의 출시일을 조사하고 검토 요청\n",
    "user_input = (\n",
    "    \"2024년 노벨 문학상 수상자가 누구인지 조사해주세요. \"\n",
    "    \"답을 찾으면 `human_review` 도구를 사용해서 검토를 요청하세요.\"\n",
    ")\n",
    "\n",
    "custom_config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "# 실행 (interrupt에서 중단될 것임)\n",
    "stream_graph(\n",
    "    custom_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=custom_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 최신 메시지 가져오기\n",
    "last_message = custom_graph.get_state(custom_config).values[\"messages\"][-1]\n",
    "\n",
    "# 최신 메시지 tree 구조로 표시\n",
    "display_message_tree(last_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 가 작성한 내용\n",
    "print(last_message.tool_calls[0][\"args\"][\"human_feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인간의 검토 응답으로 재개\n",
    "human_command = Command(\n",
    "    resume={\"human_feedback\": \"2024년 노벨 문학상 수상자는 대한민국의 한강 작가입니다.\"}\n",
    ")\n",
    "\n",
    "stream_graph(custom_graph, inputs=human_command, config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: 상태 이력 관리\n",
    "\n",
    "## 🎯 목적\n",
    "체크포인트 기반으로 상태를 저장/복원해 **롤백/재실행** 시나리오를 실습합니다.\n",
    "\n",
    "### 핵심 개념\n",
    "- **State History**: 상태 변경 이력 관리(추적/복원)  \n",
    "- **Checkpoint ID**: 특정 시점 식별자  \n",
    "- **Rollback**: 지정 시점으로 복원  \n",
    "- **Resume**: 복원 상태에서 재실행\n",
    "\n",
    "### 기대 효과\n",
    "- **안전한 실험**, **디버깅 효율**, **A/B 테스트**, **안정성 향상**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-68",
   "metadata": {},
   "source": [
    "### 체크포인트 기반 그래프 구성\n",
    "\n",
    "상태 이력 확인과 롤백/재실행을 위한 최소 구성으로 시작합니다.\n",
    "\n",
    "- **도구**: 검색(Tavily)  \n",
    "- **체크포인터**: InMemorySaver  \n",
    "- **이력 조회**: `get_state_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 관리 테스트를 위한 체크포인트 기반 그래프\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 도구와 LLM 설정\n",
    "tools = [TavilySearch(max_results=2)]\n",
    "llm_with_tools_tt = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot_tt(state: State):\n",
    "    \"\"\"상태 관리 테스트용 챗봇\"\"\"\n",
    "    return {\"messages\": [llm_with_tools_tt.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "graph_builder.add_node(\"chatbot\", chatbot_tt)\n",
    "tool_node_tt = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node_tt)\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "memory_tt = InMemorySaver()\n",
    "time_travel_graph = graph_builder.compile(checkpointer=memory_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-70",
   "metadata": {},
   "source": [
    "### 구조 시각화\n",
    "\n",
    "체크포인트 기반 그래프 구조를 시각화하여 분기와 루프를 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "visualize_graph(time_travel_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-72",
   "metadata": {},
   "source": [
    "### 체크포인트 시퀀스 생성\n",
    "\n",
    "여러 번 대화를 실행해 충분한 상태 이력을 만듭니다.\n",
    "\n",
    "- 체크포인트 1: 첫 대화 종료  \n",
    "- 체크포인트 2: 두 번째 대화 종료  \n",
    "- 체크포인트 3: 이후 확장(선택)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-73",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_travel_config = RunnableConfig(configurable={\"thread_id\": \"time-travel-1\"})\n",
    "\n",
    "# 첫 번째 대화\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"테디노트에 대해서 조사 좀 해주세요.\")]},\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 대화\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"테디노트 온라인 강의 주소를 조사해 해주세요.\")\n",
    "        ]\n",
    "    },\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-75",
   "metadata": {},
   "source": [
    "### 상태 이력 탐색 및 시점 선택\n",
    "\n",
    "`get_state_history` 로 이력을 조회하고, 롤백/재실행할 체크포인트를 선택합니다.\n",
    "\n",
    "- **조회 항목**: 다음 노드, 체크포인트 ID, 메시지 수  \n",
    "- **선택 기준**: 수정하고 싶은 단계 직후의 안정 시점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 상태 히스토리 확인\n",
    "print(\"📜 상태 히스토리 (최신순):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# to_replay 변수 초기화\n",
    "to_replay = None\n",
    "\n",
    "for i, state in enumerate(time_travel_graph.get_state_history(time_travel_config)):\n",
    "    print(f\"\\n[체크포인트 {i}]\")\n",
    "    print(f\"  다음 노드: {state.next}\")\n",
    "    print(f\"  체크포인트 ID: {state.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "    if len(state.values[\"messages\"]) == 6 and to_replay is None:\n",
    "        print(\"  ⭐ 이 상태로 되돌아갈 예정\")\n",
    "        display_message_tree(state.values[\"messages\"][-1])\n",
    "        to_replay = state\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-77",
   "metadata": {},
   "source": [
    "### 특정 체크포인트로 롤백\n",
    "\n",
    "선택한 체크포인트로 상태를 복원하여 이후 단계를 재실행할 준비를 합니다.\n",
    "\n",
    "- **대상**: 두 번째 검색 완료 시점  \n",
    "- **목적**: 검색 전략 변경 후 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-78",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-79",
   "metadata": {},
   "source": [
    "### 상태 수정 및 최적화\n",
    "\n",
    "복원된 상태에서 도구 호출 파라미터를 수정해 다른 결과를 유도합니다.\n",
    "\n",
    "- **예시 변경**: `query` 를 도메인 한정으로 수정(`site:...`)  \n",
    "- **목표**: 정확도 향상 및 결과 품질 비교(A/B)\n",
    "\n",
    "런타임 파라미터 수정은 재실행 비용을 줄이면서 최적화를 빠르게 검증할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import update_tool_call\n",
    "\n",
    "# 사용 예시:\n",
    "updated_message = update_tool_call(\n",
    "    to_replay.values[\"messages\"][-1],\n",
    "    tool_name=\"tavily_search\",\n",
    "    tool_args={\"query\": \"[LG전자 메뉴얼] 궤도 강의 youtube\", \"search_depth\": \"basic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경하기 전의 message\n",
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경한 이후의 메시지 트리\n",
    "display_message_tree(updated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경된 메시지를 update_state 로 업데이트\n",
    "updated_state = time_travel_graph.update_state(\n",
    "    values={\"messages\": [updated_message]}, config=to_replay.config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-84",
   "metadata": {},
   "source": [
    "### 수정 상태 재실행\n",
    "\n",
    "업데이트된 상태로 재실행하여 결과를 비교합니다.\n",
    "\n",
    "- **실행 방식**: 입력 없이 업데이트된 상태로 재개  \n",
    "- **비교 항목**: 원래 결과 vs 수정 후 결과  \n",
    "- **기대 효과**: 정확도 향상, 비용 절감, 빠른 실험 사이클"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업데이트된 메시지를 스트리밍 합니다.\n",
    "stream_graph(time_travel_graph, inputs=None, config=updated_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
