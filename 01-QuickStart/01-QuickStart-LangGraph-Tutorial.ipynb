{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🚀 LangGraph QuickStart 튜토리얼\n",
    "\n",
    "## 📚 개요\n",
    "\n",
    "이 튜토리얼은 LangGraph의 핵심 개념과 기능을 단계별로 학습하는 종합 가이드입니다. 기본 챗봇 구축부터 시작하여 도구 통합, 메모리 관리, Human-in-the-Loop, 상태 커스터마이징, 타임 트래블까지 LangGraph의 강력한 기능들을 체계적으로 익힐 수 있습니다.\n",
    "\n",
    "## 🎯 학습 목표\n",
    "\n",
    "1. **기본 챗봇 구축**: StateGraph를 사용한 기본적인 대화형 AI 구현\n",
    "2. **도구 통합**: 외부 API와 도구를 활용한 챗봇 기능 확장\n",
    "3. **메모리 관리**: 체크포인팅을 통한 대화 상태 유지\n",
    "4. **Human-in-the-Loop**: 인간 개입이 필요한 워크플로우 구현\n",
    "5. **상태 커스터마이징**: 복잡한 비즈니스 로직을 위한 상태 확장\n",
    "6. **타임 트래블**: 이전 상태로 되돌아가기 및 대체 경로 탐색\n",
    "\n",
    "## 🔑 주요 개념\n",
    "\n",
    "- **StateGraph**: 상태 기계로 챗봇 구조를 정의\n",
    "- **Node**: 작업 단위 (함수)\n",
    "- **Edge**: 노드 간 전환\n",
    "- **State**: 그래프 전체에서 공유되는 데이터\n",
    "- **Checkpointing**: 상태 저장 및 복원\n",
    "- **Tool**: 외부 기능 통합\n",
    "- **Human-in-the-Loop**: 인간 검토/승인 프로세스\n",
    "\n",
    "## 📋 사전 준비사항\n",
    "\n",
    "- Python 3.11 이상\n",
    "- OpenAI API 키\n",
    "- Tavily Search API 키 (Part 2에서 필요)\n",
    "- LangSmith API 키 (선택사항, 추적용)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 환경 설정\n",
    "\n",
    "먼저 필요한 패키지를 설치하고 환경을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY 정보로드\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"LangGraph-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: 기본 챗봇 구축 🤖\n",
    "\n",
    "이 섹션에서는 LangGraph를 사용하여 기본적인 챗봇을 구축합니다. 이 챗봇은 이후 튜토리얼에서 점진적으로 더 정교한 기능을 추가할 기반이 됩니다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "### StateGraph\n",
    "- 상태(State)로 챗봇의 구조를 정의\n",
    "- **노드(Nodes)**: LLM을 호출하거나 기능을 실행하는 단위\n",
    "- **엣지(Edges)**: 노드 간 전환 방법을 지정\n",
    "\n",
    "### State\n",
    "- 그래프의 스키마와 리듀서 함수를 포함\n",
    "- 메시지 리스트를 관리하며, 새 메시지는 기존 리스트에 추가됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의: 챗봇의 상태를 나타내는 타입\n",
    "class State(TypedDict):\n",
    "    \"\"\"챗봇의 상태를 정의하는 타입\n",
    "\n",
    "    messages: 대화 메시지 리스트\n",
    "    - add_messages 함수를 통해 새 메시지가 추가됨 (덮어쓰기가 아닌 추가)\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# StateGraph 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "print(\"✅ StateGraph 생성 완료!\")\n",
    "print(\"📌 State는 messages 키를 가지며, add_messages 리듀서를 사용합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM 선택 및 설정\n",
    "\n",
    "챗봇의 두뇌 역할을 할 언어 모델을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 선택\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "\n",
    "print(f\"✅ LLM 설정 완료: {llm.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 노드 추가\n",
    "\n",
    "**노드(Node)** 는 작업 단위이며, 일반적으로 함수로 구현됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"챗봇 노드 함수\n",
    "\n",
    "    현재 상태의 메시지를 받아 LLM에 전달하고,\n",
    "    응답을 새 메시지로 추가하여 반환합니다.\n",
    "    \"\"\"\n",
    "    # LLM을 호출하여 응답 생성\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # 응답을 메시지 리스트에 추가하여 반환\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 그래프에 노드 추가\n",
    "# 첫 번째 인자: 노드의 고유 이름\n",
    "# 두 번째 인자: 노드가 사용될 때 호출될 함수\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "print(\"✅ 챗봇 노드 추가 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진입점(Entry Point)과 종료점(Exit Point) 추가\n",
    "\n",
    "그래프가 어디서 시작하고 끝나는지 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 진입점: 그래프 실행이 시작되는 지점\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 종료점: 그래프 실행이 끝나는 지점\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "print(\"✅ 진입점과 종료점 설정 완료!\")\n",
    "print(\"📌 실행 흐름: START → chatbot → END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 컴파일\n",
    "\n",
    "그래프를 실행하기 전에 컴파일해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"✅ 그래프 컴파일 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 챗봇 실행\n",
    "\n",
    "이제 챗봇과 대화해봅시다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 질문 입력\n",
    "user_input = \"안녕하세요! LangGraph에 대해 알려주세요.\"\n",
    "\n",
    "# Config 설정(recursion_limit: 재귀 깊이 제한, thread_id: 스레드 아이디)\n",
    "config = RunnableConfig(recursion_limit=20, thread_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"안녕하세요! LangGraph에 대해 알려주세요.\")]\n",
    "}\n",
    "\n",
    "# 그래프 스트리밍\n",
    "stream_graph(graph, inputs=inputs, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: 도구(Tools) 추가 🔧\n",
    "\n",
    "챗봇이 \"기억\"에서 답할 수 없는 질문을 처리하기 위해 웹 검색 도구를 통합합니다. 이를 통해 챗봇이 실시간 정보를 찾아 더 나은 응답을 제공할 수 있습니다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "- **Tool Binding**: LLM에 도구 사용 방법 알려주기\n",
    "- **Tool Node**: 도구를 실행하는 노드\n",
    "- **Conditional Edges**: 조건에 따라 다른 노드로 라우팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Tavily 검색 도구 설정\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool]\n",
    "\n",
    "# 도구 테스트\n",
    "result = tool.invoke(\"LangGraph란 무엇인가요?\")\n",
    "print(f\"검색 결과 수: {len(result['results'])}개\")\n",
    "print(f\"첫 번째 결과 제목: {result['results'][0]['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도구를 사용하는 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State 정의 (동일)\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# 새로운 그래프 빌더 생성\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# LLM에 도구 바인딩 - LLM이 도구를 사용할 수 있도록 설정\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"도구를 사용할 수 있는 챗봇 노드\"\"\"\n",
    "    # 도구가 바인딩된 LLM 호출\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# 노드 추가\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ToolNode 추가 - 도구를 실행하는 노드\n",
    "tool_node = ToolNode(tools=tools)\n",
    "builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 조건부 엣지(Conditional Edges) 추가\n",
    "\n",
    "챗봇이 도구를 호출해야 할지 직접 응답할지 결정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 tools_condition 함수 상세 설명\n",
    "\n",
    "`tools_condition`은 LangGraph의 사전 정의된 조건 함수로, LLM의 응답에 도구 호출이 포함되어 있는지 확인합니다.\n",
    "\n",
    "#### 동작 방식\n",
    "\n",
    "```python\n",
    "def tools_condition(state) -> Literal[\"tools\", \"__end__\"]: \n",
    "    \"\"\"마지막 메시지에 tool_calls가 있는지 확인하여 라우팅을 결정합니다.\"\"\"\n",
    "    \n",
    "    # 1. 상태에서 마지막 메시지 추출\n",
    "    if isinstance(state, list):\n",
    "        ai_message = state[-1]\n",
    "    elif isinstance(state, dict) and \"messages\" in state:\n",
    "        ai_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # 2. 도구 호출 여부 확인\n",
    "    if hasattr(ai_message, \"tool_calls\") and len(ai_message.tool_calls) > 0:\n",
    "        return \"tools\"  # 도구 노드로 라우팅\n",
    "    \n",
    "    return \"__end__\"  # 종료\n",
    "```\n",
    "\n",
    "#### 핵심 포인트\n",
    "\n",
    "1. **자동 판단**: LLM이 도구를 호출해야 한다고 판단하면 `tool_calls` 필드가 생성됩니다\n",
    "2. **조건부 라우팅**: \n",
    "   - 도구 호출이 있으면 → `\"tools\"` 노드로 이동\n",
    "   - 도구 호출이 없으면 → `\"__end__\"`로 이동 (그래프 종료)\n",
    "3. **유연한 상태 처리**: 리스트, 딕셔너리, BaseModel 등 다양한 상태 형식 지원\n",
    "\n",
    "#### 실제 사용 예시\n",
    "\n",
    "```python\n",
    "# LLM이 검색이 필요하다고 판단한 경우\n",
    "# ai_message.tool_calls = [{\"name\": \"tavily_search\", \"args\": {\"query\": \"...\"}}, ...]\n",
    "# → tools_condition은 \"tools\"를 반환\n",
    "\n",
    "# LLM이 직접 답변할 수 있다고 판단한 경우\n",
    "# ai_message.tool_calls = []\n",
    "# → tools_condition은 \"__end__\"를 반환\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 조건부 엣지 추가\n",
    "# tools_condition은 메시지에 tool_calls가 있으면 \"tools\"로,\n",
    "# 없으면 END로 라우팅합니다\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # 사전 정의된 조건 함수 사용\n",
    ")\n",
    "\n",
    "# 도구 실행 후 다시 챗봇으로 돌아가기\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# 시작점 설정\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_with_tools = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 시각화\n",
    "visualize_graph(graph_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도구를 사용하는 챗봇 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "stream_graph(\n",
    "    graph_with_tools,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"2025년 LangGraph 사용 사례 알려주세요.\")]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: 메모리 추가 💾\n",
    "\n",
    "챗봇이 이전 대화 내용을 기억할 수 있도록 **체크포인팅(Checkpointing)** 을 추가합니다. 이를 통해 멀티턴 대화가 가능해집니다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "- **Checkpointer**: 상태를 저장하고 복원하는 메커니즘\n",
    "- **Thread ID**: 대화 세션을 구분하는 식별자\n",
    "- **Persistent State**: 여러 호출에 걸쳐 유지되는 상태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_teddynote.memory import create_memory_extractor\n",
    "import uuid\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "memory_extractor = create_memory_extractor(model=\"gpt-4.1\")\n",
    "\n",
    "\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig,\n",
    "    *,\n",
    "    store: BaseStore,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Call the LLM model and manage user memory.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): The current state containing messages.\n",
    "        config (RunnableConfig): The runnable configuration.\n",
    "        store (BaseStore): The memory store.\n",
    "    \"\"\"\n",
    "    # 마지막 메시지에서 user_id 추출\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    print(namespace)\n",
    "\n",
    "    # 유저의 메모리 검색\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([f\"{memory.key}: {memory.value}\" for memory in memories])\n",
    "    system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "    # 사용자가 기억 요청 시 메모리 저장\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"remember\" in last_message.content.lower():\n",
    "        result = memory_extractor.invoke({\"input\": str(state[\"messages\"][-1].content)})\n",
    "        for memory in result.memories:\n",
    "            print(memory)\n",
    "            print(\"-\" * 100)\n",
    "            store.put(namespace, str(uuid.uuid4()), {memory.key: memory.value})\n",
    "\n",
    "    # LLM 호출\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# 그래프 빌드\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "# 메모리 체크포인터 생성\n",
    "# 실제 프로덕션에서는 PostgresSaver 사용 권장\n",
    "memory_saver = InMemorySaver()\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph_with_memory = builder.compile(\n",
    "    checkpointer=memory_saver,\n",
    "    store=memory_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    msg,\n",
    "    thread_id=\"default\",\n",
    "    user_id=\"default\",\n",
    "):\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id + user_id,\n",
    "            \"user_id\": user_id,\n",
    "        }\n",
    "    }\n",
    "    print(f\"\\n[유저🙋] {msg}\")\n",
    "    stream_graph(\n",
    "        graph_with_memory,\n",
    "        inputs={\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "        config=config,\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"안녕? 내 이름은 테디야\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고?\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고?\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`remember` 라는 키워드를 입력하여 Long-term memory에 정보 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 테디야 remember\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이렇게 저장한 Long-term memory를 활용할 때는 thread_id 가 바뀌어도 주요 정보를 기억하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\"내 이름이 뭐라고 했더라?\", \"3\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메시지, thread_id, user_id 전달\n",
    "run_graph(\n",
    "    \"내 직업은 AI Engineer 야. 내 취미는 Netflix 보기 야. remember\", \"4\", \"someone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 스레드에서 실행\n",
    "run_graph(\"내 이름, 직업, 취미 알려줘\", \"100\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다른 user_id 로 실행한 경우\n",
    "run_graph(\"내 이름, 직업, 취미 알려줘\", \"100\", \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State 확인\n",
    "\n",
    "`get_state` 함수를 사용하여 저장된 상태를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 Config 설정\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"100\" + \"someone\",\n",
    "        \"user_id\": \"someone\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# 현재 상태 가져오기\n",
    "snapshot = graph_with_memory.get_state(config)\n",
    "\n",
    "print(\"📊 현재 상태 정보:\")\n",
    "print(f\"- 메시지 수: {len(snapshot.values['messages'])}개\")\n",
    "print(f\"- 체크포인트 ID: {snapshot.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "# 최근 메시지 몇 개 표시\n",
    "print(\"\\n[최근 메시지]\")\n",
    "for msg in snapshot.values[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, \"type\") else \"unknown\"\n",
    "    content = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "    print(f\"  [{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Human-in-the-Loop 🙋\n",
    "\n",
    "에이전트가 신뢰할 수 없거나 중요한 결정을 내릴 때 인간의 입력이 필요할 수 있습니다. LangGraph의 **interrupt** 기능을 사용하여 실행을 일시 중지하고 인간의 피드백을 받을 수 있습니다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "- **interrupt**: 실행을 일시 중지하는 함수\n",
    "- **Command**: 실행을 재개하고 데이터를 전달하는 객체\n",
    "- **Human Approval**: 인간 검토/승인 프로세스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from an expert(human).\"\"\"\n",
    "    # interrupt를 호출하여 실행 일시 중지\n",
    "    # 사람의 응답을 기다림\n",
    "    human_response = interrupt({\"query\": query})\n",
    "\n",
    "    # 사람의 응답 반환\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-the-Loop가 있는 그래프 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 리스트 업데이트\n",
    "tools_with_human = [human_assistance]\n",
    "\n",
    "# 새로운 그래프 구성\n",
    "graph_builder_hitl = StateGraph(State)\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm_with_human_tools = llm.bind_tools(tools_with_human)\n",
    "\n",
    "\n",
    "def chatbot_with_human(state: State):\n",
    "    \"\"\"Human Interuption 요청할 수 있는 챗봇\"\"\"\n",
    "    message = llm_with_human_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # interrupt 중 병렬 도구 호출 방지\n",
    "    # (재개 시 도구 호출이 반복되는 것을 방지)\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert (\n",
    "            len(message.tool_calls) <= 1\n",
    "        ), \"병렬 도구 호출은 interrupt와 함께 사용할 수 없습니다\"\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder_hitl.add_node(\"chatbot_with_human\", chatbot_with_human)\n",
    "\n",
    "# ToolNode 추가\n",
    "tool_node_hitl = ToolNode(tools=tools_with_human)\n",
    "graph_builder_hitl.add_node(\"tools\", tool_node_hitl)\n",
    "\n",
    "# 엣지 추가\n",
    "graph_builder_hitl.add_conditional_edges(\"chatbot_with_human\", tools_condition)\n",
    "graph_builder_hitl.add_edge(\"tools\", \"chatbot_with_human\")\n",
    "graph_builder_hitl.add_edge(START, \"chatbot_with_human\")\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "memory_hitl = InMemorySaver()\n",
    "graph_hitl = graph_builder_hitl.compile(checkpointer=memory_hitl)\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(graph_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human-in-the-Loop 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import random_uuid\n",
    "\n",
    "# 인간 지원을 요청하는 메시지\n",
    "user_input = \"LangGraph 잘하고 싶은데, 사람에게 조언을 듣고 싶어요.\"\n",
    "config_hitl = {\"configurable\": {\"thread_id\": random_uuid()}}\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "stream_graph(\n",
    "    graph_hitl,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=config_hitl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상태 확인 - 어느 노드에서 중단되었는지 확인\n",
    "snapshot = graph_hitl.get_state(config_hitl)\n",
    "print(f\"\\n📊 현재 상태:\")\n",
    "print(f\"  다음 실행할 노드: {snapshot.next}\")\n",
    "print(f\"  체크포인트 ID: {snapshot.config['configurable']['checkpoint_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인간의 응답으로 실행 재개\n",
    "human_response = \"\"\"## 전문가의 조언: \n",
    "- YouTube 테디노트: https://www.youtube.com/c/teddynote\n",
    "- 고급 개발자 강의 [패스트캠퍼스 RAG 비법노트](https://fastcampus.co.kr/data_online_teddy)\n",
    "\"\"\"\n",
    "\n",
    "# Command 객체로 재개\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "print(f\"\\n💡 사람의 응답: {human_response}\\n\")\n",
    "\n",
    "# 재개\n",
    "stream_graph(graph_hitl, inputs=human_command, config=config_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: 상태 커스터마이징 🎨\n",
    "\n",
    "메시지 리스트 외에 추가 필드를 상태에 추가하여 복잡한 동작을 정의할 수 있습니다. 예를 들어, 특정 정보를 저장하고 인간의 검토를 받는 워크플로우를 구현해봅시다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "- **Custom State Fields**: 상태에 커스텀 필드 추가\n",
    "- **State Updates from Tools**: 도구 내부에서 상태 업데이트\n",
    "- **Manual State Updates**: 수동으로 상태 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "\n",
    "\n",
    "# 확장된 State 정의\n",
    "class CustomState(TypedDict):\n",
    "    \"\"\"커스텀 필드가 추가된 상태\"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    human_feedback: str  # 사람의 피드백"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상태를 업데이트하는 도구"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def human_review(\n",
    "    human_feedback, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request human review for information.\"\"\"\n",
    "    # 인간에게 검토 요청\n",
    "    human_response = interrupt(\n",
    "        {\"question\": \"이 정보가 맞나요?\", \"human_feedback\": human_feedback}\n",
    "    )\n",
    "\n",
    "    feedback = human_response.get(\"human_feedback\", \"\")\n",
    "\n",
    "    if feedback.strip() == \"\":\n",
    "        # 사용자가 AI 의 답변에 동의하는 경우\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [ToolMessage(human_response, tool_call_id=tool_call_id)]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # 사용자가 AI 의 답변에 동의하지 않는 경우\n",
    "        corrected_information = f\"# 사용자에 의해 수정된 피드백: {feedback}\"\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    ToolMessage(corrected_information, tool_call_id=tool_call_id)\n",
    "                ]\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀 상태를 사용하는 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 도구 리스트\n",
    "tools_custom = [human_review]\n",
    "\n",
    "# 새로운 그래프 구성\n",
    "custom_graph_builder = StateGraph(CustomState)  # CustomState 사용\n",
    "\n",
    "# LLM에 도구 바인딩\n",
    "llm_with_custom_tools = llm.bind_tools(tools_custom)\n",
    "\n",
    "\n",
    "def chatbot_custom(state: CustomState):\n",
    "    \"\"\"커스텀 상태를 사용하는 챗봇\"\"\"\n",
    "    message = llm_with_custom_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert len(message.tool_calls) <= 1\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# 노드와 엣지 추가\n",
    "custom_graph_builder.add_node(\"chatbot\", chatbot_custom)\n",
    "tool_node_custom = ToolNode(tools=tools_custom)\n",
    "custom_graph_builder.add_node(\"tools\", tool_node_custom)\n",
    "\n",
    "custom_graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "custom_graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "custom_graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 컴파일\n",
    "memory_custom = InMemorySaver()\n",
    "custom_graph = custom_graph_builder.compile(checkpointer=memory_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그래프를 시각화 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 시각화\n",
    "visualize_graph(custom_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 커스텀 상태 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraph의 출시일을 조사하고 검토 요청\n",
    "user_input = (\n",
    "    \"2024년 노벨 문학상 수상자가 누구인지 조사해주세요. \"\n",
    "    \"답을 찾으면 `human_review` 도구를 사용해서 검토를 요청하세요.\"\n",
    ")\n",
    "\n",
    "custom_config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "# 실행 (interrupt에서 중단될 것임)\n",
    "stream_graph(\n",
    "    custom_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=custom_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# 최신 메시지 가져오기\n",
    "last_message = custom_graph.get_state(custom_config).values[\"messages\"][-1]\n",
    "\n",
    "# 최신 메시지 tree 구조로 표시\n",
    "display_message_tree(last_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 가 작성한 내용\n",
    "print(last_message.tool_calls[0][\"args\"][\"human_feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인간의 검토 응답으로 재개\n",
    "human_command = Command(\n",
    "    resume={\"human_feedback\": \"2024년 노벨 문학상 수상자는 대한민국의 한강 작가입니다.\"}\n",
    ")\n",
    "\n",
    "stream_graph(custom_graph, inputs=human_command, config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: 타임 트래블 ⏰\n",
    "\n",
    "LangGraph의 **타임 트래블** 기능을 사용하면 이전 체크포인트로 돌아가서 다른 경로를 탐색할 수 있습니다. 이는 디버깅, 실험, 대화형 애플리케이션에 매우 유용합니다.\n",
    "\n",
    "## 핵심 개념\n",
    "\n",
    "- **State History**: 모든 체크포인트의 기록\n",
    "- **Checkpoint ID**: 특정 시점의 식별자\n",
    "- **Rewind**: 이전 상태로 되돌리기\n",
    "- **Resume**: 특정 체크포인트에서 재개"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타임 트래블을 위한 그래프 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 타임 트래블 테스트를 위한 간단한 그래프\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 도구와 LLM 설정\n",
    "tools = [TavilySearch(max_results=2)]\n",
    "llm_with_tools_tt = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot_tt(state: State):\n",
    "    \"\"\"타임 트래블 테스트용 챗봇\"\"\"\n",
    "    return {\"messages\": [llm_with_tools_tt.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# 그래프 구성\n",
    "graph_builder.add_node(\"chatbot\", chatbot_tt)\n",
    "tool_node_tt = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node_tt)\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# 메모리와 함께 컴파일\n",
    "memory_tt = InMemorySaver()\n",
    "time_travel_graph = graph_builder.compile(checkpointer=memory_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시각화를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "visualize_graph(time_travel_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 여러 단계의 대화 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_travel_config = RunnableConfig(configurable={\"thread_id\": \"time-travel-1\"})\n",
    "\n",
    "# 첫 번째 대화\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"테디노트에 대해서 조사 좀 해주세요.\")]},\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 번째 대화\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"테디노트 온라인 강의 주소를 조사해 해주세요.\")\n",
    "        ]\n",
    "    },\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상태 히스토리 탐색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 상태 히스토리 확인\n",
    "print(\"📜 상태 히스토리 (최신순):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# to_replay 변수 초기화\n",
    "to_replay = None\n",
    "\n",
    "for i, state in enumerate(time_travel_graph.get_state_history(time_travel_config)):\n",
    "    print(f\"\\n[체크포인트 {i}]\")\n",
    "    print(f\"  다음 노드: {state.next}\")\n",
    "    print(f\"  체크포인트 ID: {state.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "    if len(state.values[\"messages\"]) == 6 and to_replay is None:\n",
    "        print(\"  ⭐ 이 상태로 되돌아갈 예정\")\n",
    "        display_message_tree(state.values[\"messages\"][-1])\n",
    "        to_replay = state\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특정 체크포인트에서 재개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`update_tool_call` 을 활용하여 검색할 쿼리를 수정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import update_tool_call\n",
    "\n",
    "# 사용 예시:\n",
    "updated_message = update_tool_call(\n",
    "    to_replay.values[\"messages\"][-1],\n",
    "    tool_name=\"tavily_search\",\n",
    "    tool_args={\"query\": \"테디노트 강의 site:fastcampus.co.kr\", \"search_depth\": \"basic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경하기 전의 message\n",
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경한 이후의 메시지 트리\n",
    "display_message_tree(updated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변경된 메시지를 update_state 로 업데이트\n",
    "updated_state = time_travel_graph.update_state(\n",
    "    values={\"messages\": [updated_message]}, config=to_replay.config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "업데이트된 메시지를 스트리밍 합니다. 여기서 `inputs` 는 `None` 으로 주고, `config` 는 `updated_state` 로 주어 Replay 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업데이트된 메시지를 스트리밍 합니다.\n",
    "stream_graph(time_travel_graph, inputs=None, config=updated_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
