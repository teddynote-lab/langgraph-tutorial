{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-00",
   "metadata": {},
   "source": [
    "# ğŸš€ LangGraph QuickStart - ì…ë¬¸ìë¥¼ ìœ„í•œ ì‹¤ì „ íŠœí† ë¦¬ì–¼\n",
    "\n",
    "## ğŸ¯ ëª©í‘œì™€ ëŒ€ìƒ\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **LangGraph**ë¥¼ ì²˜ìŒ ì ‘í•˜ëŠ” ë¶„ì„ ìœ„í•œ **ì‹¤ì „ ì¤‘ì‹¬ íŠœí† ë¦¬ì–¼** ì…ë‹ˆë‹¤. \n",
    "\n",
    "### ğŸ“‹ ì´ íŠœí† ë¦¬ì–¼ì—ì„œ ë§Œë“¤ ê¸°ëŠ¥\n",
    "\n",
    "- **ğŸ§  ê¸°ì–µë ¥**: ì´ì „ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ëŠ” ìƒíƒœ ê´€ë¦¬\n",
    "- **ğŸ” ê²€ìƒ‰ ì—°ë™**: ì™¸ë¶€ ê²€ìƒ‰ ë„êµ¬ë¡œ ìµœì‹  ì •ë³´ í™•ë³´  \n",
    "- **ğŸ™‹ ì¸ê°„ ê°œì…**: ìŠ¹ì¸ ê¸°ë°˜ Human-in-the-Loop\n",
    "- **âª ìƒíƒœ ì´ë ¥**: ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ë¡¤ë°± ë° ì¬ì‹¤í–‰\n",
    "\n",
    "### ğŸ—ï¸ ì§„í–‰ ë¡œë“œë§µ\n",
    "\n",
    "- **ë‹¨ê³„ 1: ê¸°ë³¸ ì±—ë´‡ êµ¬ì¶•** â€” StateGraph, ë©”ì‹œì§€ íë¦„\n",
    "- **ë‹¨ê³„ 2: ë„êµ¬ í†µí•©** â€” Tool ë°”ì¸ë”©, ì¡°ê±´ë¶€ ë¼ìš°íŒ…\n",
    "- **ë‹¨ê³„ 3: ë©”ëª¨ë¦¬ ì¶”ê°€** â€” ì²´í¬í¬ì¸íŠ¸, Thread ID\n",
    "- **ë‹¨ê³„ 4: Human-in-the-Loop** â€” interrupt, ìŠ¹ì¸ íë¦„\n",
    "- **ë‹¨ê³„ 5: ìƒíƒœ ì»¤ìŠ¤í„°ë§ˆì´ì§•** â€” ì»¤ìŠ¤í…€ State, Tool ì—…ë°ì´íŠ¸\n",
    "- **ë‹¨ê³„ 6: ìƒíƒœ ì´ë ¥ ê´€ë¦¬** â€” ì´ë ¥ íƒìƒ‰, ë¡¤ë°±, ì¬ì‹¤í–‰\n",
    "\n",
    "### ğŸ› ï¸ í•µì‹¬ ì»´í¬ë„ŒíŠ¸\n",
    "\n",
    "- **ğŸ—ï¸ StateGraph**: ëŒ€í™” í”„ë¡œì„¸ìŠ¤ ì •ì˜\n",
    "- **ğŸ”¨ Node**: ì‘ì—…ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ ë‹¨ìœ„\n",
    "- **ğŸ›¤ï¸ Edge**: ë…¸ë“œ ê°„ ì‹¤í–‰ ê²½ë¡œ\n",
    "- **ğŸ“ State**: ë©”ì‹œì§€ì™€ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì†Œ\n",
    "- **ğŸ’¾ Checkpointing**: ì‹¤í–‰ ì‹œì  ì €ì¥ ë° ë³µì›\n",
    "\n",
    "### âœ… í•™ìŠµ ì„±ê³¼\n",
    "\n",
    "- **ë‚˜ë§Œì˜ AI ë¹„ì„œ**ë¥¼ ì²˜ìŒë¶€í„° ëê¹Œì§€ êµ¬í˜„  \n",
    "- **LangGraph í•µì‹¬ ê°œë…**ì˜ ì‹¤ì „ ì´í•´  \n",
    "- **ì‹¤ë¬´ ì ìš© ê°€ëŠ¥í•œ êµ¬ì¡°**ì™€ íŒ¨í„´ í™•ë³´  \n",
    "- **í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜** ì„¤ê³„ ê°ê° ìŠµë“\n",
    "\n",
    "### ğŸ”§ ì¤€ë¹„ë¬¼\n",
    "\n",
    "- **Python 3.11 ì´ìƒ**  \n",
    "- **OpenAI API í‚¤**  \n",
    "- **Tavily Search API í‚¤**  \n",
    "- **LangSmith API í‚¤** (ì„ íƒ)\n",
    "\n",
    "### ğŸ“Œ ì§„í–‰ ë°©ì‹\n",
    "\n",
    "ì„¤ëª…ì€ ê°„ê²°í•˜ê²Œ, ì˜ˆì‹œëŠ” ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì½”ë“œë¡œ ì œê³µí•©ë‹ˆë‹¤. ê³¼ì¥ëœ í‘œí˜„ì€ ì§€ì–‘í•˜ê³ , í•„ìš”í•œ ê³³ì—ë§Œ ì´ëª¨ì§€ë¥¼ ì‚¬ìš©í•´ ê°€ë…ì„±ì„ ë†’ì˜€ìŠµë‹ˆë‹¤.  \n",
    "\n",
    "**í•¨ê»˜ êµ¬ì¶•í•´ë´…ì‹œë‹¤.** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-01",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ í™˜ê²½ ì„¤ì • - ìµœì†Œ ìš”êµ¬ì‚¬í•­ ì •ë¦¬\n",
    "\n",
    "ì‹¤í–‰ì— í•„ìš”í•œ ì„¤ì •ì„ ê°„ë‹¨íˆ ì •ë¦¬í•©ë‹ˆë‹¤. ê³¼í•œ ë¹„ìœ ëŠ” ìƒëµí•˜ê³  í•„ìš”í•œ í•­ëª©ë§Œ ë¹ ë¥´ê²Œ ë§ì¶¥ë‹ˆë‹¤. ğŸ‘‡\n",
    "\n",
    "### ğŸ”§ ì¤€ë¹„ í•­ëª©\n",
    "\n",
    "1. **ğŸ”‘ API í‚¤ ì„¤ì •** â€” OpenAI, Tavily, (ì„ íƒ) LangSmith\n",
    "2. **ğŸ“Š ì¶”ì  ì„¤ì •** â€” LangSmithë¡œ ì‹¤í–‰ ì¶”ì  (ì„ íƒ)\n",
    "\n",
    "### ğŸ’¡ ì´ìœ \n",
    "\n",
    "- **ğŸ”’ ë³´ì•ˆ**: í‚¤ë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ì•ˆì „í•˜ê²Œ ê´€ë¦¬\n",
    "- **ğŸ“ˆ ëª¨ë‹ˆí„°ë§**: ì‹¤í–‰ ê²½ë¡œì™€ ë¹„ìš© ì¶”ì \n",
    "- **ğŸ› ë””ë²„ê¹…**: ì˜¤ë¥˜ ë°œìƒ ì§€ì  ì‹ ì† íŒŒì•…\n",
    "\n",
    "ë°”ë¡œ ì´ì–´ì„œ ì„¤ì •ì„ ì§„í–‰í•©ë‹ˆë‹¤. ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEYë¥¼ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ê¸° ìœ„í•œ ì„¤ì • íŒŒì¼\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# API KEY ì •ë³´ë¡œë“œ\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith ì¶”ì ì„ ì„¤ì •í•©ë‹ˆë‹¤. https://smith.langchain.com\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì´ë¦„ì„ ì…ë ¥í•©ë‹ˆë‹¤.\n",
    "logging.langsmith(\"LangGraph-Tutorial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-04",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: ê¸°ë³¸ ì±—ë´‡ êµ¬ì¶• ğŸ¤–\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "\n",
    "ê°€ì¥ ë‹¨ìˆœí•œ í˜•íƒœì˜ **ë©”ì‹œì§€ ê¸°ë°˜ ì±—ë´‡**ì„ êµ¬ì„±í•©ë‹ˆë‹¤. ë¶ˆí•„ìš”í•œ ìˆ˜ì‚¬ëŠ” ì¤„ì´ê³ , êµ¬ì¡°ì™€ íë¦„ì„ ëª…í™•íˆ ë³´ì—¬ë“œë¦½ë‹ˆë‹¤.\n",
    "\n",
    "### êµ¬ì„± ìš”ì†Œ\n",
    "\n",
    "- **ğŸ—ï¸ StateGraph**: ì „ì²´ íë¦„ ì •ì˜\n",
    "- **ğŸ“ State**: ë©”ì‹œì§€ ì €ì¥ êµ¬ì¡°\n",
    "- **ğŸ”¨ Node**: ì²˜ë¦¬ í•¨ìˆ˜ (LLM í˜¸ì¶œ)\n",
    "- **ğŸ›¤ï¸ Edge**: ì‹¤í–‰ ê²½ë¡œ ì—°ê²°\n",
    "- **âš™ï¸ Compile/Invoke**: ì‹¤í–‰ ì¤€ë¹„ ë° í˜¸ì¶œ\n",
    "\n",
    "### ì™œ ì´ë ‡ê²Œ êµ¬ì„±í•˜ë‚˜ìš”?\n",
    "\n",
    "- **í™•ì¥ì„±**: ê¸°ëŠ¥ ì¶”ê°€ê°€ ìš©ì´\n",
    "- **ê°€ë…ì„±**: ì²˜ë¦¬ ë‹¨ê³„ë¥¼ ë¶„ë¦¬í•´ ì´í•´ ìš©ì´  \n",
    "- **ìš´ì˜ì„±**: ì¥ì•  êµ¬ê°„ì„ ë¹ ë¥´ê²Œ ì‹ë³„ ê°€ëŠ¥\n",
    "\n",
    "ì´ì œ ë°”ë¡œ êµ¬í˜„ìœ¼ë¡œ ë“¤ì–´ê°‘ë‹ˆë‹¤. ğŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State ì •ì˜: ì±—ë´‡ì˜ ìƒíƒœë¥¼ ë‚˜íƒ€ë‚´ëŠ” íƒ€ì…\n",
    "class State(TypedDict):\n",
    "    \"\"\"ì±—ë´‡ì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” íƒ€ì…\n",
    "\n",
    "    messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸\n",
    "    - add_messages í•¨ìˆ˜ë¥¼ í†µí•´ ìƒˆ ë©”ì‹œì§€ê°€ ì¶”ê°€ë¨ (ë®ì–´ì“°ê¸°ê°€ ì•„ë‹Œ ì¶”ê°€)\n",
    "    \"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# StateGraph ìƒì„±\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "print(\"âœ… StateGraph ìƒì„± ì™„ë£Œ!\")\n",
    "print(\"ğŸ“Œ StateëŠ” messages í‚¤ë¥¼ ê°€ì§€ë©°, add_messages ë¦¬ë“€ì„œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-06",
   "metadata": {},
   "source": [
    "### ğŸ§  LLM ì„ íƒ ë° ì„¤ì •\n",
    "\n",
    "ì‹¤ìŠµì—ì„œëŠ” **GPT-4.1**ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ëª©ì ì€ ì•ˆì •ì ì¸ ë‹µë³€ì´ë¯€ë¡œ `temperature=0` ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ëª¨ë¸**: gpt-4.1  \n",
    "- **ì „ëµ**: ì¼ê´€ì„± ìš°ì„  (ì°½ì˜ì„± ìµœì†Œí™”)  \n",
    "- **ì´ìœ **: íŠœí† ë¦¬ì–¼ ì¬í˜„ì„±ê³¼ ê²€ì¦ ìš©ì´ì„± í™•ë³´\n",
    "\n",
    "í•„ìš” ì‹œ, ì¡°ì§ í™˜ê²½ì˜ ëª¨ë¸ë¡œ êµì²´í•´ë„ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM ì„ íƒ\n",
    "from langchain_openai import ChatOpenAI, AzureChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "llm = ChatOpenAI(model=\"gpt-4.1\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-08",
   "metadata": {},
   "source": [
    "### ğŸ”¨ ì±—ë´‡ ë…¸ë“œ ì¶”ê°€\n",
    "\n",
    "ëŒ€í™” ë©”ì‹œì§€ë¥¼ ì…ë ¥ë°›ì•„ LLMì— ì „ë‹¬í•˜ê³ , ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ìƒíƒœì— ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì…ë ¥**: `State[\"messages\"]`  \n",
    "- **ì²˜ë¦¬**: LLM í˜¸ì¶œ í›„ ì‘ë‹µ ìƒì„±  \n",
    "- **ì¶œë ¥**: ìƒˆ ë©”ì‹œì§€ 1ê°œ ì¶”ê°€\n",
    "\n",
    "í•„ìš”í•œ ìµœì†Œ ì„¤ëª…ë§Œìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: State):\n",
    "    \"\"\"ì±—ë´‡ ë…¸ë“œ í•¨ìˆ˜\n",
    "\n",
    "    í˜„ì¬ ìƒíƒœì˜ ë©”ì‹œì§€ë¥¼ ë°›ì•„ LLMì— ì „ë‹¬í•˜ê³ ,\n",
    "    ì‘ë‹µì„ ìƒˆ ë©”ì‹œì§€ë¡œ ì¶”ê°€í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # LLMì„ í˜¸ì¶œí•˜ì—¬ ì‘ë‹µ ìƒì„±\n",
    "    response = llm.invoke(state[\"messages\"])\n",
    "\n",
    "    # ì‘ë‹µì„ ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€í•˜ì—¬ ë°˜í™˜\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ì— ë…¸ë“œ ì¶”ê°€\n",
    "# ì²« ë²ˆì§¸ ì¸ì: ë…¸ë“œì˜ ê³ ìœ  ì´ë¦„\n",
    "# ë‘ ë²ˆì§¸ ì¸ì: ë…¸ë“œê°€ ì‚¬ìš©ë  ë•Œ í˜¸ì¶œë  í•¨ìˆ˜\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "### ğŸšª ì§„ì…ì ê³¼ ì¢…ë£Œì  ì„¤ì •\n",
    "\n",
    "ì‹¤í–‰ ê²½ë¡œë¥¼ ëª…í™•íˆ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **START**: ì…ë ¥ ìˆ˜ì‹   \n",
    "- **chatbot**: LLM í˜¸ì¶œ ë° ì‘ë‹µ ìƒì„±  \n",
    "- **END**: ê²°ê³¼ ë°˜í™˜\n",
    "\n",
    "ê°€ì¥ ë‹¨ìˆœí•œ ì‹¤í–‰ íë¦„ì„ ë¨¼ì € ì™„ì„±í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì§„ì…ì : ê·¸ë˜í”„ ì‹¤í–‰ì´ ì‹œì‘ë˜ëŠ” ì§€ì \n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ì¢…ë£Œì : ê·¸ë˜í”„ ì‹¤í–‰ì´ ëë‚˜ëŠ” ì§€ì \n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "print(\"âœ… ì§„ì…ì ê³¼ ì¢…ë£Œì  ì„¤ì • ì™„ë£Œ!\")\n",
    "print(\"ğŸ“Œ ì‹¤í–‰ íë¦„: START â†’ chatbot â†’ END\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "### âš¡ ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "\n",
    "êµ¬ì„±í•œ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì»´íŒŒì¼í•©ë‹ˆë‹¤. ì‚¬ì „ ê²€ì¦ì„ í†µí•´ ëŸ°íƒ€ì„ ì˜¤ë¥˜ë¥¼ ì¤„ì´ê³ , ì‹¤í–‰ ì¤€ë¹„ë¥¼ ë§ˆì¹©ë‹ˆë‹¤.\n",
    "\n",
    "- **ê²€ì¦**: ì—°ê²° ê´€ê³„, ì˜ì¡´ì„± í™•ì¸  \n",
    "- **ìµœì í™”**: ì‹¤í–‰ ì¤€ë¹„ ë° ì„±ëŠ¥ ê¸°ë³¸ íŠœë‹  \n",
    "- **ì•ˆì •ì„±**: ì‚¬ì „ ê²€ì‚¬ë¡œ ì˜¤ë¥˜ ê°€ëŠ¥ì„± ì¶•ì†Œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "print(\"âœ… ê·¸ë˜í”„ ì»´íŒŒì¼ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "### ğŸ‘€ ê·¸ë˜í”„ ì‹œê°í™”\n",
    "\n",
    "êµ¬ì„±í•œ ê·¸ë˜í”„ë¥¼ ì‹œê°í™”í•´ êµ¬ì¡°ë¥¼ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë…¸ë“œ**: ì²˜ë¦¬ ë‹¨ìœ„  \n",
    "- **ì—£ì§€**: ì‹¤í–‰ ê²½ë¡œ  \n",
    "- **START/END**: ì‹œì‘/ì¢…ë£Œ í¬ì¸íŠ¸\n",
    "\n",
    "ì‹œê°í™”ëŠ” êµ¬ì¡° ê²€ì¦ê³¼ ì´í•´ë¥¼ ë¹ ë¥´ê²Œ ë•ìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.graphs import visualize_graph\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "### ğŸ‰ ì±—ë´‡ ì‹¤í–‰\n",
    "\n",
    "ê°„ë‹¨í•œ ì§ˆë¬¸ìœ¼ë¡œ ê·¸ë˜í”„ë¥¼ ì‹¤í–‰í•´ ì •ìƒ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì§ˆë¬¸ ì˜ˆì‹œ**: \"LangGraphì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”\"  \n",
    "- **íë¦„**: START â†’ chatbot â†’ END  \n",
    "- **ì£¼ì˜**: `recursion_limit`, `thread_id` ë“± ì„¤ì •ê°’ì€ ì¬í˜„ì„±ì— ì˜í–¥ì„ ì¤ë‹ˆë‹¤.\n",
    "\n",
    "ë°”ë¡œ ì‹¤í–‰í•´ë³´ê² ìŠµë‹ˆë‹¤. ğŸ§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# ì§ˆë¬¸ ì…ë ¥\n",
    "user_input = \"ì•ˆë…•í•˜ì„¸ìš”! LangGraphì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# Config ì„¤ì •(recursion_limit: ì¬ê·€ ê¹Šì´ ì œí•œ, thread_id: ìŠ¤ë ˆë“œ ì•„ì´ë””)\n",
    "config = RunnableConfig(recursion_limit=20, thread_id=\"abc123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"messages\": [HumanMessage(content=\"ì•ˆë…•í•˜ì„¸ìš”! LangGraphì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”.\")]\n",
    "}\n",
    "\n",
    "# ê·¸ë˜í”„ ìŠ¤íŠ¸ë¦¬ë°\n",
    "stream_graph(graph, inputs=inputs, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: ë„êµ¬(Tools) ì¶”ê°€ ğŸ”§\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ìš”ì²­ì— ëŒ€ì‘í•˜ê¸° ìœ„í•´ ì™¸ë¶€ ê²€ìƒ‰ ë„êµ¬ë¥¼ í†µí•©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì™œ í•„ìš”í•œê°€\n",
    "- **ì§€ì‹ í•œê³„ ë³´ì™„**: ëª¨ë¸ í•™ìŠµ ì‹œì  ì´í›„ì˜ ì •ë³´ ì¡°íšŒ\n",
    "- **íŒ©íŠ¸ ì²´í¬**: ì¶œì²˜ ê¸°ë°˜ ê²€ì¦ ê°•í™”\n",
    "- **ì‹¤ë¬´ ì¹œí™”ì„±**: ìµœì‹  ë°ì´í„° ê¸°ë°˜ ì‘ë‹µ\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **Tool Binding**: LLMì´ ë„êµ¬ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë„ë¡ ì—°ê²°\n",
    "- **Tool Node**: ì™¸ë¶€ API í˜¸ì¶œì„ ë‹´ë‹¹í•˜ëŠ” ë…¸ë“œ\n",
    "- **Conditional Edges**: ë„êµ¬ ì‚¬ìš© ì—¬ë¶€ë¥¼ ìë™ìœ¼ë¡œ ë¶„ê¸°\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- **ì‹¤ì‹œê°„ì„±**, **ì •í™•ì„±**, **í™•ì¥ì„±** í–¥ìƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê³µìœ \n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"add two numbers\"\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_tavily import TavilySearch\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Tavily ê²€ìƒ‰ ë„êµ¬ ì„¤ì •\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, add]\n",
    "\n",
    "# ë„êµ¬ í…ŒìŠ¤íŠ¸\n",
    "result = tool.invoke(\"LangGraphë€ ë¬´ì—‡ì¸ê°€ìš”?\")\n",
    "print(f\"ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(result['results'])}ê°œ\")\n",
    "print(f\"ì²« ë²ˆì§¸ ê²°ê³¼ ì œëª©: {result['results'][0]['title']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ ë„êµ¬ ì‚¬ìš© ê·¸ë˜í”„ êµ¬ì„±\n",
    "\n",
    "ê¸°ë³¸ íë¦„ì— ë„êµ¬ í˜¸ì¶œ ê²½ë¡œë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ê¸°ì¡´: ì‚¬ìš©ì â†’ chatbot â†’ END\n",
    "- ë³€ê²½: ì‚¬ìš©ì â†’ chatbot â‡„ tools â†’ chatbot â†’ END\n",
    "\n",
    "í•µì‹¬ ìš”ì†Œ\n",
    "- **Tool ë°”ì¸ë”©**  \n",
    "- **ToolNode ì¶”ê°€**  \n",
    "- **ì¡°ê±´ë¶€ ë¶„ê¸° ì ìš©**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret1 = llm_with_tools.invoke(\"LangGraph ê°€ ë­ì•¼?\")\n",
    "ret2 = llm_with_tools.invoke(\"LangGraph ê°€ ë­ì•¼? ê²€ìƒ‰í•´ì„œ ì•Œë ¤ì¤˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "display_message_tree(ret1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_message_tree(ret2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "# State ì •ì˜ (ë™ì¼)\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "# ìƒˆë¡œìš´ ê·¸ë˜í”„ ë¹Œë” ìƒì„±\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# LLMì— ë„êµ¬ ë°”ì¸ë”© - LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    \"\"\"ë„êµ¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì±—ë´‡ ë…¸ë“œ\"\"\"\n",
    "    # ë„êµ¬ê°€ ë°”ì¸ë”©ëœ LLM í˜¸ì¶œ\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# ToolNode ì¶”ê°€ - ë„êµ¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë…¸ë“œ\n",
    "tool_node = ToolNode(tools=tools)\n",
    "builder.add_node(\"tools\", tool_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "### ğŸš¦ ì¡°ê±´ë¶€ ë¼ìš°íŒ…(Conditional Edges)\n",
    "\n",
    "ìš”ì²­ì— ë”°ë¼ ìë™ìœ¼ë¡œ ê²½ë¡œë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì™¸ë¶€ ê²€ìƒ‰ í•„ìš”**: \"tools\" ë¡œ ì´ë™  \n",
    "- **ë‚´ë¶€ ì²˜ë¦¬ ê°€ëŠ¥**: ì¢…ë£Œ\n",
    "\n",
    "í•µì‹¬: `tools_condition` ì´ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì˜ `tool_calls` ì¡´ì¬ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ êµ¬ì¡°ë¡œ ë¶ˆí•„ìš”í•œ ë„êµ¬ í˜¸ì¶œì„ ì¤„ì´ê³  ì‘ë‹µ ì†ë„ë¥¼ í™•ë³´í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "### ğŸ” tools_condition ë™ì‘ ìš”ì•½\n",
    "\n",
    "`tools_condition` ì€ ë§ˆì§€ë§‰ AI ë©”ì‹œì§€ì— ë„êµ¬ í˜¸ì¶œì´ ìˆëŠ”ì§€ í™•ì¸í•´ ë¶„ê¸°í•©ë‹ˆë‹¤.\n",
    "\n",
    "- `tool_calls` ìˆìŒ â†’ \"tools\"  \n",
    "- `tool_calls` ì—†ìŒ â†’ \"__end__\"\n",
    "\n",
    "ê°„ë‹¨í•œ êµ¬í˜„ ì˜ˆì‹œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "```python\n",
    "def tools_condition(state) -> Literal[\"tools\", \"__end__\"]:\n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ ì¶”ì¶œ\n",
    "    ai_message = state[-1] if isinstance(state, list) else state[\"messages\"][-1]\n",
    "    # ë¶„ê¸° íŒë‹¨\n",
    "    return \"tools\" if getattr(ai_message, \"tool_calls\", []) else \"__end__\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€\n",
    "# tools_conditionì€ ë©”ì‹œì§€ì— tool_callsê°€ ìˆìœ¼ë©´ \"tools\"ë¡œ,\n",
    "# ì—†ìœ¼ë©´ ENDë¡œ ë¼ìš°íŒ…í•©ë‹ˆë‹¤\n",
    "builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # ì‚¬ì „ ì •ì˜ëœ ì¡°ê±´ í•¨ìˆ˜ ì‚¬ìš©\n",
    ")\n",
    "\n",
    "# ë„êµ¬ ì‹¤í–‰ í›„ ë‹¤ì‹œ ì±—ë´‡ìœ¼ë¡œ ëŒì•„ê°€ê¸°\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# ì‹œì‘ì  ì„¤ì •\n",
    "builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph_with_tools = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-26",
   "metadata": {},
   "source": [
    "### ğŸ‘€ ì—…ê·¸ë ˆì´ë“œ ê·¸ë˜í”„ ì‹œê°í™”\n",
    "\n",
    "ë³€ê²½ëœ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•´ ë¶„ê¸°ì™€ ë£¨í”„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- ìƒˆ ë…¸ë“œ: `tools`  \n",
    "- ë¶„ê¸°: `chatbot` â†’ íŒë‹¨ â†’ `tools` ë˜ëŠ” ì¢…ë£Œ  \n",
    "- ë£¨í”„: `tools` â†’ `chatbot`\n",
    "\n",
    "ì‹œê°í™”ë¥¼ í†µí•´ ì„¤ì •ì´ ì˜ë„ëŒ€ë¡œ ì ìš©ë˜ì—ˆëŠ”ì§€ ë¹ ë¥´ê²Œ ê²€ì¦í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(graph_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "### ğŸš€ ë„êµ¬ ì‚¬ìš© í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì‹œê°„ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸ìœ¼ë¡œ ë™ì‘ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì˜ˆì‹œ ì§ˆë¬¸**: \"2025ë…„ LangGraph ì‚¬ìš© ì‚¬ë¡€ ì•Œë ¤ì£¼ì„¸ìš”.\"  \n",
    "- **ê¸°ëŒ€ íë¦„**: `chatbot` â†’ `tools` â†’ `chatbot` â†’ END  \n",
    "- **í™•ì¸ í¬ì¸íŠ¸**: ê²€ìƒ‰ í˜¸ì¶œ ì—¬ë¶€, ê²°ê³¼ ì •ë¦¬ í’ˆì§ˆ, ì‘ë‹µ ìì—°ìŠ¤ëŸ¬ì›€\n",
    "\n",
    "ì´ì œ ì‹¤í–‰í•´ ê²°ê³¼ë¥¼ í™•ì¸í•©ë‹ˆë‹¤. ğŸ§ª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "stream_graph(\n",
    "    graph_with_tools,\n",
    "    inputs={\n",
    "        \"messages\": [HumanMessage(content=\"2025ë…„ LangGraph ì‚¬ìš© ì‚¬ë¡€ ì•Œë ¤ì£¼ì„¸ìš”.\")]\n",
    "    },\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-30",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: ë©”ëª¨ë¦¬ ì¶”ê°€ ğŸ’¾\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ì„¸ì…˜ ê°„ì—ë„ ì‚¬ìš©ì ì •ë³´ë¥¼ ìœ ì§€í•˜ëŠ” **ì˜êµ¬ ìƒíƒœ ê´€ë¦¬**ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "### Before\n",
    "- ì„¸ì…˜ì´ ë°”ë€Œë©´ ì´ì „ ì •ë³´ ì†Œì‹¤\n",
    "\n",
    "### After\n",
    "- ì‚¬ìš©ìë³„ë¡œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì €ì¥í•˜ê³  ì¬ì‚¬ìš©\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **ğŸ’¾ Checkpointer**: ëŒ€í™” ìƒíƒœ ì €ì¥/ë³µì›\n",
    "- **ğŸ·ï¸ Thread ID**: ì„¸ì…˜ ì‹ë³„ì\n",
    "- **ğŸ—‚ï¸ Persistent State**: ëˆ„ì  ì´ë ¥ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- **ì—°ì† ëŒ€í™”**, **ê°œì¸í™”**, **ì»¨í…ìŠ¤íŠ¸ ì•ˆì •ì„±**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "import os\n",
    "\n",
    "\n",
    "# Pydantic ëª¨ë¸ ì •ì˜\n",
    "class MemoryItem(BaseModel):\n",
    "    \"\"\"ê°œë³„ ë©”ëª¨ë¦¬ ì•„ì´í…œ\"\"\"\n",
    "\n",
    "    key: str = Field(description=\"ë©”ëª¨ë¦¬ í‚¤ (ì˜ˆ: user_name, preference, fact)\")\n",
    "    value: str = Field(description=\"ë©”ëª¨ë¦¬ ê°’\")\n",
    "    category: str = Field(\n",
    "        description=\"ì¹´í…Œê³ ë¦¬ (personal_info, preference, interest, relationship, fact, etc.)\"\n",
    "    )\n",
    "    importance: int = Field(description=\"ì¤‘ìš”ë„ (1-5, 5ê°€ ê°€ì¥ ì¤‘ìš”)\", ge=1, le=5)\n",
    "    confidence: float = Field(description=\"ì¶”ì¶œ ì‹ ë¢°ë„ (0.0-1.0)\", ge=0.0, le=1.0)\n",
    "\n",
    "\n",
    "class ExtractedMemories(BaseModel):\n",
    "    \"\"\"ì¶”ì¶œëœ ë©”ëª¨ë¦¬ ì»¬ë ‰ì…˜\"\"\"\n",
    "\n",
    "    memories: List[MemoryItem] = Field(description=\"ì¶”ì¶œëœ ë©”ëª¨ë¦¬ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸\")\n",
    "    summary: str = Field(description=\"ëŒ€í™” ë‚´ìš© ìš”ì•½\")\n",
    "    timestamp: str = Field(\n",
    "        default_factory=lambda: datetime.now().isoformat(), description=\"ì¶”ì¶œ ì‹œê°„\"\n",
    "    )\n",
    "\n",
    "\n",
    "# ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸\n",
    "DEFAULT_SYSTEM_PROMPT = \"\"\"You are an expert memory extraction assistant. Your task is to extract important information from user conversations and convert them into structured key-value pairs for long-term memory storage.\n",
    "\n",
    "Extract ALL relevant information from the conversation, including:\n",
    "- Personal information (name, age, location, occupation, etc.)\n",
    "- Preferences and interests\n",
    "- Relationships and social connections\n",
    "- Important facts or events mentioned\n",
    "- Opinions and beliefs\n",
    "- Goals and aspirations\n",
    "- Any other notable information\n",
    "\n",
    "For each piece of information:\n",
    "1. Create a concise, searchable key\n",
    "2. Store the complete value\n",
    "3. Categorize appropriately\n",
    "4. Assess importance (1-5 scale)\n",
    "5. Evaluate extraction confidence (0.0-1.0)\"\"\"\n",
    "\n",
    "\n",
    "def create_memory_extractor(\n",
    "    model: Optional[str] = \"gpt-4.1\",\n",
    "    system_prompt: Optional[str] = None,\n",
    ") -> any:\n",
    "    \"\"\"\n",
    "    ë©”ëª¨ë¦¬ ì¶”ì¶œê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "\n",
    "    Args:\n",
    "        model: ì‚¬ìš©í•  ì–¸ì–´ ëª¨ë¸. Noneì¼ ê²½ìš° ê¸°ë³¸ ChatOpenAI ëª¨ë¸ ì‚¬ìš©\n",
    "        system_prompt: ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸. Noneì¼ ê²½ìš° ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©\n",
    "\n",
    "    Returns:\n",
    "        ë©”ëª¨ë¦¬ ì¶”ì¶œ ì²´ì¸\n",
    "    \"\"\"\n",
    "    # Output Parser ìƒì„±\n",
    "    memory_parser = PydanticOutputParser(pydantic_object=ExtractedMemories)\n",
    "\n",
    "    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •\n",
    "    if system_prompt is None:\n",
    "        system_prompt = DEFAULT_SYSTEM_PROMPT\n",
    "\n",
    "    # ì „ì²´ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±\n",
    "    template = f\"\"\"{system_prompt}\n",
    "\n",
    "User Input: {{input}}\n",
    "\n",
    "{{format_instructions}}\n",
    "\n",
    "Remember to:\n",
    "- Extract multiple memory items if the conversation contains various pieces of information\n",
    "- Use clear, consistent key naming conventions\n",
    "- Preserve context in values when necessary\n",
    "- Be comprehensive but avoid redundancy\n",
    "\"\"\"\n",
    "\n",
    "    # í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "    prompt = ChatPromptTemplate.from_template(\n",
    "        template,\n",
    "        partial_variables={\n",
    "            \"format_instructions\": memory_parser.get_format_instructions()\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # ëª¨ë¸ ì„¤ì •\n",
    "    model = AzureChatOpenAI(\n",
    "        deployment_name=\"gpt-4.1-mini\",  # ì‚¬ìš©í•˜ëŠ” ëª¨ë¸ëª…(deployment_name)\n",
    "        api_version=\"2024-12-01-preview\",\n",
    "        azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "    )\n",
    "\n",
    "    # ë©”ëª¨ë¦¬ ì¶”ì¶œ ì²´ì¸ ìƒì„±\n",
    "    memory_extractor = prompt | model | memory_parser\n",
    "\n",
    "    return memory_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_teddynote.memory import create_memory_extractor\n",
    "import uuid\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4.1\", temperature=0)\n",
    "memory_extractor = create_memory_extractor(model=\"gpt-4.1\")\n",
    "\n",
    "\n",
    "def call_model(\n",
    "    state: MessagesState,\n",
    "    config: RunnableConfig,\n",
    "    *,\n",
    "    store: BaseStore,\n",
    ") -> dict[str, Any]:\n",
    "    \"\"\"Call the LLM model and manage user memory.\n",
    "\n",
    "    Args:\n",
    "        state (MessagesState): The current state containing messages.\n",
    "        config (RunnableConfig): The runnable configuration.\n",
    "        store (BaseStore): The memory store.\n",
    "    \"\"\"\n",
    "    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ user_id ì¶”ì¶œ\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    print(namespace)\n",
    "\n",
    "    # ìœ ì €ì˜ ë©”ëª¨ë¦¬ ê²€ìƒ‰\n",
    "    memories = store.search(namespace, query=str(state[\"messages\"][-1].content))\n",
    "    info = \"\\n\".join([f\"{memory.key}: {memory.value}\" for memory in memories])\n",
    "    system_msg = f\"You are a helpful assistant talking to the user. User info: {info}\"\n",
    "\n",
    "    # ì‚¬ìš©ìê°€ ê¸°ì–µ ìš”ì²­ ì‹œ ë©”ëª¨ë¦¬ ì €ì¥\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if \"remember\" in last_message.content.lower():\n",
    "        result = memory_extractor.invoke({\"input\": str(state[\"messages\"][-1].content)})\n",
    "        for memory in result.memories:\n",
    "            print(memory)\n",
    "            print(\"-\" * 100)\n",
    "            store.put(namespace, str(uuid.uuid4()), {memory.key: memory.value})\n",
    "\n",
    "    # LLM í˜¸ì¶œ\n",
    "    response = model.invoke(\n",
    "        [{\"role\": \"system\", \"content\": system_msg}] + state[\"messages\"]\n",
    "    )\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# ê·¸ë˜í”„ ë¹Œë“œ\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ ì²´í¬í¬ì¸í„° ìƒì„±\n",
    "# ì‹¤ì œ í”„ë¡œë•ì…˜ì—ì„œëŠ” PostgresSaver ì‚¬ìš© ê¶Œì¥\n",
    "memory_saver = InMemorySaver()\n",
    "memory_store = InMemoryStore()\n",
    "\n",
    "# ê·¸ë˜í”„ ì»´íŒŒì¼\n",
    "graph_with_memory = builder.compile(\n",
    "    checkpointer=memory_saver,\n",
    "    store=memory_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import stream_graph\n",
    "\n",
    "\n",
    "def run_graph(\n",
    "    msg,\n",
    "    thread_id=\"default\",\n",
    "    user_id=\"default\",\n",
    "):\n",
    "    config = {\n",
    "        \"configurable\": {\n",
    "            \"thread_id\": thread_id + user_id,\n",
    "            \"user_id\": user_id,\n",
    "        }\n",
    "    }\n",
    "    print(f\"\\n[ìœ ì €ğŸ™‹] {msg}\")\n",
    "    stream_graph(\n",
    "        graph_with_memory,\n",
    "        inputs={\"messages\": [{\"role\": \"user\", \"content\": msg}]},\n",
    "        config=config,\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\"ì•ˆë…•? ë‚´ ì´ë¦„ì€ í…Œë””ì•¼\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\", \"1\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "### ğŸ§  ì¥ê¸° ê¸°ì–µ ì €ì¥: `remember` í‚¤ì›Œë“œ\n",
    "\n",
    "ë©”ì‹œì§€ì— `remember` ê°€ í¬í•¨ë˜ë©´ ì¤‘ìš” ì •ë³´ë¥¼ ì¥ê¸° ì €ì¥ì†Œì— ê¸°ë¡í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì˜ˆì‹œ**: \"ë‚´ ì´ë¦„ì€ í…Œë””ì•¼ remember\"  \n",
    "- **ì €ì¥ ëŒ€ìƒ**: ì´ë¦„, ì§ì—…, ì„ í˜¸ ë“± ì‚¬ìš©ì í”„ë¡œí•„ì„± ì •ë³´  \n",
    "- **ê¸°ë³¸ ì›ì¹™**: ì¼ë°˜ ëŒ€í™”ëŠ” ë‹¨ê¸° ì»¨í…ìŠ¤íŠ¸ë¡œë§Œ ìœ ì§€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\"ë‚´ ì´ë¦„ì´ í…Œë””ì•¼ remember\", \"2\", \"someone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-39",
   "metadata": {},
   "source": [
    "### ğŸŒŸ Thread ê°„ ì§€ì†ì„±\n",
    "\n",
    "ì‚¬ìš©ì ê¸°ë°˜ ì¥ê¸° ê¸°ì–µì€ Thread ê°€ ë‹¬ë¼ë„ ìœ ì§€ë©ë‹ˆë‹¤.\n",
    "\n",
    "- **Short-term Memory**: Thread ì»¨í…ìŠ¤íŠ¸(ì„¸ì…˜ ë‹¨ìœ„)\n",
    "- **Long-term Memory**: User ID ê¸°ë°˜ í”„ë¡œí•„(ì„¸ì…˜ ê°„ ìœ ì§€)\n",
    "\n",
    "ì‹¤ë¬´ì—ì„œë„ ì‚¬ìš©ì ì •ë³´ëŠ” í´ë¼ì´ì–¸íŠ¸ê°€ ë‹¬ë¼ë„ ìœ ì§€ë˜ëŠ” ê²ƒì´ ì¼ë°˜ì ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\"ë‚´ ì´ë¦„ì´ ë­ë¼ê³  í–ˆë”ë¼?\", \"3\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ì‹œì§€, thread_id, user_id ì „ë‹¬\n",
    "run_graph(\n",
    "    \"ë‚´ ì§ì—…ì€ AI Engineer ì•¼. ë‚´ ì·¨ë¯¸ëŠ” Netflix ë³´ê¸° ì•¼. remember\", \"4\", \"someone\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰\n",
    "run_graph(\"ë‚´ ì´ë¦„, ì§ì—…, ì·¨ë¯¸ ì•Œë ¤ì¤˜\", \"100\", \"someone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ë¥¸ user_id ë¡œ ì‹¤í–‰í•œ ê²½ìš°\n",
    "run_graph(\"ë‚´ ì´ë¦„, ì§ì—…, ì·¨ë¯¸ ì•Œë ¤ì¤˜\", \"100\", \"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### ğŸ” State í™•ì¸\n",
    "\n",
    "í˜„ì¬ ì €ì¥ëœ ìƒíƒœë¥¼ ì¡°íšŒí•´ ë©”ì‹œì§€ ì´ë ¥ê³¼ ì²´í¬í¬ì¸íŠ¸ ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë©”ì‹œì§€ ìˆ˜**  \n",
    "- **ì²´í¬í¬ì¸íŠ¸ ID**  \n",
    "- **ìµœê·¼ ë©”ì‹œì§€ ë‚´ìš©**\n",
    "\n",
    "ìƒíƒœ ì¡°íšŒëŠ” ë””ë²„ê¹…ê³¼ ê²€ì¦ì— ìœ ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì„ì˜ì˜ Config ì„¤ì •\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"100\" + \"someone\",\n",
    "        \"user_id\": \"someone\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# í˜„ì¬ ìƒíƒœ ê°€ì ¸ì˜¤ê¸°\n",
    "snapshot = graph_with_memory.get_state(config)\n",
    "\n",
    "print(\"ğŸ“Š í˜„ì¬ ìƒíƒœ ì •ë³´:\")\n",
    "print(f\"- ë©”ì‹œì§€ ìˆ˜: {len(snapshot.values['messages'])}ê°œ\")\n",
    "print(f\"- ì²´í¬í¬ì¸íŠ¸ ID: {snapshot.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "# ìµœê·¼ ë©”ì‹œì§€ ëª‡ ê°œ í‘œì‹œ\n",
    "print(\"\\n[ìµœê·¼ ë©”ì‹œì§€]\")\n",
    "for msg in snapshot.values[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, \"type\") else \"unknown\"\n",
    "    content = msg.content if hasattr(msg, \"content\") else str(msg)\n",
    "    print(f\"  [{role}]: {content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Human-in-the-Loop ğŸ™‹\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ê³ ìœ„í—˜/ì¤‘ìš” ì‘ì—…ì— ëŒ€í•´ AIê°€ ìŠ¤ìŠ¤ë¡œ ë©ˆì¶”ê³  ì¸ê°„ ìŠ¹ì¸ì„ ìš”ì²­í•˜ëŠ” ìŠ¹ì¸ ê¸°ë°˜ íë¦„ì„ ë„ì…í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ì–¸ì œ ìŠ¹ì¸ì´ í•„ìš”í•œê°€\n",
    "- **ğŸ’° ê¸ˆìœµ ì²˜ë¦¬**: ê²°ì œ/ì´ì²´/íˆ¬ì\n",
    "- **ğŸ¥ ì˜ë£Œ ì¡°ì–¸**: ì²˜ë°©/ì¹˜ë£Œ ê¶Œê³ \n",
    "- **ğŸ“§ ëŒ€ì™¸ ì»¤ë®¤ë‹ˆì¼€ì´ì…˜**: ê³µì§€/ë°œì†¡\n",
    "- **ğŸ” ë³´ì•ˆ ë³€ê²½**: ê¶Œí•œ/ì„¤ì •\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **â¸ï¸ interrupt**: ì‹¤í–‰ ì¼ì‹œì •ì§€ ë° ìŠ¹ì¸ ëŒ€ê¸°\n",
    "- **ğŸ“‹ Command**: ìŠ¹ì¸/ê±°ë¶€ í›„ ì¬ê°œ ëª…ë ¹\n",
    "- **ğŸ‘” Human Approval**: ìŠ¹ì¸ ì›Œí¬í”Œë¡œìš°(ê²€í†  â†’ ê²°ì • â†’ ì¬ê°œ)\n",
    "\n",
    "### ì•„í‚¤í…ì²˜\n",
    "```\n",
    "ì‚¬ìš©ì ìš”ì²­ â†’ AI ë¶„ì„ â†’ â¸ï¸ ìŠ¹ì¸ í•„ìš” íŒë‹¨\n",
    "                  â†“\n",
    "               ì¸ê°„ ê²€í†  â†’ âœ… ìŠ¹ì¸ / âŒ ê±°ë¶€\n",
    "                  â†“\n",
    "                 â–¶ï¸ ì¬ê°œ ë° ì•ˆì „ ì‹¤í–‰\n",
    "```\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- **ì•ˆì „ì„± í–¥ìƒ**, **ì‹ ë¢°ì„± í™•ë³´**, **í˜‘ì—… ê°•í™”**, **ì •ì±… ì¤€ìˆ˜**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(query: str) -> str:\n",
    "    \"\"\"Request assistance from an expert(human).\"\"\"\n",
    "    # interruptë¥¼ í˜¸ì¶œí•˜ì—¬ ì‹¤í–‰ ì¼ì‹œ ì¤‘ì§€\n",
    "    # ì‚¬ëŒì˜ ì‘ë‹µì„ ê¸°ë‹¤ë¦¼\n",
    "    human_response = interrupt({\"query\": query})\n",
    "\n",
    "    # ì‚¬ëŒì˜ ì‘ë‹µ ë°˜í™˜\n",
    "    return human_response[\"data\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### ğŸ—ï¸ HITL ê·¸ë˜í”„ êµ¬ì„±\n",
    "\n",
    "`human_assistance` ë„êµ¬ë¥¼ í†µí•´ ìŠ¹ì¸ ì§€ì ì„ êµ¬í˜„í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì—­í• **: í•„ìš” ì‹œ interrupt ë¡œ ì¤‘ë‹¨ í›„ ì¸ê°„ ë‹µë³€ ëŒ€ê¸°  \n",
    "- **íë¦„**: chatbot â†’ tools(`human_assistance`) â†’ chatbot â†’ END  \n",
    "- **ì£¼ì˜**: interrupt ì™€ ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œì€ í•¨ê»˜ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤(ì¬ê°œ ì‹œ ì¤‘ë³µ í˜¸ì¶œ ë°©ì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸\n",
    "tools_with_human = [human_assistance]\n",
    "\n",
    "# ìƒˆë¡œìš´ ê·¸ë˜í”„ êµ¬ì„±\n",
    "graph_builder_hitl = StateGraph(State)\n",
    "\n",
    "# LLMì— ë„êµ¬ ë°”ì¸ë”©\n",
    "llm_with_human_tools = llm.bind_tools(tools_with_human)\n",
    "\n",
    "\n",
    "def chatbot_with_human(state: State):\n",
    "    \"\"\"Human Interuption ìš”ì²­í•  ìˆ˜ ìˆëŠ” ì±—ë´‡\"\"\"\n",
    "    message = llm_with_human_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # interrupt ì¤‘ ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œ ë°©ì§€\n",
    "    # (ì¬ê°œ ì‹œ ë„êµ¬ í˜¸ì¶œì´ ë°˜ë³µë˜ëŠ” ê²ƒì„ ë°©ì§€)\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert (\n",
    "            len(message.tool_calls) <= 1\n",
    "        ), \"ë³‘ë ¬ ë„êµ¬ í˜¸ì¶œì€ interruptì™€ í•¨ê»˜ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\"\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# ë…¸ë“œ ì¶”ê°€\n",
    "graph_builder_hitl.add_node(\"chatbot_with_human\", chatbot_with_human)\n",
    "\n",
    "# ToolNode ì¶”ê°€\n",
    "tool_node_hitl = ToolNode(tools=tools_with_human)\n",
    "graph_builder_hitl.add_node(\"tools\", tool_node_hitl)\n",
    "\n",
    "# ì—£ì§€ ì¶”ê°€\n",
    "graph_builder_hitl.add_conditional_edges(\"chatbot_with_human\", tools_condition)\n",
    "graph_builder_hitl.add_edge(\"tools\", \"chatbot_with_human\")\n",
    "graph_builder_hitl.add_edge(START, \"chatbot_with_human\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ì™€ í•¨ê»˜ ì»´íŒŒì¼\n",
    "memory_hitl = InMemorySaver()\n",
    "graph_hitl = graph_builder_hitl.compile(checkpointer=memory_hitl)\n",
    "\n",
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(graph_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "### ğŸ¬ HITL í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì‚¬ëŒì—ê²Œ ì¡°ì–¸ì„ ìš”ì²­í•˜ëŠ” ì§ˆë¬¸ìœ¼ë¡œ interrupt ì™€ ì¬ê°œ íë¦„ì„ ê²€ì¦í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì§ˆë¬¸**: \"LangGraph ì˜í•˜ê³  ì‹¶ì€ë°, ì‚¬ëŒì—ê²Œ ì¡°ì–¸ì„ ë“£ê³  ì‹¶ì–´ìš”.\"  \n",
    "- **ê¸°ëŒ€ íë¦„**: chatbot â†’ tools(`human_assistance`) â†’ interrupt â†’ ì¬ê°œ(Command) â†’ ë‹µë³€ ì™„ì„±  \n",
    "- **í™•ì¸ í¬ì¸íŠ¸**: ì¤‘ë‹¨ ì§€ì , ì²´í¬í¬ì¸íŠ¸ ID, ì¬ê°œ í›„ ì¼ê´€ì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import random_uuid\n",
    "\n",
    "# ì¸ê°„ ì§€ì›ì„ ìš”ì²­í•˜ëŠ” ë©”ì‹œì§€\n",
    "user_input = \"LangGraph ê°€ ë­ì•¼? ì‚¬ëŒí•œí…Œ ë“£ê³  ì‹¶ì–´.\"\n",
    "config_hitl = {\"configurable\": {\"thread_id\": random_uuid()}}\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "stream_graph(\n",
    "    graph_hitl,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=config_hitl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ í™•ì¸ - ì–´ëŠ ë…¸ë“œì—ì„œ ì¤‘ë‹¨ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "snapshot = graph_hitl.get_state(config_hitl)\n",
    "print(f\"\\nğŸ“Š í˜„ì¬ ìƒíƒœ:\")\n",
    "print(f\"  ë‹¤ìŒ ì‹¤í–‰í•  ë…¸ë“œ: {snapshot.next}\")\n",
    "print(f\"  ì²´í¬í¬ì¸íŠ¸ ID: {snapshot.config['configurable']['checkpoint_id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ê°„ì˜ ì‘ë‹µìœ¼ë¡œ ì‹¤í–‰ ì¬ê°œ\n",
    "human_response = \"\"\"## ì „ë¬¸ê°€ì˜ ì¡°ì–¸: \n",
    "- YouTube í…Œë””ë…¸íŠ¸: https://www.youtube.com/c/teddynote\n",
    "- ê³ ê¸‰ ê°œë°œì ê°•ì˜ [íŒ¨ìŠ¤íŠ¸ìº í¼ìŠ¤ RAG ë¹„ë²•ë…¸íŠ¸](https://fastcampus.co.kr/data_online_teddy)\n",
    "\"\"\"\n",
    "\n",
    "# Command ê°ì²´ë¡œ ì¬ê°œ\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "print(f\"\\nğŸ’¡ ì‚¬ëŒì˜ ì‘ë‹µ: {human_response}\\n\")\n",
    "\n",
    "# ì¬ê°œ\n",
    "stream_graph(graph_hitl, inputs=human_command, config=config_hitl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-54",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 5: ìƒíƒœ ì»¤ìŠ¤í„°ë§ˆì´ì§•\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ë©”ì‹œì§€ ì™¸ ì—…ë¬´ ë°ì´í„°ê¹Œì§€ ë‹¤ë£¨ëŠ” **ì»¤ìŠ¤í…€ ìƒíƒœ**ì™€ **ë„êµ¬ ê¸°ë°˜ ìƒíƒœ ì—…ë°ì´íŠ¸**ë¥¼ ë„ì…í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **Custom State Fields**: ë©”ì‹œì§€ ì™¸ ê²€í† ìš©/ê²°ê³¼ìš© í•„ë“œ ì¶”ê°€\n",
    "- **State Updates from Tools**: ë„êµ¬ ê²°ê³¼ë¡œ ìƒíƒœ ìë™ ê°±ì‹ \n",
    "- **Manual State Updates**: í•„ìš” ì‹œ ìˆ˜ë™ìœ¼ë¡œ ìƒíƒœ ìˆ˜ì •\n",
    "\n",
    "### ì•„í‚¤í…ì²˜ íŒ¨í„´\n",
    "```\n",
    "ì‚¬ìš©ì ì…ë ¥ â†’ ì •ë³´ ìˆ˜ì§‘(ë„êµ¬) â†’ ì„ì‹œ ì €ì¥(State)\n",
    "             â†“\n",
    "           ê²€í† /ìˆ˜ì • â†’ ìµœì¢… ê²°ê³¼(State)\n",
    "```\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- **ë³µí•© ìƒíƒœ ê´€ë¦¬**, **í”„ë¡œì„¸ìŠ¤ ìë™í™”**, **í’ˆì§ˆ ë³´ì¦**, **ìœ ì—°í•œ ìˆ˜ì •**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId\n",
    "\n",
    "\n",
    "# í™•ì¥ëœ State ì •ì˜\n",
    "class CustomState(TypedDict):\n",
    "    \"\"\"ì»¤ìŠ¤í…€ í•„ë“œê°€ ì¶”ê°€ëœ ìƒíƒœ\"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    human_feedback: str  # ì‚¬ëŒì˜ í”¼ë“œë°±"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-56",
   "metadata": {},
   "source": [
    "### ìƒíƒœ ì—…ë°ì´íŠ¸ ë„êµ¬\n",
    "\n",
    "ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ë¥¼ `Command(update=...)` ë¡œ ìƒíƒœì— ë°˜ì˜í•˜ëŠ” íŒ¨í„´ì„ ì‚¬ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def human_review(\n",
    "    human_feedback, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request human review for information.\"\"\"\n",
    "    # ì¸ê°„ì—ê²Œ ê²€í†  ìš”ì²­\n",
    "    human_response = interrupt(\n",
    "        {\"question\": \"ì´ ì •ë³´ê°€ ë§ë‚˜ìš”?\", \"human_feedback\": human_feedback}\n",
    "    )\n",
    "\n",
    "    feedback = human_response.get(\"human_feedback\", \"\")\n",
    "\n",
    "    if feedback.strip() == \"\":\n",
    "        # ì‚¬ìš©ìê°€ AI ì˜ ë‹µë³€ì— ë™ì˜í•˜ëŠ” ê²½ìš°\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [ToolMessage(human_response, tool_call_id=tool_call_id)]\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        # ì‚¬ìš©ìê°€ AI ì˜ ë‹µë³€ì— ë™ì˜í•˜ì§€ ì•ŠëŠ” ê²½ìš°\n",
    "        corrected_information = f\"# ì‚¬ìš©ìì— ì˜í•´ ìˆ˜ì •ëœ í”¼ë“œë°±: {feedback}\"\n",
    "        return Command(\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    ToolMessage(corrected_information, tool_call_id=tool_call_id)\n",
    "                ]\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-58",
   "metadata": {},
   "source": [
    "### ì»¤ìŠ¤í…€ ìƒíƒœ ê·¸ë˜í”„\n",
    "\n",
    "ì»¤ìŠ¤í…€ í•„ë“œë¥¼ í¬í•¨í•œ `CustomState` ë¡œ ê·¸ë˜í”„ë¥¼ êµ¬ì„±í•˜ê³ , ë„êµ¬ë¥¼ í†µí•œ ìƒíƒœ ì—…ë°ì´íŠ¸ ë£¨í”„ë¥¼ ì ìš©í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë„êµ¬ ë¦¬ìŠ¤íŠ¸\n",
    "tools_custom = [human_review]\n",
    "\n",
    "# ìƒˆë¡œìš´ ê·¸ë˜í”„ êµ¬ì„±\n",
    "custom_graph_builder = StateGraph(CustomState)  # CustomState ì‚¬ìš©\n",
    "\n",
    "# LLMì— ë„êµ¬ ë°”ì¸ë”©\n",
    "llm_with_custom_tools = llm.bind_tools(tools_custom)\n",
    "\n",
    "\n",
    "def chatbot_custom(state: CustomState):\n",
    "    \"\"\"ì»¤ìŠ¤í…€ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ëŠ” ì±—ë´‡\"\"\"\n",
    "    message = llm_with_custom_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    if hasattr(message, \"tool_calls\"):\n",
    "        assert len(message.tool_calls) <= 1\n",
    "\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "# ë…¸ë“œì™€ ì—£ì§€ ì¶”ê°€\n",
    "custom_graph_builder.add_node(\"chatbot\", chatbot_custom)\n",
    "tool_node_custom = ToolNode(tools=tools_custom)\n",
    "custom_graph_builder.add_node(\"tools\", tool_node_custom)\n",
    "\n",
    "custom_graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "custom_graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "custom_graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ì»´íŒŒì¼\n",
    "memory_custom = InMemorySaver()\n",
    "custom_graph = custom_graph_builder.compile(checkpointer=memory_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-60",
   "metadata": {},
   "source": [
    "ê·¸ë˜í”„ ì‹œê°í™”ë¡œ ë…¸ë“œì™€ ì¡°ê±´ë¶€ ë¶„ê¸°, ë£¨í”„ êµ¬ì„±ì„ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ì‹œê°í™”\n",
    "visualize_graph(custom_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-62",
   "metadata": {},
   "source": [
    "### ì»¤ìŠ¤í…€ ìƒíƒœ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "`human_review` ë„êµ¬ í˜¸ì¶œì—ì„œ interrupt ë¡œ ì¤‘ë‹¨ëœ ë’¤, ì¬ê°œ ì‹œ ìƒíƒœê°€ ì˜¬ë°”ë¥´ê²Œ ê°±ì‹ ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangGraphì˜ ì¶œì‹œì¼ì„ ì¡°ì‚¬í•˜ê³  ê²€í†  ìš”ì²­\n",
    "user_input = (\n",
    "    \"2024ë…„ ë…¸ë²¨ ë¬¸í•™ìƒ ìˆ˜ìƒìê°€ ëˆ„êµ¬ì¸ì§€ ì¡°ì‚¬í•´ì£¼ì„¸ìš”. \"\n",
    "    \"ë‹µì„ ì°¾ìœ¼ë©´ `human_review` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ê²€í† ë¥¼ ìš”ì²­í•˜ì„¸ìš”.\"\n",
    ")\n",
    "\n",
    "custom_config = RunnableConfig(configurable={\"thread_id\": random_uuid()})\n",
    "\n",
    "print(f\"User: {user_input}\\n\")\n",
    "\n",
    "# ì‹¤í–‰ (interruptì—ì„œ ì¤‘ë‹¨ë  ê²ƒì„)\n",
    "stream_graph(\n",
    "    custom_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=user_input)]},\n",
    "    config=custom_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.messages import display_message_tree\n",
    "\n",
    "# ìµœì‹  ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°\n",
    "last_message = custom_graph.get_state(custom_config).values[\"messages\"][-1]\n",
    "\n",
    "# ìµœì‹  ë©”ì‹œì§€ tree êµ¬ì¡°ë¡œ í‘œì‹œ\n",
    "display_message_tree(last_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI ê°€ ì‘ì„±í•œ ë‚´ìš©\n",
    "print(last_message.tool_calls[0][\"args\"][\"human_feedback\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¸ê°„ì˜ ê²€í†  ì‘ë‹µìœ¼ë¡œ ì¬ê°œ\n",
    "human_command = Command(\n",
    "    resume={\"human_feedback\": \"2024ë…„ ë…¸ë²¨ ë¬¸í•™ìƒ ìˆ˜ìƒìëŠ” ëŒ€í•œë¯¼êµ­ì˜ í•œê°• ì‘ê°€ì…ë‹ˆë‹¤.\"}\n",
    ")\n",
    "\n",
    "stream_graph(custom_graph, inputs=human_command, config=custom_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 6: ìƒíƒœ ì´ë ¥ ê´€ë¦¬\n",
    "\n",
    "## ğŸ¯ ëª©ì \n",
    "ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ìƒíƒœë¥¼ ì €ì¥/ë³µì›í•´ **ë¡¤ë°±/ì¬ì‹¤í–‰** ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "### í•µì‹¬ ê°œë…\n",
    "- **State History**: ìƒíƒœ ë³€ê²½ ì´ë ¥ ê´€ë¦¬(ì¶”ì /ë³µì›)  \n",
    "- **Checkpoint ID**: íŠ¹ì • ì‹œì  ì‹ë³„ì  \n",
    "- **Rollback**: ì§€ì • ì‹œì ìœ¼ë¡œ ë³µì›  \n",
    "- **Resume**: ë³µì› ìƒíƒœì—ì„œ ì¬ì‹¤í–‰\n",
    "\n",
    "### ê¸°ëŒ€ íš¨ê³¼\n",
    "- **ì•ˆì „í•œ ì‹¤í—˜**, **ë””ë²„ê¹… íš¨ìœ¨**, **A/B í…ŒìŠ¤íŠ¸**, **ì•ˆì •ì„± í–¥ìƒ**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-68",
   "metadata": {},
   "source": [
    "### ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ê·¸ë˜í”„ êµ¬ì„±\n",
    "\n",
    "ìƒíƒœ ì´ë ¥ í™•ì¸ê³¼ ë¡¤ë°±/ì¬ì‹¤í–‰ì„ ìœ„í•œ ìµœì†Œ êµ¬ì„±ìœ¼ë¡œ ì‹œì‘í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ë„êµ¬**: ê²€ìƒ‰(Tavily)  \n",
    "- **ì²´í¬í¬ì¸í„°**: InMemorySaver  \n",
    "- **ì´ë ¥ ì¡°íšŒ**: `get_state_history`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒíƒœ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ê·¸ë˜í”„\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# ë„êµ¬ì™€ LLM ì„¤ì •\n",
    "tools = [TavilySearch(max_results=2)]\n",
    "llm_with_tools_tt = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot_tt(state: State):\n",
    "    \"\"\"ìƒíƒœ ê´€ë¦¬ í…ŒìŠ¤íŠ¸ìš© ì±—ë´‡\"\"\"\n",
    "    return {\"messages\": [llm_with_tools_tt.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# ê·¸ë˜í”„ êµ¬ì„±\n",
    "graph_builder.add_node(\"chatbot\", chatbot_tt)\n",
    "tool_node_tt = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node_tt)\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# ë©”ëª¨ë¦¬ì™€ í•¨ê»˜ ì»´íŒŒì¼\n",
    "memory_tt = InMemorySaver()\n",
    "time_travel_graph = graph_builder.compile(checkpointer=memory_tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-70",
   "metadata": {},
   "source": [
    "### êµ¬ì¡° ì‹œê°í™”\n",
    "\n",
    "ì²´í¬í¬ì¸íŠ¸ ê¸°ë°˜ ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ ì‹œê°í™”í•˜ì—¬ ë¶„ê¸°ì™€ ë£¨í”„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œê°í™”\n",
    "visualize_graph(time_travel_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-72",
   "metadata": {},
   "source": [
    "### ì²´í¬í¬ì¸íŠ¸ ì‹œí€€ìŠ¤ ìƒì„±\n",
    "\n",
    "ì—¬ëŸ¬ ë²ˆ ëŒ€í™”ë¥¼ ì‹¤í–‰í•´ ì¶©ë¶„í•œ ìƒíƒœ ì´ë ¥ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "\n",
    "- ì²´í¬í¬ì¸íŠ¸ 1: ì²« ëŒ€í™” ì¢…ë£Œ  \n",
    "- ì²´í¬í¬ì¸íŠ¸ 2: ë‘ ë²ˆì§¸ ëŒ€í™” ì¢…ë£Œ  \n",
    "- ì²´í¬í¬ì¸íŠ¸ 3: ì´í›„ í™•ì¥(ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-73",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_travel_config = RunnableConfig(configurable={\"thread_id\": \"time-travel-1\"})\n",
    "\n",
    "# ì²« ë²ˆì§¸ ëŒ€í™”\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\"messages\": [HumanMessage(content=\"í…Œë””ë…¸íŠ¸ì— ëŒ€í•´ì„œ ì¡°ì‚¬ ì¢€ í•´ì£¼ì„¸ìš”.\")]},\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‘ ë²ˆì§¸ ëŒ€í™”\n",
    "stream_graph(\n",
    "    time_travel_graph,\n",
    "    inputs={\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"í…Œë””ë…¸íŠ¸ ì˜¨ë¼ì¸ ê°•ì˜ ì£¼ì†Œë¥¼ ì¡°ì‚¬í•´ í•´ì£¼ì„¸ìš”.\")\n",
    "        ]\n",
    "    },\n",
    "    config=time_travel_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-75",
   "metadata": {},
   "source": [
    "### ìƒíƒœ ì´ë ¥ íƒìƒ‰ ë° ì‹œì  ì„ íƒ\n",
    "\n",
    "`get_state_history` ë¡œ ì´ë ¥ì„ ì¡°íšŒí•˜ê³ , ë¡¤ë°±/ì¬ì‹¤í–‰í•  ì²´í¬í¬ì¸íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì¡°íšŒ í•­ëª©**: ë‹¤ìŒ ë…¸ë“œ, ì²´í¬í¬ì¸íŠ¸ ID, ë©”ì‹œì§€ ìˆ˜  \n",
    "- **ì„ íƒ ê¸°ì¤€**: ìˆ˜ì •í•˜ê³  ì‹¶ì€ ë‹¨ê³„ ì§í›„ì˜ ì•ˆì • ì‹œì "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì „ì²´ ìƒíƒœ íˆìŠ¤í† ë¦¬ í™•ì¸\n",
    "print(\"ğŸ“œ ìƒíƒœ íˆìŠ¤í† ë¦¬ (ìµœì‹ ìˆœ):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# to_replay ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "to_replay = None\n",
    "\n",
    "for i, state in enumerate(time_travel_graph.get_state_history(time_travel_config)):\n",
    "    print(f\"\\n[ì²´í¬í¬ì¸íŠ¸ {i}]\")\n",
    "    print(f\"  ë‹¤ìŒ ë…¸ë“œ: {state.next}\")\n",
    "    print(f\"  ì²´í¬í¬ì¸íŠ¸ ID: {state.config['configurable']['checkpoint_id']}\")\n",
    "\n",
    "    if len(state.values[\"messages\"]) == 6 and to_replay is None:\n",
    "        print(\"  â­ ì´ ìƒíƒœë¡œ ë˜ëŒì•„ê°ˆ ì˜ˆì •\")\n",
    "        display_message_tree(state.values[\"messages\"][-1])\n",
    "        to_replay = state\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-77",
   "metadata": {},
   "source": [
    "### íŠ¹ì • ì²´í¬í¬ì¸íŠ¸ë¡œ ë¡¤ë°±\n",
    "\n",
    "ì„ íƒí•œ ì²´í¬í¬ì¸íŠ¸ë¡œ ìƒíƒœë¥¼ ë³µì›í•˜ì—¬ ì´í›„ ë‹¨ê³„ë¥¼ ì¬ì‹¤í–‰í•  ì¤€ë¹„ë¥¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ëŒ€ìƒ**: ë‘ ë²ˆì§¸ ê²€ìƒ‰ ì™„ë£Œ ì‹œì   \n",
    "- **ëª©ì **: ê²€ìƒ‰ ì „ëµ ë³€ê²½ í›„ ê²°ê³¼ ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-78",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-79",
   "metadata": {},
   "source": [
    "### ìƒíƒœ ìˆ˜ì • ë° ìµœì í™”\n",
    "\n",
    "ë³µì›ëœ ìƒíƒœì—ì„œ ë„êµ¬ í˜¸ì¶œ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•´ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ìœ ë„í•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì˜ˆì‹œ ë³€ê²½**: `query` ë¥¼ ë„ë©”ì¸ í•œì •ìœ¼ë¡œ ìˆ˜ì •(`site:...`)  \n",
    "- **ëª©í‘œ**: ì •í™•ë„ í–¥ìƒ ë° ê²°ê³¼ í’ˆì§ˆ ë¹„êµ(A/B)\n",
    "\n",
    "ëŸ°íƒ€ì„ íŒŒë¼ë¯¸í„° ìˆ˜ì •ì€ ì¬ì‹¤í–‰ ë¹„ìš©ì„ ì¤„ì´ë©´ì„œ ìµœì í™”ë¥¼ ë¹ ë¥´ê²Œ ê²€ì¦í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools import update_tool_call\n",
    "\n",
    "# ì‚¬ìš© ì˜ˆì‹œ:\n",
    "updated_message = update_tool_call(\n",
    "    to_replay.values[\"messages\"][-1],\n",
    "    tool_name=\"tavily_search\",\n",
    "    tool_args={\"query\": \"[LGì „ì ë©”ë‰´ì–¼] ê¶¤ë„ ê°•ì˜ youtube\", \"search_depth\": \"basic\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ê²½í•˜ê¸° ì „ì˜ message\n",
    "display_message_tree(to_replay.values[\"messages\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ê²½í•œ ì´í›„ì˜ ë©”ì‹œì§€ íŠ¸ë¦¬\n",
    "display_message_tree(updated_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë³€ê²½ëœ ë©”ì‹œì§€ë¥¼ update_state ë¡œ ì—…ë°ì´íŠ¸\n",
    "updated_state = time_travel_graph.update_state(\n",
    "    values={\"messages\": [updated_message]}, config=to_replay.config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-84",
   "metadata": {},
   "source": [
    "### ìˆ˜ì • ìƒíƒœ ì¬ì‹¤í–‰\n",
    "\n",
    "ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ì¬ì‹¤í–‰í•˜ì—¬ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "- **ì‹¤í–‰ ë°©ì‹**: ì…ë ¥ ì—†ì´ ì—…ë°ì´íŠ¸ëœ ìƒíƒœë¡œ ì¬ê°œ  \n",
    "- **ë¹„êµ í•­ëª©**: ì›ë˜ ê²°ê³¼ vs ìˆ˜ì • í›„ ê²°ê³¼  \n",
    "- **ê¸°ëŒ€ íš¨ê³¼**: ì •í™•ë„ í–¥ìƒ, ë¹„ìš© ì ˆê°, ë¹ ë¥¸ ì‹¤í—˜ ì‚¬ì´í´"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—…ë°ì´íŠ¸ëœ ë©”ì‹œì§€ë¥¼ ìŠ¤íŠ¸ë¦¬ë° í•©ë‹ˆë‹¤.\n",
    "stream_graph(time_travel_graph, inputs=None, config=updated_state)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
